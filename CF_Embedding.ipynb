{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a964da95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pandas/compat/_optional.py:161: UserWarning: Pandas requires version '2.7.1' or newer of 'numexpr' (version '2.7.0' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import preprocess.preprocess as cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66824980",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.abspath(os.path.join(os.getcwd(), 'data'))\n",
    "\n",
    "df_traveller = pd.read_csv(os.path.join(data_path, 'traveller.csv'))\n",
    "df_travel = pd.read_csv(os.path.join(data_path, 'travel.csv'))\n",
    "df_area = pd.read_csv(os.path.join(data_path, 'area.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056cc247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = [\n",
    "#     'TRAVELER_ID', 'GENDER', 'AGE_GRP', 'INCOME', 'TRAVEL_STYL_1', 'TRAVEL_STYL_2', 'TRAVEL_STYL_3',\n",
    "#     'TRAVEL_STYL_4', 'TRAVEL_STYL_5', 'TRAVEL_STYL_6', 'TRAVEL_STYL_7', 'TRAVEL_STYL_8',\n",
    "#     'TRAVEL_MOTIVE_1', 'TRAVEL_NUM', 'TRAVEL_COMPANIONS_NUM',\n",
    "#     'VISIT_AREA_NM', 'VISIT_AREA_TYPE_CD', 'SIDO', 'GUNGU', 'RESIDENCE_TIME_MIN', 'REVISIT_YN',\n",
    "#     'DGSTFN'\n",
    "# ]\n",
    "\n",
    "df = cf.cf_preprocess(df_traveller, df_travel, df_area)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ee62899",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'X_COORD'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'X_COORD'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTRAVELER_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma004293\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mX_COORD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'X_COORD'"
     ]
    }
   ],
   "source": [
    "a = df[df['TRAVELER_ID']=='a004293']\n",
    "a[['X_COORD', 'Y_COORD']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47c43d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['경기', '인천', '서울', '강원', '충북', '서울특별시', '경북', '충남', '인천광역시', '경기도',\n",
       "       '대전', '경상북도', '대구', '광주', '경남', '세종특별자치시', '부산', '울산', '강원도', '전남',\n",
       "       '전북', '부산광역시', '대구광역시', '울산광역시', '경상남도', '광복동', '제주특별자치도', '충청남도',\n",
       "       '전라북도', '충청북도', '전라남도', '광주광역시', '동부리', '대전광역시'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df['SIDO'].unique()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d231976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TravelDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.users = df['TRAVELER_ID'].astype('category').cat.codes.values\n",
    "        self.items = df['VISIT_AREA_NM'].astype('category').cat.codes.values\n",
    "        self.visit_area_type_cd = df['VISIT_AREA_TYPE_CD'].astype('category').cat.codes.values\n",
    "        self.sido = df['SIDO'].astype('category').cat.codes.values\n",
    "        self.gungu = df['GUNGU'].astype('category').cat.codes.values\n",
    "        self.residence_time_min = df['RESIDENCE_TIME_MIN'].values\n",
    "        self.revisit_yn = df['REVISIT_YN'].values\n",
    "        self.travel_mission_priority = df['TRAVEL_MISSION_PRIORITY'].astype('category').cat.codes.values\n",
    "        self.gender = df['GENDER'].astype('category').values\n",
    "        self.age_grp = df['AGE_GRP'].astype('category').cat.codes.values\n",
    "        self.income = df['INCOME'].astype('category').cat.codes.values\n",
    "        self.style1 = df['TRAVEL_STYL_1'].astype('category').cat.codes.values\n",
    "        self.style2 = df['TRAVEL_STYL_2'].astype('category').cat.codes.values\n",
    "        self.style3 = df['TRAVEL_STYL_3'].astype('category').cat.codes.values\n",
    "        self.style4 = df['TRAVEL_STYL_4'].astype('category').cat.codes.values\n",
    "        self.style5 = df['TRAVEL_STYL_5'].astype('category').cat.codes.values\n",
    "        self.style6 = df['TRAVEL_STYL_6'].astype('category').cat.codes.values\n",
    "        self.style7 = df['TRAVEL_STYL_7'].astype('category').cat.codes.values\n",
    "        self.style8 = df['TRAVEL_STYL_8'].astype('category').cat.codes.values\n",
    "        self.motive = df['TRAVEL_MOTIVE_1'].astype('category').cat.codes.values\n",
    "        self.travel_num = df['TRAVEL_NUM'].values\n",
    "        self.companion_num = df['TRAVEL_COMPANIONS_NUM'].values\n",
    "        \n",
    "        self.ratings = df['SCORE'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 모든 특성을 포함시켜 반환\n",
    "        features = (\n",
    "            torch.tensor(self.users[idx], dtype=torch.long),\n",
    "            torch.tensor(self.items[idx], dtype=torch.long),\n",
    "            torch.tensor(self.visit_area_type_cd[idx], dtype=torch.long),\n",
    "            torch.tensor(self.sido[idx], dtype=torch.long),\n",
    "            torch.tensor(self.gungu[idx], dtype=torch.long),\n",
    "            torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n",
    "            torch.tensor(self.revisit_yn[idx], dtype=torch.long),\n",
    "            torch.tensor(self.travel_mission_priority[idx], dtype=torch.long),\n",
    "            torch.tensor(self.gender[idx], dtype=torch.long),\n",
    "            torch.tensor(self.age_grp[idx], dtype=torch.long),\n",
    "            torch.tensor(self.income[idx], dtype=torch.long),\n",
    "            torch.tensor(self.style1[idx], dtype=torch.long),\n",
    "            torch.tensor(self.style2[idx], dtype=torch.long),\n",
    "            torch.tensor(self.style3[idx], dtype=torch.long),\n",
    "            torch.tensor(self.style4[idx], dtype=torch.long),\n",
    "            torch.tensor(self.style5[idx], dtype=torch.long),\n",
    "            torch.tensor(self.style6[idx], dtype=torch.long),\n",
    "            torch.tensor(self.style7[idx], dtype=torch.long),\n",
    "            torch.tensor(self.style8[idx], dtype=torch.long),\n",
    "            torch.tensor(self.motive[idx], dtype=torch.long),\n",
    "            torch.tensor(self.travel_num[idx], dtype=torch.long),\n",
    "            torch.tensor(self.companion_num[idx], dtype=torch.long)\n",
    "        )\n",
    "\n",
    "        target = torch.tensor(self.ratings[idx], dtype=torch.float)\n",
    "\n",
    "        return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc5d5f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, num_sido, num_gungu, num_travel_mission_priority, num_age_grp, num_income,\n",
    "                 num_style1, num_style2, num_style3, num_style4, num_style5, num_style6, num_style7, num_style8, num_motive, embed_size):\n",
    "        super(NCF, self).__init__()\n",
    "        # 기본 임베딩\n",
    "        self.user_embed = nn.Embedding(num_users, embed_size)\n",
    "        self.item_embed = nn.Embedding(num_items, embed_size)\n",
    "        \n",
    "        # 추가적인 범주형 특성에 대한 임베딩\n",
    "        self.sido_embed = nn.Embedding(num_sido, embed_size)\n",
    "        self.gungu_embed = nn.Embedding(num_gungu, embed_size)\n",
    "        self.travel_mission_priority_embed = nn.Embedding(num_travel_mission_priority, embed_size)\n",
    "        self.age_grp_embed = nn.Embedding(num_age_grp, embed_size)\n",
    "        self.income_embed = nn.Embedding(num_income, embed_size)\n",
    "        #self.style1_embed = nn.Embedding(num_style1, embed_size)\n",
    "        self.style2_embed = nn.Embedding(num_style2, embed_size)\n",
    "        self.style3_embed = nn.Embedding(num_style3, embed_size)\n",
    "        self.style4_embed = nn.Embedding(num_style4, embed_size)\n",
    "        self.style5_embed = nn.Embedding(num_style5, embed_size)\n",
    "        self.style6_embed = nn.Embedding(num_style6, embed_size)\n",
    "        self.style7_embed = nn.Embedding(num_style7, embed_size)\n",
    "        self.style8_embed = nn.Embedding(num_style8, embed_size)\n",
    "        self.motive_embed = nn.Embedding(num_motive, embed_size)\n",
    "        \n",
    "        # 연속형 특성을 위한 입력 크기\n",
    "        continuous_feature_input_dim = 5  # 'gender', 'revisit_yn', 'residence_time_min', 'travel_num', 'companion_num'\n",
    "        \n",
    "        # MLP 파트\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(embed_size * 15 + continuous_feature_input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, features):\n",
    "        user_ids, item_ids, sido, gungu, residence_time_min, revisit_yn, travel_mission_priority, gender, age_grp, income, style1, style2, style3, style4, style5, style6, style7, style8, motive, residence_time_min, travel_num, companion_num = features\n",
    "        \n",
    "        # 기본 및 추가적인 범주형 특성에 대한 임베딩\n",
    "        user_embedded = self.user_embed(user_ids)\n",
    "        item_embedded = self.item_embed(item_ids)\n",
    "        sido_embedded = self.sido_embed(sido)\n",
    "        gungu_embedded = self.gungu_embed(gungu)\n",
    "        travel_mission_priority_embedded = self.travel_mission_priority_embed(travel_mission_priority)\n",
    "        age_grp_embedded = self.age_grp_embed(age_grp)\n",
    "        income_embedded = self.income_embed(income)\n",
    "        #style1_embedded = self.style1_embed(style1)\n",
    "        style2_embedded = self.style2_embed(style2)\n",
    "        style3_embedded = self.style3_embed(style3)\n",
    "        style4_embedded = self.style4_embed(style4)\n",
    "        style5_embedded = self.style5_embed(style5)\n",
    "        style6_embedded = self.style6_embed(style6)\n",
    "        style7_embedded = self.style7_embed(style7)\n",
    "        style8_embedded = self.style8_embed(style8)\n",
    "        motive_embedded = self.motive_embed(motive)\n",
    "\n",
    "        # 연속형 특성\n",
    "        continuous_features = torch.cat([gender.unsqueeze(1), residence_time_min.unsqueeze(1), revisit_yn.unsqueeze(1), travel_num.unsqueeze(1), companion_num.unsqueeze(1)], dim=1)\n",
    "\n",
    "        # 모든 임베딩 및 연속형 특성을 결합\n",
    "        x = torch.cat([\n",
    "            user_embedded, item_embedded, sido_embedded, gungu_embedded, travel_mission_priority_embedded,\n",
    "            age_grp_embedded, income_embedded,\n",
    "            style2_embedded, style3_embedded, style4_embedded,\n",
    "            style5_embedded, style6_embedded, style7_embedded, style8_embedded,\n",
    "            motive_embedded, continuous_features\n",
    "        ], dim=-1)\n",
    "\n",
    "        # MLP를 통해 예측값을 계산\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f094cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, optimizer, model, criterion):\n",
    "    \n",
    "    # 학습 루프\n",
    "    for epoch in range(100):\n",
    "        for batch in train_dataloader:\n",
    "            features, targets = batch\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(features).squeeze()\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "def test(test_dataloader, model):\n",
    "    # 모델을 평가 모드로 설정\n",
    "    model.eval()\n",
    "\n",
    "    # 예측값과 실제값을 저장할 리스트 초기화\n",
    "    preds = []\n",
    "    targets = []\n",
    "\n",
    "    # 데이터로더에서 배치를 순회하며 평가\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            features, target = batch\n",
    "            # 모델 예측\n",
    "            output = model(features).squeeze()  # 모델 출력 조정 필요 시 여기를 수정\n",
    "            preds.extend(output.cpu().numpy())  # 예측값 저장\n",
    "            targets.extend(target.cpu().numpy())  # 실제값 저장\n",
    "\n",
    "    test_df['PREDICT'] = preds\n",
    "    # MSE 계산\n",
    "    mse = mean_squared_error(targets, preds)\n",
    "    print(f'Test MSE: {mse}')\n",
    "    \n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4db8223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7056321501731873\n",
      "Epoch 2, Loss: 0.4360787868499756\n",
      "Epoch 3, Loss: 0.6231222152709961\n",
      "Epoch 4, Loss: 0.40896308422088623\n",
      "Epoch 5, Loss: 0.7478969097137451\n",
      "Epoch 6, Loss: 0.36712467670440674\n",
      "Epoch 7, Loss: 0.41165676712989807\n",
      "Epoch 8, Loss: 0.20606181025505066\n",
      "Epoch 9, Loss: 0.28790345788002014\n",
      "Epoch 10, Loss: 0.22555848956108093\n",
      "Epoch 11, Loss: 1.021498203277588\n",
      "Epoch 12, Loss: 0.5736213326454163\n",
      "Epoch 13, Loss: 0.2431604266166687\n",
      "Epoch 14, Loss: 0.22717301547527313\n",
      "Epoch 15, Loss: 0.34455543756484985\n",
      "Epoch 16, Loss: 0.06578680872917175\n",
      "Epoch 17, Loss: 0.07224244624376297\n",
      "Epoch 18, Loss: 0.16720430552959442\n",
      "Epoch 19, Loss: 0.13267236948013306\n",
      "Epoch 20, Loss: 0.21964022517204285\n",
      "Epoch 21, Loss: 0.25768014788627625\n",
      "Epoch 22, Loss: 0.13209745287895203\n",
      "Epoch 23, Loss: 0.21425828337669373\n",
      "Epoch 24, Loss: 0.09112724661827087\n",
      "Epoch 25, Loss: 0.38650691509246826\n",
      "Epoch 26, Loss: 0.10389889031648636\n",
      "Epoch 27, Loss: 0.15350408852100372\n",
      "Epoch 28, Loss: 0.07656414806842804\n",
      "Epoch 29, Loss: 0.06964005529880524\n",
      "Epoch 30, Loss: 0.08565869927406311\n",
      "Epoch 31, Loss: 0.10716178268194199\n",
      "Epoch 32, Loss: 0.07171168923377991\n",
      "Epoch 33, Loss: 0.06875918805599213\n",
      "Epoch 34, Loss: 0.035641081631183624\n",
      "Epoch 35, Loss: 0.10258039087057114\n",
      "Epoch 36, Loss: 0.056215301156044006\n",
      "Epoch 37, Loss: 0.06904609501361847\n",
      "Epoch 38, Loss: 0.045262500643730164\n",
      "Epoch 39, Loss: 0.031522925943136215\n",
      "Epoch 40, Loss: 0.05216330662369728\n",
      "Epoch 41, Loss: 0.04901769012212753\n",
      "Epoch 42, Loss: 0.1050194799900055\n",
      "Epoch 43, Loss: 0.04724729806184769\n",
      "Epoch 44, Loss: 0.04629763960838318\n",
      "Epoch 45, Loss: 0.017480630427598953\n",
      "Epoch 46, Loss: 0.05014694109559059\n",
      "Epoch 47, Loss: 0.030881140381097794\n",
      "Epoch 48, Loss: 0.05909988656640053\n",
      "Epoch 49, Loss: 0.017445219680666924\n",
      "Epoch 50, Loss: 0.026719210669398308\n",
      "Epoch 51, Loss: 0.015636365860700607\n",
      "Epoch 52, Loss: 0.039840009063482285\n",
      "Epoch 53, Loss: 0.03697238862514496\n",
      "Epoch 54, Loss: 0.030992282554507256\n",
      "Epoch 55, Loss: 0.038168247789144516\n",
      "Epoch 56, Loss: 0.020050643011927605\n",
      "Epoch 57, Loss: 0.031106766313314438\n",
      "Epoch 58, Loss: 0.018995054066181183\n",
      "Epoch 59, Loss: 0.015554596669971943\n",
      "Epoch 60, Loss: 0.03372897207736969\n",
      "Epoch 61, Loss: 0.026919519528746605\n",
      "Epoch 62, Loss: 0.024595947936177254\n",
      "Epoch 63, Loss: 0.058763351291418076\n",
      "Epoch 64, Loss: 0.010636362247169018\n",
      "Epoch 65, Loss: 0.01942732185125351\n",
      "Epoch 66, Loss: 0.01703748106956482\n",
      "Epoch 67, Loss: 0.009895184077322483\n",
      "Epoch 68, Loss: 0.012082425877451897\n",
      "Epoch 69, Loss: 0.015275354497134686\n",
      "Epoch 70, Loss: 0.012640454806387424\n",
      "Epoch 71, Loss: 0.006441389676183462\n",
      "Epoch 72, Loss: 0.009672331623733044\n",
      "Epoch 73, Loss: 0.013812018558382988\n",
      "Epoch 74, Loss: 0.013394886627793312\n",
      "Epoch 75, Loss: 0.013866879045963287\n",
      "Epoch 76, Loss: 0.017085149884223938\n",
      "Epoch 77, Loss: 0.013788978569209576\n",
      "Epoch 78, Loss: 0.014920140616595745\n",
      "Epoch 79, Loss: 0.012658994644880295\n",
      "Epoch 80, Loss: 0.008055035024881363\n",
      "Epoch 81, Loss: 0.007768220268189907\n",
      "Epoch 82, Loss: 0.007561190985143185\n",
      "Epoch 83, Loss: 0.030829021707177162\n",
      "Epoch 84, Loss: 0.012057001702487469\n",
      "Epoch 85, Loss: 0.011231559328734875\n",
      "Epoch 86, Loss: 0.015344089828431606\n",
      "Epoch 87, Loss: 0.004878728184849024\n",
      "Epoch 88, Loss: 0.009179879911243916\n",
      "Epoch 89, Loss: 0.004499337635934353\n",
      "Epoch 90, Loss: 0.00947109516710043\n",
      "Epoch 91, Loss: 0.008737199008464813\n",
      "Epoch 92, Loss: 0.010464326478540897\n",
      "Epoch 93, Loss: 0.006953651085495949\n",
      "Epoch 94, Loss: 0.007355266250669956\n",
      "Epoch 95, Loss: 0.010989409871399403\n",
      "Epoch 96, Loss: 0.006846133153885603\n",
      "Epoch 97, Loss: 0.00583061994984746\n",
      "Epoch 98, Loss: 0.004969865549355745\n",
      "Epoch 99, Loss: 0.005528867710381746\n",
      "Epoch 100, Loss: 0.015648122876882553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.4129966497421265\n",
      "Epoch 1, Loss: 0.4808848202228546\n",
      "Epoch 2, Loss: 0.4547133445739746\n",
      "Epoch 3, Loss: 0.46294963359832764\n",
      "Epoch 4, Loss: 1.0071873664855957\n",
      "Epoch 5, Loss: 0.456292986869812\n",
      "Epoch 6, Loss: 0.5417840480804443\n",
      "Epoch 7, Loss: 0.561427652835846\n",
      "Epoch 8, Loss: 0.49334171414375305\n",
      "Epoch 9, Loss: 0.32193490862846375\n",
      "Epoch 10, Loss: 0.3872184157371521\n",
      "Epoch 11, Loss: 0.5322033762931824\n",
      "Epoch 12, Loss: 0.28539928793907166\n",
      "Epoch 13, Loss: 0.3315727114677429\n",
      "Epoch 14, Loss: 0.42454206943511963\n",
      "Epoch 15, Loss: 0.4816496670246124\n",
      "Epoch 16, Loss: 0.3004109263420105\n",
      "Epoch 17, Loss: 0.18539108335971832\n",
      "Epoch 18, Loss: 0.2008640319108963\n",
      "Epoch 19, Loss: 0.32426509261131287\n",
      "Epoch 20, Loss: 0.32064417004585266\n",
      "Epoch 21, Loss: 0.15206079185009003\n",
      "Epoch 22, Loss: 0.15363426506519318\n",
      "Epoch 23, Loss: 0.14380109310150146\n",
      "Epoch 24, Loss: 0.15929126739501953\n",
      "Epoch 25, Loss: 0.06840632855892181\n",
      "Epoch 26, Loss: 0.06830112636089325\n",
      "Epoch 27, Loss: 0.42941442131996155\n",
      "Epoch 28, Loss: 0.04587310552597046\n",
      "Epoch 29, Loss: 0.0964256301522255\n",
      "Epoch 30, Loss: 0.11088511347770691\n",
      "Epoch 31, Loss: 0.11918459832668304\n",
      "Epoch 32, Loss: 0.06177103519439697\n",
      "Epoch 33, Loss: 0.2010703831911087\n",
      "Epoch 34, Loss: 0.07566499710083008\n",
      "Epoch 35, Loss: 0.03895159065723419\n",
      "Epoch 36, Loss: 0.09120651334524155\n",
      "Epoch 37, Loss: 0.06575682759284973\n",
      "Epoch 38, Loss: 0.0776011124253273\n",
      "Epoch 39, Loss: 0.06976771354675293\n",
      "Epoch 40, Loss: 0.04622238874435425\n",
      "Epoch 41, Loss: 0.045793548226356506\n",
      "Epoch 42, Loss: 0.06313759833574295\n",
      "Epoch 43, Loss: 0.05015765503048897\n",
      "Epoch 44, Loss: 0.03257191926240921\n",
      "Epoch 45, Loss: 0.03486191853880882\n",
      "Epoch 46, Loss: 0.02156979776918888\n",
      "Epoch 47, Loss: 0.029832355678081512\n",
      "Epoch 48, Loss: 0.043197888880968094\n",
      "Epoch 49, Loss: 0.053233370184898376\n",
      "Epoch 50, Loss: 0.02247297763824463\n",
      "Epoch 51, Loss: 0.025570515543222427\n",
      "Epoch 52, Loss: 0.02563832327723503\n",
      "Epoch 53, Loss: 0.014803758822381496\n",
      "Epoch 54, Loss: 0.02383124642074108\n",
      "Epoch 55, Loss: 0.01897755078971386\n",
      "Epoch 56, Loss: 0.01672542281448841\n",
      "Epoch 57, Loss: 0.019419275224208832\n",
      "Epoch 58, Loss: 0.024560146033763885\n",
      "Epoch 59, Loss: 0.014372888952493668\n",
      "Epoch 60, Loss: 0.02145260199904442\n",
      "Epoch 61, Loss: 0.014956891536712646\n",
      "Epoch 62, Loss: 0.024916108697652817\n",
      "Epoch 63, Loss: 0.008723916485905647\n",
      "Epoch 64, Loss: 0.017320122569799423\n",
      "Epoch 65, Loss: 0.025677569210529327\n",
      "Epoch 66, Loss: 0.0060674212872982025\n",
      "Epoch 67, Loss: 0.012967915274202824\n",
      "Epoch 68, Loss: 0.005881685763597488\n",
      "Epoch 69, Loss: 0.01347796805202961\n",
      "Epoch 70, Loss: 0.014802861958742142\n",
      "Epoch 71, Loss: 0.019517676904797554\n",
      "Epoch 72, Loss: 0.011006978340446949\n",
      "Epoch 73, Loss: 0.012467621825635433\n",
      "Epoch 74, Loss: 0.018518924713134766\n",
      "Epoch 75, Loss: 0.011370551772415638\n",
      "Epoch 76, Loss: 0.016193712130188942\n",
      "Epoch 77, Loss: 0.024772200733423233\n",
      "Epoch 78, Loss: 0.006222202442586422\n",
      "Epoch 79, Loss: 0.016097500920295715\n",
      "Epoch 80, Loss: 0.009844903834164143\n",
      "Epoch 81, Loss: 0.021106639876961708\n",
      "Epoch 82, Loss: 0.019687991589307785\n",
      "Epoch 83, Loss: 0.009421298280358315\n",
      "Epoch 84, Loss: 0.005354651249945164\n",
      "Epoch 85, Loss: 0.006613613571971655\n",
      "Epoch 86, Loss: 0.009830298833549023\n",
      "Epoch 87, Loss: 0.02061491645872593\n",
      "Epoch 88, Loss: 0.010872209444642067\n",
      "Epoch 89, Loss: 0.017345525324344635\n",
      "Epoch 90, Loss: 0.005257448181509972\n",
      "Epoch 91, Loss: 0.02338295988738537\n",
      "Epoch 92, Loss: 0.0061255269683897495\n",
      "Epoch 93, Loss: 0.004658658988773823\n",
      "Epoch 94, Loss: 0.014265424571931362\n",
      "Epoch 95, Loss: 0.003376234322786331\n",
      "Epoch 96, Loss: 0.022777916863560677\n",
      "Epoch 97, Loss: 0.009695325046777725\n",
      "Epoch 98, Loss: 0.005550898611545563\n",
      "Epoch 99, Loss: 0.0026871145237237215\n",
      "Epoch 100, Loss: 0.013577858917415142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3247429132461548\n",
      "Epoch 1, Loss: 0.47577211260795593\n",
      "Epoch 2, Loss: 0.5268906354904175\n",
      "Epoch 3, Loss: 0.5137926340103149\n",
      "Epoch 4, Loss: 0.43528950214385986\n",
      "Epoch 5, Loss: 0.23465310037136078\n",
      "Epoch 6, Loss: 1.020770788192749\n",
      "Epoch 7, Loss: 0.5765424966812134\n",
      "Epoch 8, Loss: 0.6289665699005127\n",
      "Epoch 9, Loss: 0.2790728807449341\n",
      "Epoch 10, Loss: 0.8366454839706421\n",
      "Epoch 11, Loss: 0.5558504462242126\n",
      "Epoch 12, Loss: 0.11618483066558838\n",
      "Epoch 13, Loss: 0.27070868015289307\n",
      "Epoch 14, Loss: 0.5328861474990845\n",
      "Epoch 15, Loss: 0.2972677946090698\n",
      "Epoch 16, Loss: 0.19932778179645538\n",
      "Epoch 17, Loss: 0.18418660759925842\n",
      "Epoch 18, Loss: 0.19723673164844513\n",
      "Epoch 19, Loss: 0.3731497526168823\n",
      "Epoch 20, Loss: 0.18131786584854126\n",
      "Epoch 21, Loss: 0.18185649812221527\n",
      "Epoch 22, Loss: 0.14261089265346527\n",
      "Epoch 23, Loss: 0.18721769750118256\n",
      "Epoch 24, Loss: 0.250100314617157\n",
      "Epoch 25, Loss: 0.12531347572803497\n",
      "Epoch 26, Loss: 0.19312866032123566\n",
      "Epoch 27, Loss: 0.048347365111112595\n",
      "Epoch 28, Loss: 0.12407436966896057\n",
      "Epoch 29, Loss: 0.08616766333580017\n",
      "Epoch 30, Loss: 0.13573327660560608\n",
      "Epoch 31, Loss: 0.10715726017951965\n",
      "Epoch 32, Loss: 0.023118318989872932\n",
      "Epoch 33, Loss: 0.032873135060071945\n",
      "Epoch 34, Loss: 0.10966982692480087\n",
      "Epoch 35, Loss: 0.09010624885559082\n",
      "Epoch 36, Loss: 0.020785951986908913\n",
      "Epoch 37, Loss: 0.11902900785207748\n",
      "Epoch 38, Loss: 0.02446877956390381\n",
      "Epoch 39, Loss: 0.06327038258314133\n",
      "Epoch 40, Loss: 0.08207006752490997\n",
      "Epoch 41, Loss: 0.0460783876478672\n",
      "Epoch 42, Loss: 0.049196090549230576\n",
      "Epoch 43, Loss: 0.05151212587952614\n",
      "Epoch 44, Loss: 0.037104494869709015\n",
      "Epoch 45, Loss: 0.08235222846269608\n",
      "Epoch 46, Loss: 0.022396022453904152\n",
      "Epoch 47, Loss: 0.057884421199560165\n",
      "Epoch 48, Loss: 0.014677531085908413\n",
      "Epoch 49, Loss: 0.04158508777618408\n",
      "Epoch 50, Loss: 0.016741350293159485\n",
      "Epoch 51, Loss: 0.05073399841785431\n",
      "Epoch 52, Loss: 0.018101997673511505\n",
      "Epoch 53, Loss: 0.04422835633158684\n",
      "Epoch 54, Loss: 0.022356729954481125\n",
      "Epoch 55, Loss: 0.015357496216893196\n",
      "Epoch 56, Loss: 0.03238053247332573\n",
      "Epoch 57, Loss: 0.0202113576233387\n",
      "Epoch 58, Loss: 0.04901958629488945\n",
      "Epoch 59, Loss: 0.059627898037433624\n",
      "Epoch 60, Loss: 0.019810102880001068\n",
      "Epoch 61, Loss: 0.010126065462827682\n",
      "Epoch 62, Loss: 0.04669124633073807\n",
      "Epoch 63, Loss: 0.03954248130321503\n",
      "Epoch 64, Loss: 0.011227669194340706\n",
      "Epoch 65, Loss: 0.011881211772561073\n",
      "Epoch 66, Loss: 0.015630921348929405\n",
      "Epoch 67, Loss: 0.02435976453125477\n",
      "Epoch 68, Loss: 0.026874292641878128\n",
      "Epoch 69, Loss: 0.016939371824264526\n",
      "Epoch 70, Loss: 0.14723563194274902\n",
      "Epoch 71, Loss: 0.013508754782378674\n",
      "Epoch 72, Loss: 0.005623336881399155\n",
      "Epoch 73, Loss: 0.023188089951872826\n",
      "Epoch 74, Loss: 0.01689031533896923\n",
      "Epoch 75, Loss: 0.008041046559810638\n",
      "Epoch 76, Loss: 0.04062575101852417\n",
      "Epoch 77, Loss: 0.018860194832086563\n",
      "Epoch 78, Loss: 0.02234271541237831\n",
      "Epoch 79, Loss: 0.011085405945777893\n",
      "Epoch 80, Loss: 0.04141830652952194\n",
      "Epoch 81, Loss: 0.0083094397559762\n",
      "Epoch 82, Loss: 0.005690565798431635\n",
      "Epoch 83, Loss: 0.009554322808980942\n",
      "Epoch 84, Loss: 0.02219141088426113\n",
      "Epoch 85, Loss: 0.018288277089595795\n",
      "Epoch 86, Loss: 0.016416998580098152\n",
      "Epoch 87, Loss: 0.010262731462717056\n",
      "Epoch 88, Loss: 0.008059639483690262\n",
      "Epoch 89, Loss: 0.007025493308901787\n",
      "Epoch 90, Loss: 0.00908927246928215\n",
      "Epoch 91, Loss: 0.009485847316682339\n",
      "Epoch 92, Loss: 0.010956931859254837\n",
      "Epoch 93, Loss: 0.021016402170062065\n",
      "Epoch 94, Loss: 0.01377175748348236\n",
      "Epoch 95, Loss: 0.005454997532069683\n",
      "Epoch 96, Loss: 0.010255617089569569\n",
      "Epoch 97, Loss: 0.010025626979768276\n",
      "Epoch 98, Loss: 0.010206464678049088\n",
      "Epoch 99, Loss: 0.010968503542244434\n",
      "Epoch 100, Loss: 0.011936694383621216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.386162281036377\n",
      "Epoch 1, Loss: 0.5450057983398438\n",
      "Epoch 2, Loss: 0.9955669045448303\n",
      "Epoch 3, Loss: 0.3994830846786499\n",
      "Epoch 4, Loss: 0.6609759330749512\n",
      "Epoch 5, Loss: 0.7784177660942078\n",
      "Epoch 6, Loss: 0.4522574245929718\n",
      "Epoch 7, Loss: 0.5921516418457031\n",
      "Epoch 8, Loss: 0.38850682973861694\n",
      "Epoch 9, Loss: 0.3060351014137268\n",
      "Epoch 10, Loss: 0.14689002931118011\n",
      "Epoch 11, Loss: 0.37616482377052307\n",
      "Epoch 12, Loss: 0.4361293911933899\n",
      "Epoch 13, Loss: 0.2941215932369232\n",
      "Epoch 14, Loss: 0.17695650458335876\n",
      "Epoch 15, Loss: 0.20914596319198608\n",
      "Epoch 16, Loss: 0.22300158441066742\n",
      "Epoch 17, Loss: 0.40989622473716736\n",
      "Epoch 18, Loss: 0.265945702791214\n",
      "Epoch 19, Loss: 0.1594000607728958\n",
      "Epoch 20, Loss: 0.166142538189888\n",
      "Epoch 21, Loss: 0.11060772836208344\n",
      "Epoch 22, Loss: 0.24210603535175323\n",
      "Epoch 23, Loss: 0.14396518468856812\n",
      "Epoch 24, Loss: 0.13079407811164856\n",
      "Epoch 25, Loss: 0.1010349839925766\n",
      "Epoch 26, Loss: 0.10328997671604156\n",
      "Epoch 27, Loss: 0.128803551197052\n",
      "Epoch 28, Loss: 0.10121769458055496\n",
      "Epoch 29, Loss: 0.10437767207622528\n",
      "Epoch 30, Loss: 0.05952974036335945\n",
      "Epoch 31, Loss: 0.08269913494586945\n",
      "Epoch 32, Loss: 0.0641530305147171\n",
      "Epoch 33, Loss: 0.17487169802188873\n",
      "Epoch 34, Loss: 0.05379950627684593\n",
      "Epoch 35, Loss: 0.09717210382223129\n",
      "Epoch 36, Loss: 0.05422443896532059\n",
      "Epoch 37, Loss: 0.029134860262274742\n",
      "Epoch 38, Loss: 0.05572479963302612\n",
      "Epoch 39, Loss: 0.09467986226081848\n",
      "Epoch 40, Loss: 0.06656516343355179\n",
      "Epoch 41, Loss: 0.07635317742824554\n",
      "Epoch 42, Loss: 0.05824349820613861\n",
      "Epoch 43, Loss: 0.06604757905006409\n",
      "Epoch 44, Loss: 0.03642406314611435\n",
      "Epoch 45, Loss: 0.05837026610970497\n",
      "Epoch 46, Loss: 0.03724057972431183\n",
      "Epoch 47, Loss: 0.012675768695771694\n",
      "Epoch 48, Loss: 0.023364581167697906\n",
      "Epoch 49, Loss: 0.06666405498981476\n",
      "Epoch 50, Loss: 0.03661655634641647\n",
      "Epoch 51, Loss: 0.08097699284553528\n",
      "Epoch 52, Loss: 0.015174665488302708\n",
      "Epoch 53, Loss: 0.03002391941845417\n",
      "Epoch 54, Loss: 0.015607126988470554\n",
      "Epoch 55, Loss: 0.044782817363739014\n",
      "Epoch 56, Loss: 0.023314476013183594\n",
      "Epoch 57, Loss: 0.020877817645668983\n",
      "Epoch 58, Loss: 0.011063574813306332\n",
      "Epoch 59, Loss: 0.036578670144081116\n",
      "Epoch 60, Loss: 0.024606719613075256\n",
      "Epoch 61, Loss: 0.04007258638739586\n",
      "Epoch 62, Loss: 0.038358937948942184\n",
      "Epoch 63, Loss: 0.016313396394252777\n",
      "Epoch 64, Loss: 0.024538561701774597\n",
      "Epoch 65, Loss: 0.011579695157706738\n",
      "Epoch 66, Loss: 0.019358256831765175\n",
      "Epoch 67, Loss: 0.01966945081949234\n",
      "Epoch 68, Loss: 0.02384464628994465\n",
      "Epoch 69, Loss: 0.03391173854470253\n",
      "Epoch 70, Loss: 0.032777972519397736\n",
      "Epoch 71, Loss: 0.04391990602016449\n",
      "Epoch 72, Loss: 0.03862488642334938\n",
      "Epoch 73, Loss: 0.009347530081868172\n",
      "Epoch 74, Loss: 0.013959760777652264\n",
      "Epoch 75, Loss: 0.005379669833928347\n",
      "Epoch 76, Loss: 0.03460109606385231\n",
      "Epoch 77, Loss: 0.008614606224000454\n",
      "Epoch 78, Loss: 0.012571717612445354\n",
      "Epoch 79, Loss: 0.014864888042211533\n",
      "Epoch 80, Loss: 0.01664867252111435\n",
      "Epoch 81, Loss: 0.04586242139339447\n",
      "Epoch 82, Loss: 0.017780201509594917\n",
      "Epoch 83, Loss: 0.011266817338764668\n",
      "Epoch 84, Loss: 0.0422428697347641\n",
      "Epoch 85, Loss: 0.010267035104334354\n",
      "Epoch 86, Loss: 0.013336490839719772\n",
      "Epoch 87, Loss: 0.010683262720704079\n",
      "Epoch 88, Loss: 0.007970969192683697\n",
      "Epoch 89, Loss: 0.006188615225255489\n",
      "Epoch 90, Loss: 0.026651401072740555\n",
      "Epoch 91, Loss: 0.02050895243883133\n",
      "Epoch 92, Loss: 0.024544797837734222\n",
      "Epoch 93, Loss: 0.0121017936617136\n",
      "Epoch 94, Loss: 0.00524156354367733\n",
      "Epoch 95, Loss: 0.008484498597681522\n",
      "Epoch 96, Loss: 0.006035436876118183\n",
      "Epoch 97, Loss: 0.015257556922733784\n",
      "Epoch 98, Loss: 0.05948442220687866\n",
      "Epoch 99, Loss: 0.07532346248626709\n",
      "Epoch 100, Loss: 0.0050958432257175446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.4278994798660278\n",
      "Epoch 1, Loss: 0.581213116645813\n",
      "Epoch 2, Loss: 0.6736035943031311\n",
      "Epoch 3, Loss: 0.523436427116394\n",
      "Epoch 4, Loss: 0.28699323534965515\n",
      "Epoch 5, Loss: 0.41190260648727417\n",
      "Epoch 6, Loss: 0.39243656396865845\n",
      "Epoch 7, Loss: 1.137006163597107\n",
      "Epoch 8, Loss: 0.4230699837207794\n",
      "Epoch 9, Loss: 0.4485645294189453\n",
      "Epoch 10, Loss: 0.20024102926254272\n",
      "Epoch 11, Loss: 0.704883873462677\n",
      "Epoch 12, Loss: 0.7989715337753296\n",
      "Epoch 13, Loss: 0.44657495617866516\n",
      "Epoch 14, Loss: 0.5623582601547241\n",
      "Epoch 15, Loss: 0.3214205801486969\n",
      "Epoch 16, Loss: 0.15477396547794342\n",
      "Epoch 17, Loss: 0.35548293590545654\n",
      "Epoch 18, Loss: 0.18641111254692078\n",
      "Epoch 19, Loss: 0.14939171075820923\n",
      "Epoch 20, Loss: 0.09916751086711884\n",
      "Epoch 21, Loss: 0.2706928253173828\n",
      "Epoch 22, Loss: 0.1824595332145691\n",
      "Epoch 23, Loss: 0.12689010798931122\n",
      "Epoch 24, Loss: 0.09859587997198105\n",
      "Epoch 25, Loss: 0.33555054664611816\n",
      "Epoch 26, Loss: 0.2520406246185303\n",
      "Epoch 27, Loss: 0.27504509687423706\n",
      "Epoch 28, Loss: 0.07999534904956818\n",
      "Epoch 29, Loss: 0.08978218585252762\n",
      "Epoch 30, Loss: 0.2155216485261917\n",
      "Epoch 31, Loss: 0.03581489995121956\n",
      "Epoch 32, Loss: 0.1601247638463974\n",
      "Epoch 33, Loss: 0.06428012996912003\n",
      "Epoch 34, Loss: 0.15748630464076996\n",
      "Epoch 35, Loss: 0.11072761565446854\n",
      "Epoch 36, Loss: 0.14419075846672058\n",
      "Epoch 37, Loss: 0.15299564599990845\n",
      "Epoch 38, Loss: 0.05845383182168007\n",
      "Epoch 39, Loss: 0.04590975493192673\n",
      "Epoch 40, Loss: 0.09643509984016418\n",
      "Epoch 41, Loss: 0.027897987514734268\n",
      "Epoch 42, Loss: 0.07372473925352097\n",
      "Epoch 43, Loss: 0.0619436651468277\n",
      "Epoch 44, Loss: 0.07488224655389786\n",
      "Epoch 45, Loss: 0.05059833079576492\n",
      "Epoch 46, Loss: 0.07695632427930832\n",
      "Epoch 47, Loss: 0.02946440689265728\n",
      "Epoch 48, Loss: 0.07964113354682922\n",
      "Epoch 49, Loss: 0.03482714295387268\n",
      "Epoch 50, Loss: 0.02943936362862587\n",
      "Epoch 51, Loss: 0.03500548005104065\n",
      "Epoch 52, Loss: 0.018392855301499367\n",
      "Epoch 53, Loss: 0.032471392303705215\n",
      "Epoch 54, Loss: 0.02660701423883438\n",
      "Epoch 55, Loss: 0.03763788938522339\n",
      "Epoch 56, Loss: 0.06911090016365051\n",
      "Epoch 57, Loss: 0.027442561462521553\n",
      "Epoch 58, Loss: 0.028598465025424957\n",
      "Epoch 59, Loss: 0.010899378918111324\n",
      "Epoch 60, Loss: 0.026996741071343422\n",
      "Epoch 61, Loss: 0.03156020864844322\n",
      "Epoch 62, Loss: 0.018005328252911568\n",
      "Epoch 63, Loss: 0.015596394427120686\n",
      "Epoch 64, Loss: 0.00807517021894455\n",
      "Epoch 65, Loss: 0.13548588752746582\n",
      "Epoch 66, Loss: 0.057365432381629944\n",
      "Epoch 67, Loss: 0.018703069537878036\n",
      "Epoch 68, Loss: 0.01075939740985632\n",
      "Epoch 69, Loss: 0.019541122019290924\n",
      "Epoch 70, Loss: 0.016912328079342842\n",
      "Epoch 71, Loss: 0.01582929491996765\n",
      "Epoch 72, Loss: 0.01668453961610794\n",
      "Epoch 73, Loss: 0.03837508708238602\n",
      "Epoch 74, Loss: 0.011445747688412666\n",
      "Epoch 75, Loss: 0.012663369998335838\n",
      "Epoch 76, Loss: 0.043112825602293015\n",
      "Epoch 77, Loss: 0.009612717665731907\n",
      "Epoch 78, Loss: 0.00984288938343525\n",
      "Epoch 79, Loss: 0.03751969709992409\n",
      "Epoch 80, Loss: 0.010493326932191849\n",
      "Epoch 81, Loss: 0.01230377983301878\n",
      "Epoch 82, Loss: 0.018814081326127052\n",
      "Epoch 83, Loss: 0.012772218324244022\n",
      "Epoch 84, Loss: 0.010968045331537724\n",
      "Epoch 85, Loss: 0.006936549674719572\n",
      "Epoch 86, Loss: 0.04557941481471062\n",
      "Epoch 87, Loss: 0.011585451662540436\n",
      "Epoch 88, Loss: 0.014302490279078484\n",
      "Epoch 89, Loss: 0.011891585774719715\n",
      "Epoch 90, Loss: 0.016021551564335823\n",
      "Epoch 91, Loss: 0.012563329190015793\n",
      "Epoch 92, Loss: 0.022201057523489\n",
      "Epoch 93, Loss: 0.008404385298490524\n",
      "Epoch 94, Loss: 0.01031308900564909\n",
      "Epoch 95, Loss: 0.0271796565502882\n",
      "Epoch 96, Loss: 0.012857739813625813\n",
      "Epoch 97, Loss: 0.016199015080928802\n",
      "Epoch 98, Loss: 0.010599199682474136\n",
      "Epoch 99, Loss: 0.0070701902732253075\n",
      "Epoch 100, Loss: 0.013998465612530708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.4206926822662354\n",
      "Epoch 1, Loss: 1.0662201642990112\n",
      "Epoch 2, Loss: 0.33703675866127014\n",
      "Epoch 3, Loss: 0.57843416929245\n",
      "Epoch 4, Loss: 0.32421961426734924\n",
      "Epoch 5, Loss: 0.29452797770500183\n",
      "Epoch 6, Loss: 0.3069581687450409\n",
      "Epoch 7, Loss: 0.2549951374530792\n",
      "Epoch 8, Loss: 0.2316899299621582\n",
      "Epoch 9, Loss: 0.9155910015106201\n",
      "Epoch 10, Loss: 0.24772818386554718\n",
      "Epoch 11, Loss: 0.24907316267490387\n",
      "Epoch 12, Loss: 0.3962443172931671\n",
      "Epoch 13, Loss: 0.3605239689350128\n",
      "Epoch 14, Loss: 0.20598824322223663\n",
      "Epoch 15, Loss: 0.4698910117149353\n",
      "Epoch 16, Loss: 0.22016282379627228\n",
      "Epoch 17, Loss: 0.17335551977157593\n",
      "Epoch 18, Loss: 0.14220207929611206\n",
      "Epoch 19, Loss: 0.21837422251701355\n",
      "Epoch 20, Loss: 0.08542552590370178\n",
      "Epoch 21, Loss: 0.09530159831047058\n",
      "Epoch 22, Loss: 0.06363746523857117\n",
      "Epoch 23, Loss: 0.11678291857242584\n",
      "Epoch 24, Loss: 0.13636644184589386\n",
      "Epoch 25, Loss: 0.08538343012332916\n",
      "Epoch 26, Loss: 0.06702908873558044\n",
      "Epoch 27, Loss: 0.09851238131523132\n",
      "Epoch 28, Loss: 0.09641722589731216\n",
      "Epoch 29, Loss: 0.07841479778289795\n",
      "Epoch 30, Loss: 0.12936529517173767\n",
      "Epoch 31, Loss: 0.039803244173526764\n",
      "Epoch 32, Loss: 0.0372457429766655\n",
      "Epoch 33, Loss: 0.047908131033182144\n",
      "Epoch 34, Loss: 0.08938857913017273\n",
      "Epoch 35, Loss: 0.06995503604412079\n",
      "Epoch 36, Loss: 0.045095451176166534\n",
      "Epoch 37, Loss: 0.06248892843723297\n",
      "Epoch 38, Loss: 0.05388351529836655\n",
      "Epoch 39, Loss: 0.03750491887331009\n",
      "Epoch 40, Loss: 0.050231512635946274\n",
      "Epoch 41, Loss: 0.044083282351493835\n",
      "Epoch 42, Loss: 0.04119866341352463\n",
      "Epoch 43, Loss: 0.10533229261636734\n",
      "Epoch 44, Loss: 0.08086290955543518\n",
      "Epoch 45, Loss: 0.05564984306693077\n",
      "Epoch 46, Loss: 0.01913071982562542\n",
      "Epoch 47, Loss: 0.016254223883152008\n",
      "Epoch 48, Loss: 0.02292189933359623\n",
      "Epoch 49, Loss: 0.024641675874590874\n",
      "Epoch 50, Loss: 0.019361380487680435\n",
      "Epoch 51, Loss: 0.041614972054958344\n",
      "Epoch 52, Loss: 0.05389272794127464\n",
      "Epoch 53, Loss: 0.023272216320037842\n",
      "Epoch 54, Loss: 0.035410281270742416\n",
      "Epoch 55, Loss: 0.023667626082897186\n",
      "Epoch 56, Loss: 0.03205644711852074\n",
      "Epoch 57, Loss: 0.018959246575832367\n",
      "Epoch 58, Loss: 0.020314017310738564\n",
      "Epoch 59, Loss: 0.022334108129143715\n",
      "Epoch 60, Loss: 0.025209246203303337\n",
      "Epoch 61, Loss: 0.01047380268573761\n",
      "Epoch 62, Loss: 0.06462058424949646\n",
      "Epoch 63, Loss: 0.010334369726479053\n",
      "Epoch 64, Loss: 0.014768128283321857\n",
      "Epoch 65, Loss: 0.0694732666015625\n",
      "Epoch 66, Loss: 0.012253785505890846\n",
      "Epoch 67, Loss: 0.01958240009844303\n",
      "Epoch 68, Loss: 0.012100789695978165\n",
      "Epoch 69, Loss: 0.010626938194036484\n",
      "Epoch 70, Loss: 0.006779585033655167\n",
      "Epoch 71, Loss: 0.01281275600194931\n",
      "Epoch 72, Loss: 0.017056511715054512\n",
      "Epoch 73, Loss: 0.05889609083533287\n",
      "Epoch 74, Loss: 0.01015564426779747\n",
      "Epoch 75, Loss: 0.022504813969135284\n",
      "Epoch 76, Loss: 0.02382020652294159\n",
      "Epoch 77, Loss: 0.01115049235522747\n",
      "Epoch 78, Loss: 0.01588725484907627\n",
      "Epoch 79, Loss: 0.012003247626125813\n",
      "Epoch 80, Loss: 0.017441004514694214\n",
      "Epoch 81, Loss: 0.008574108593165874\n",
      "Epoch 82, Loss: 0.006226314231753349\n",
      "Epoch 83, Loss: 0.01799517497420311\n",
      "Epoch 84, Loss: 0.01778166927397251\n",
      "Epoch 85, Loss: 0.0155965406447649\n",
      "Epoch 86, Loss: 0.00902281329035759\n",
      "Epoch 87, Loss: 0.00724351592361927\n",
      "Epoch 88, Loss: 0.0032251395750790834\n",
      "Epoch 89, Loss: 0.010133516043424606\n",
      "Epoch 90, Loss: 0.007909142412245274\n",
      "Epoch 91, Loss: 0.011234638281166553\n",
      "Epoch 92, Loss: 0.007810445502400398\n",
      "Epoch 93, Loss: 0.009221329353749752\n",
      "Epoch 94, Loss: 0.0423729382455349\n",
      "Epoch 95, Loss: 0.0020910988096147776\n",
      "Epoch 96, Loss: 0.0024625526275485754\n",
      "Epoch 97, Loss: 0.010492876172065735\n",
      "Epoch 98, Loss: 0.00515279546380043\n",
      "Epoch 99, Loss: 0.01064508780837059\n",
      "Epoch 100, Loss: 0.006395977456122637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3116719722747803\n",
      "Epoch 1, Loss: 0.4209580421447754\n",
      "Epoch 2, Loss: 0.4919634461402893\n",
      "Epoch 3, Loss: 0.7105804681777954\n",
      "Epoch 4, Loss: 0.9476253986358643\n",
      "Epoch 5, Loss: 0.36469364166259766\n",
      "Epoch 6, Loss: 0.5065385699272156\n",
      "Epoch 7, Loss: 0.872204065322876\n",
      "Epoch 8, Loss: 0.5986192226409912\n",
      "Epoch 9, Loss: 0.45424938201904297\n",
      "Epoch 10, Loss: 0.5397790670394897\n",
      "Epoch 11, Loss: 0.42402487993240356\n",
      "Epoch 12, Loss: 0.283675879240036\n",
      "Epoch 13, Loss: 0.15833331644535065\n",
      "Epoch 14, Loss: 0.4410910904407501\n",
      "Epoch 15, Loss: 0.45596086978912354\n",
      "Epoch 16, Loss: 0.16710008680820465\n",
      "Epoch 17, Loss: 0.1822158247232437\n",
      "Epoch 18, Loss: 0.21498318016529083\n",
      "Epoch 19, Loss: 0.2536052167415619\n",
      "Epoch 20, Loss: 0.2034989595413208\n",
      "Epoch 21, Loss: 0.11818722635507584\n",
      "Epoch 22, Loss: 0.1150088831782341\n",
      "Epoch 23, Loss: 0.13905304670333862\n",
      "Epoch 24, Loss: 0.1425897479057312\n",
      "Epoch 25, Loss: 0.1194017305970192\n",
      "Epoch 26, Loss: 0.023753823712468147\n",
      "Epoch 27, Loss: 0.05866976082324982\n",
      "Epoch 28, Loss: 0.06299065798521042\n",
      "Epoch 29, Loss: 0.11514099687337875\n",
      "Epoch 30, Loss: 0.05652378499507904\n",
      "Epoch 31, Loss: 0.06868238002061844\n",
      "Epoch 32, Loss: 0.13544239103794098\n",
      "Epoch 33, Loss: 0.1430855691432953\n",
      "Epoch 34, Loss: 0.044692955911159515\n",
      "Epoch 35, Loss: 0.111959308385849\n",
      "Epoch 36, Loss: 0.05972674861550331\n",
      "Epoch 37, Loss: 0.07407679408788681\n",
      "Epoch 38, Loss: 0.058117423206567764\n",
      "Epoch 39, Loss: 0.04625597596168518\n",
      "Epoch 40, Loss: 0.058072347193956375\n",
      "Epoch 41, Loss: 0.055890042334795\n",
      "Epoch 42, Loss: 0.04464784637093544\n",
      "Epoch 43, Loss: 0.07055234909057617\n",
      "Epoch 44, Loss: 0.03629783168435097\n",
      "Epoch 45, Loss: 0.024960609152913094\n",
      "Epoch 46, Loss: 0.014483858831226826\n",
      "Epoch 47, Loss: 0.035267286002635956\n",
      "Epoch 48, Loss: 0.1991259604692459\n",
      "Epoch 49, Loss: 0.04424761235713959\n",
      "Epoch 50, Loss: 0.08174939453601837\n",
      "Epoch 51, Loss: 0.058156244456768036\n",
      "Epoch 52, Loss: 0.01415446400642395\n",
      "Epoch 53, Loss: 0.027558626607060432\n",
      "Epoch 54, Loss: 0.03436523303389549\n",
      "Epoch 55, Loss: 0.06601371616125107\n",
      "Epoch 56, Loss: 0.012066877447068691\n",
      "Epoch 57, Loss: 0.0355127789080143\n",
      "Epoch 58, Loss: 0.012610804289579391\n",
      "Epoch 59, Loss: 0.006243204697966576\n",
      "Epoch 60, Loss: 0.040697112679481506\n",
      "Epoch 61, Loss: 0.01471248921006918\n",
      "Epoch 62, Loss: 0.012581494636833668\n",
      "Epoch 63, Loss: 0.02606387622654438\n",
      "Epoch 64, Loss: 0.01326759159564972\n",
      "Epoch 65, Loss: 0.01206580176949501\n",
      "Epoch 66, Loss: 0.0315108522772789\n",
      "Epoch 67, Loss: 0.026752952486276627\n",
      "Epoch 68, Loss: 0.007415244355797768\n",
      "Epoch 69, Loss: 0.01273416355252266\n",
      "Epoch 70, Loss: 0.021578455343842506\n",
      "Epoch 71, Loss: 0.01182179432362318\n",
      "Epoch 72, Loss: 0.02380521036684513\n",
      "Epoch 73, Loss: 0.015524756163358688\n",
      "Epoch 74, Loss: 0.024991042912006378\n",
      "Epoch 75, Loss: 0.017493529245257378\n",
      "Epoch 76, Loss: 0.015313370153307915\n",
      "Epoch 77, Loss: 0.013316284865140915\n",
      "Epoch 78, Loss: 0.011632751673460007\n",
      "Epoch 79, Loss: 0.01835458353161812\n",
      "Epoch 80, Loss: 0.005579820368438959\n",
      "Epoch 81, Loss: 0.012381375767290592\n",
      "Epoch 82, Loss: 0.009593459777534008\n",
      "Epoch 83, Loss: 0.010472692549228668\n",
      "Epoch 84, Loss: 0.008614777587354183\n",
      "Epoch 85, Loss: 0.034902043640613556\n",
      "Epoch 86, Loss: 0.009747926145792007\n",
      "Epoch 87, Loss: 0.01094068679958582\n",
      "Epoch 88, Loss: 0.009655923582613468\n",
      "Epoch 89, Loss: 0.009432423859834671\n",
      "Epoch 90, Loss: 0.008232670836150646\n",
      "Epoch 91, Loss: 0.00703970342874527\n",
      "Epoch 92, Loss: 0.0061662509106099606\n",
      "Epoch 93, Loss: 0.013453260064125061\n",
      "Epoch 94, Loss: 0.0071256691589951515\n",
      "Epoch 95, Loss: 0.005660850089043379\n",
      "Epoch 96, Loss: 0.011816699057817459\n",
      "Epoch 97, Loss: 0.005469279829412699\n",
      "Epoch 98, Loss: 0.00602913461625576\n",
      "Epoch 99, Loss: 0.00820445641875267\n",
      "Epoch 100, Loss: 0.005574965383857489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.2966245412826538\n",
      "Epoch 1, Loss: 1.090780258178711\n",
      "Epoch 2, Loss: 0.6412360668182373\n",
      "Epoch 3, Loss: 0.6847606897354126\n",
      "Epoch 4, Loss: 0.5322868824005127\n",
      "Epoch 5, Loss: 0.2663740813732147\n",
      "Epoch 6, Loss: 0.39457210898399353\n",
      "Epoch 7, Loss: 0.16638614237308502\n",
      "Epoch 8, Loss: 0.349025160074234\n",
      "Epoch 9, Loss: 0.3677835762500763\n",
      "Epoch 10, Loss: 0.4536168873310089\n",
      "Epoch 11, Loss: 0.2587782144546509\n",
      "Epoch 12, Loss: 0.2140868455171585\n",
      "Epoch 13, Loss: 0.33342087268829346\n",
      "Epoch 14, Loss: 0.3143352270126343\n",
      "Epoch 15, Loss: 0.25590980052948\n",
      "Epoch 16, Loss: 0.12996520102024078\n",
      "Epoch 17, Loss: 0.3523561656475067\n",
      "Epoch 18, Loss: 0.2063605636358261\n",
      "Epoch 19, Loss: 0.32374200224876404\n",
      "Epoch 20, Loss: 0.1514279842376709\n",
      "Epoch 21, Loss: 0.281546413898468\n",
      "Epoch 22, Loss: 0.13687175512313843\n",
      "Epoch 23, Loss: 0.20196646451950073\n",
      "Epoch 24, Loss: 0.11552533507347107\n",
      "Epoch 25, Loss: 0.17967253923416138\n",
      "Epoch 26, Loss: 0.2038704752922058\n",
      "Epoch 27, Loss: 0.16974131762981415\n",
      "Epoch 28, Loss: 0.17794373631477356\n",
      "Epoch 29, Loss: 0.1453821212053299\n",
      "Epoch 30, Loss: 0.11080088466405869\n",
      "Epoch 31, Loss: 0.11982805281877518\n",
      "Epoch 32, Loss: 0.18446125090122223\n",
      "Epoch 33, Loss: 0.09540777653455734\n",
      "Epoch 34, Loss: 0.13748648762702942\n",
      "Epoch 35, Loss: 0.021810926496982574\n",
      "Epoch 36, Loss: 0.10452573746442795\n",
      "Epoch 37, Loss: 0.05491868779063225\n",
      "Epoch 38, Loss: 0.0951460748910904\n",
      "Epoch 39, Loss: 0.05215723440051079\n",
      "Epoch 40, Loss: 0.13288423418998718\n",
      "Epoch 41, Loss: 0.03123822808265686\n",
      "Epoch 42, Loss: 0.06036624684929848\n",
      "Epoch 43, Loss: 0.09186584502458572\n",
      "Epoch 44, Loss: 0.03589355945587158\n",
      "Epoch 45, Loss: 0.02359599433839321\n",
      "Epoch 46, Loss: 0.05074714124202728\n",
      "Epoch 47, Loss: 0.01826172135770321\n",
      "Epoch 48, Loss: 0.10883123427629471\n",
      "Epoch 49, Loss: 0.0759294405579567\n",
      "Epoch 50, Loss: 0.024001918733119965\n",
      "Epoch 51, Loss: 0.018326878547668457\n",
      "Epoch 52, Loss: 0.0508626252412796\n",
      "Epoch 53, Loss: 0.031675346195697784\n",
      "Epoch 54, Loss: 0.038754113018512726\n",
      "Epoch 55, Loss: 0.025835102424025536\n",
      "Epoch 56, Loss: 0.046251330524683\n",
      "Epoch 57, Loss: 0.025357143953442574\n",
      "Epoch 58, Loss: 0.0091211823746562\n",
      "Epoch 59, Loss: 0.012041192501783371\n",
      "Epoch 60, Loss: 0.02019343338906765\n",
      "Epoch 61, Loss: 0.024066269397735596\n",
      "Epoch 62, Loss: 0.024692093953490257\n",
      "Epoch 63, Loss: 0.05680755153298378\n",
      "Epoch 64, Loss: 0.043751731514930725\n",
      "Epoch 65, Loss: 0.10373282432556152\n",
      "Epoch 66, Loss: 0.03250638023018837\n",
      "Epoch 67, Loss: 0.02811460755765438\n",
      "Epoch 68, Loss: 0.011427827179431915\n",
      "Epoch 69, Loss: 0.00922255590558052\n",
      "Epoch 70, Loss: 0.022080648690462112\n",
      "Epoch 71, Loss: 0.010146688669919968\n",
      "Epoch 72, Loss: 0.021324951201677322\n",
      "Epoch 73, Loss: 0.0164394062012434\n",
      "Epoch 74, Loss: 0.018867792561650276\n",
      "Epoch 75, Loss: 0.02018870785832405\n",
      "Epoch 76, Loss: 0.01892888732254505\n",
      "Epoch 77, Loss: 0.011011490598320961\n",
      "Epoch 78, Loss: 0.01612403243780136\n",
      "Epoch 79, Loss: 0.016074560582637787\n",
      "Epoch 80, Loss: 0.013313516974449158\n",
      "Epoch 81, Loss: 0.015140091069042683\n",
      "Epoch 82, Loss: 0.03147132694721222\n",
      "Epoch 83, Loss: 0.008177313022315502\n",
      "Epoch 84, Loss: 0.01693473383784294\n",
      "Epoch 85, Loss: 0.015108519233763218\n",
      "Epoch 86, Loss: 0.025600137189030647\n",
      "Epoch 87, Loss: 0.012790865264832973\n",
      "Epoch 88, Loss: 0.010634216479957104\n",
      "Epoch 89, Loss: 0.004526080098003149\n",
      "Epoch 90, Loss: 0.013156045228242874\n",
      "Epoch 91, Loss: 0.01053853239864111\n",
      "Epoch 92, Loss: 0.011182614602148533\n",
      "Epoch 93, Loss: 0.025476055219769478\n",
      "Epoch 94, Loss: 0.06186811625957489\n",
      "Epoch 95, Loss: 0.012910380959510803\n",
      "Epoch 96, Loss: 0.012462271377444267\n",
      "Epoch 97, Loss: 0.01115483045578003\n",
      "Epoch 98, Loss: 0.008962691761553288\n",
      "Epoch 99, Loss: 0.015068724751472473\n",
      "Epoch 100, Loss: 0.011419851332902908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3976976871490479\n",
      "Epoch 1, Loss: 0.2808972895145416\n",
      "Epoch 2, Loss: 0.7241134643554688\n",
      "Epoch 3, Loss: 0.7203559279441833\n",
      "Epoch 4, Loss: 0.39941850304603577\n",
      "Epoch 5, Loss: 1.0886220932006836\n",
      "Epoch 6, Loss: 0.4324190616607666\n",
      "Epoch 7, Loss: 0.45854324102401733\n",
      "Epoch 8, Loss: 0.29263603687286377\n",
      "Epoch 9, Loss: 0.3699396550655365\n",
      "Epoch 10, Loss: 0.2124297171831131\n",
      "Epoch 11, Loss: 0.6176930665969849\n",
      "Epoch 12, Loss: 0.3224768042564392\n",
      "Epoch 13, Loss: 0.13614535331726074\n",
      "Epoch 14, Loss: 0.22495706379413605\n",
      "Epoch 15, Loss: 0.22913455963134766\n",
      "Epoch 16, Loss: 0.27772393822669983\n",
      "Epoch 17, Loss: 0.4092637300491333\n",
      "Epoch 18, Loss: 0.3878820836544037\n",
      "Epoch 19, Loss: 0.2839179039001465\n",
      "Epoch 20, Loss: 0.15153199434280396\n",
      "Epoch 21, Loss: 0.24122725427150726\n",
      "Epoch 22, Loss: 0.29692214727401733\n",
      "Epoch 23, Loss: 0.07722233235836029\n",
      "Epoch 24, Loss: 0.24850961565971375\n",
      "Epoch 25, Loss: 0.0745154470205307\n",
      "Epoch 26, Loss: 0.09447724372148514\n",
      "Epoch 27, Loss: 0.07057608664035797\n",
      "Epoch 28, Loss: 0.09888222813606262\n",
      "Epoch 29, Loss: 0.0723344013094902\n",
      "Epoch 30, Loss: 0.07799920439720154\n",
      "Epoch 31, Loss: 0.059296563267707825\n",
      "Epoch 32, Loss: 0.07578223198652267\n",
      "Epoch 33, Loss: 0.18701587617397308\n",
      "Epoch 34, Loss: 0.0584966205060482\n",
      "Epoch 35, Loss: 0.08010973036289215\n",
      "Epoch 36, Loss: 0.04346559941768646\n",
      "Epoch 37, Loss: 0.03353908658027649\n",
      "Epoch 38, Loss: 0.04865357652306557\n",
      "Epoch 39, Loss: 0.04437863081693649\n",
      "Epoch 40, Loss: 0.039038702845573425\n",
      "Epoch 41, Loss: 0.05354693904519081\n",
      "Epoch 42, Loss: 0.07329628616571426\n",
      "Epoch 43, Loss: 0.028836555778980255\n",
      "Epoch 44, Loss: 0.04140380769968033\n",
      "Epoch 45, Loss: 0.015019570477306843\n",
      "Epoch 46, Loss: 0.01613050512969494\n",
      "Epoch 47, Loss: 0.03604975715279579\n",
      "Epoch 48, Loss: 0.018095800653100014\n",
      "Epoch 49, Loss: 0.03235628455877304\n",
      "Epoch 50, Loss: 0.0150984525680542\n",
      "Epoch 51, Loss: 0.029060257598757744\n",
      "Epoch 52, Loss: 0.03631990775465965\n",
      "Epoch 53, Loss: 0.01909070834517479\n",
      "Epoch 54, Loss: 0.027254289016127586\n",
      "Epoch 55, Loss: 0.010344316251575947\n",
      "Epoch 56, Loss: 0.018127286806702614\n",
      "Epoch 57, Loss: 0.013269067741930485\n",
      "Epoch 58, Loss: 0.006013218779116869\n",
      "Epoch 59, Loss: 0.009712468832731247\n",
      "Epoch 60, Loss: 0.02060968615114689\n",
      "Epoch 61, Loss: 0.016710054129362106\n",
      "Epoch 62, Loss: 0.005886802449822426\n",
      "Epoch 63, Loss: 0.014963658526539803\n",
      "Epoch 64, Loss: 0.055447228252887726\n",
      "Epoch 65, Loss: 0.01255889143794775\n",
      "Epoch 66, Loss: 0.018186787143349648\n",
      "Epoch 67, Loss: 0.014251924119889736\n",
      "Epoch 68, Loss: 0.024594508111476898\n",
      "Epoch 69, Loss: 0.012612570077180862\n",
      "Epoch 70, Loss: 0.008417130447924137\n",
      "Epoch 71, Loss: 0.011824767105281353\n",
      "Epoch 72, Loss: 0.015419433824717999\n",
      "Epoch 73, Loss: 0.01085446123033762\n",
      "Epoch 74, Loss: 0.011386943981051445\n",
      "Epoch 75, Loss: 0.01289726048707962\n",
      "Epoch 76, Loss: 0.0192243792116642\n",
      "Epoch 77, Loss: 0.005113957915455103\n",
      "Epoch 78, Loss: 0.013490099459886551\n",
      "Epoch 79, Loss: 0.008545112796127796\n",
      "Epoch 80, Loss: 0.004896467551589012\n",
      "Epoch 81, Loss: 0.010030333884060383\n",
      "Epoch 82, Loss: 0.005680080968886614\n",
      "Epoch 83, Loss: 0.010932882316410542\n",
      "Epoch 84, Loss: 0.009184857830405235\n",
      "Epoch 85, Loss: 0.005501095205545425\n",
      "Epoch 86, Loss: 0.06185013800859451\n",
      "Epoch 87, Loss: 0.009002113714814186\n",
      "Epoch 88, Loss: 0.012645195238292217\n",
      "Epoch 89, Loss: 0.004288273397833109\n",
      "Epoch 90, Loss: 0.0037637529894709587\n",
      "Epoch 91, Loss: 0.005373338703066111\n",
      "Epoch 92, Loss: 0.004693553317338228\n",
      "Epoch 93, Loss: 0.007077005226165056\n",
      "Epoch 94, Loss: 0.00908330362290144\n",
      "Epoch 95, Loss: 0.0065932320430874825\n",
      "Epoch 96, Loss: 0.005510248243808746\n",
      "Epoch 97, Loss: 0.004569824319332838\n",
      "Epoch 98, Loss: 0.003956586588174105\n",
      "Epoch 99, Loss: 0.007663018070161343\n",
      "Epoch 100, Loss: 0.013311071321368217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.2409946918487549\n",
      "Epoch 1, Loss: 0.5565814971923828\n",
      "Epoch 2, Loss: 0.5666664242744446\n",
      "Epoch 3, Loss: 0.3603576123714447\n",
      "Epoch 4, Loss: 1.1800532341003418\n",
      "Epoch 5, Loss: 0.41994088888168335\n",
      "Epoch 6, Loss: 0.4163777530193329\n",
      "Epoch 7, Loss: 0.5126343965530396\n",
      "Epoch 8, Loss: 0.3070652186870575\n",
      "Epoch 9, Loss: 0.8743731379508972\n",
      "Epoch 10, Loss: 0.316128134727478\n",
      "Epoch 11, Loss: 0.5570089817047119\n",
      "Epoch 12, Loss: 0.23548166453838348\n",
      "Epoch 13, Loss: 0.2533055543899536\n",
      "Epoch 14, Loss: 0.19385835528373718\n",
      "Epoch 15, Loss: 0.2804073989391327\n",
      "Epoch 16, Loss: 0.18707995116710663\n",
      "Epoch 17, Loss: 0.2193073034286499\n",
      "Epoch 18, Loss: 0.1560591459274292\n",
      "Epoch 19, Loss: 0.12178459763526917\n",
      "Epoch 20, Loss: 0.21572941541671753\n",
      "Epoch 21, Loss: 0.2580099403858185\n",
      "Epoch 22, Loss: 0.15600785613059998\n",
      "Epoch 23, Loss: 0.11414968967437744\n",
      "Epoch 24, Loss: 0.18235622346401215\n",
      "Epoch 25, Loss: 0.14838165044784546\n",
      "Epoch 26, Loss: 0.15511631965637207\n",
      "Epoch 27, Loss: 0.10655297338962555\n",
      "Epoch 28, Loss: 0.1421618014574051\n",
      "Epoch 29, Loss: 0.1556578129529953\n",
      "Epoch 30, Loss: 0.31749260425567627\n",
      "Epoch 31, Loss: 0.10154569149017334\n",
      "Epoch 32, Loss: 0.15311330556869507\n",
      "Epoch 33, Loss: 0.09685862064361572\n",
      "Epoch 34, Loss: 0.18751615285873413\n",
      "Epoch 35, Loss: 0.11732599139213562\n",
      "Epoch 36, Loss: 0.02398521639406681\n",
      "Epoch 37, Loss: 0.09714325517416\n",
      "Epoch 38, Loss: 0.05476813763380051\n",
      "Epoch 39, Loss: 0.05093397945165634\n",
      "Epoch 40, Loss: 0.042093321681022644\n",
      "Epoch 41, Loss: 0.04597677290439606\n",
      "Epoch 42, Loss: 0.014809731394052505\n",
      "Epoch 43, Loss: 0.0746597945690155\n",
      "Epoch 44, Loss: 0.02554601989686489\n",
      "Epoch 45, Loss: 0.06786692142486572\n",
      "Epoch 46, Loss: 0.03213052451610565\n",
      "Epoch 47, Loss: 0.03723246604204178\n",
      "Epoch 48, Loss: 0.03141505643725395\n",
      "Epoch 49, Loss: 0.04305284470319748\n",
      "Epoch 50, Loss: 0.03065122477710247\n",
      "Epoch 51, Loss: 0.021360231563448906\n",
      "Epoch 52, Loss: 0.025752374902367592\n",
      "Epoch 53, Loss: 0.03470151498913765\n",
      "Epoch 54, Loss: 0.015116251073777676\n",
      "Epoch 55, Loss: 0.022979434579610825\n",
      "Epoch 56, Loss: 0.026064524427056313\n",
      "Epoch 57, Loss: 0.02089840918779373\n",
      "Epoch 58, Loss: 0.011619438417255878\n",
      "Epoch 59, Loss: 0.03439108282327652\n",
      "Epoch 60, Loss: 0.03702184557914734\n",
      "Epoch 61, Loss: 0.04494449123740196\n",
      "Epoch 62, Loss: 0.017540045082569122\n",
      "Epoch 63, Loss: 0.016700800508260727\n",
      "Epoch 64, Loss: 0.01039817463606596\n",
      "Epoch 65, Loss: 0.021461404860019684\n",
      "Epoch 66, Loss: 0.017700083553791046\n",
      "Epoch 67, Loss: 0.015097266994416714\n",
      "Epoch 68, Loss: 0.017203330993652344\n",
      "Epoch 69, Loss: 0.021432556211948395\n",
      "Epoch 70, Loss: 0.006494552828371525\n",
      "Epoch 71, Loss: 0.006246666889637709\n",
      "Epoch 72, Loss: 0.006319150794297457\n",
      "Epoch 73, Loss: 0.014139392413198948\n",
      "Epoch 74, Loss: 0.016858987510204315\n",
      "Epoch 75, Loss: 0.014462128281593323\n",
      "Epoch 76, Loss: 0.011983235366642475\n",
      "Epoch 77, Loss: 0.016330579295754433\n",
      "Epoch 78, Loss: 0.008804663084447384\n",
      "Epoch 79, Loss: 0.008018220774829388\n",
      "Epoch 80, Loss: 0.01096375472843647\n",
      "Epoch 81, Loss: 0.01769290119409561\n",
      "Epoch 82, Loss: 0.005458981264382601\n",
      "Epoch 83, Loss: 0.013305016793310642\n",
      "Epoch 84, Loss: 0.020833225920796394\n",
      "Epoch 85, Loss: 0.005024610087275505\n",
      "Epoch 86, Loss: 0.008444096893072128\n",
      "Epoch 87, Loss: 0.008842792361974716\n",
      "Epoch 88, Loss: 0.008252880536019802\n",
      "Epoch 89, Loss: 0.010534809902310371\n",
      "Epoch 90, Loss: 0.004324349574744701\n",
      "Epoch 91, Loss: 0.014723190106451511\n",
      "Epoch 92, Loss: 0.004479546099901199\n",
      "Epoch 93, Loss: 0.010764792561531067\n",
      "Epoch 94, Loss: 0.015321461483836174\n",
      "Epoch 95, Loss: 0.006298798136413097\n",
      "Epoch 96, Loss: 0.007291696034371853\n",
      "Epoch 97, Loss: 0.009548086673021317\n",
      "Epoch 98, Loss: 0.032808490097522736\n",
      "Epoch 99, Loss: 0.0068567791022360325\n",
      "Epoch 100, Loss: 0.020653314888477325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.4010034799575806\n",
      "Epoch 1, Loss: 1.0903804302215576\n",
      "Epoch 2, Loss: 1.0551714897155762\n",
      "Epoch 3, Loss: 0.6251160502433777\n",
      "Epoch 4, Loss: 0.2875135838985443\n",
      "Epoch 5, Loss: 0.42745012044906616\n",
      "Epoch 6, Loss: 0.3848951756954193\n",
      "Epoch 7, Loss: 0.5782381892204285\n",
      "Epoch 8, Loss: 0.48285776376724243\n",
      "Epoch 9, Loss: 0.2561221718788147\n",
      "Epoch 10, Loss: 0.9697195887565613\n",
      "Epoch 11, Loss: 0.3822571635246277\n",
      "Epoch 12, Loss: 0.155123770236969\n",
      "Epoch 13, Loss: 0.2847009599208832\n",
      "Epoch 14, Loss: 0.1925508677959442\n",
      "Epoch 15, Loss: 0.2867876887321472\n",
      "Epoch 16, Loss: 0.21659527719020844\n",
      "Epoch 17, Loss: 0.35263365507125854\n",
      "Epoch 18, Loss: 0.18048608303070068\n",
      "Epoch 19, Loss: 0.17713624238967896\n",
      "Epoch 20, Loss: 0.15147508680820465\n",
      "Epoch 21, Loss: 0.16940602660179138\n",
      "Epoch 22, Loss: 0.1439056694507599\n",
      "Epoch 23, Loss: 0.07807502150535583\n",
      "Epoch 24, Loss: 0.18833059072494507\n",
      "Epoch 25, Loss: 0.0496944785118103\n",
      "Epoch 26, Loss: 0.04858459532260895\n",
      "Epoch 27, Loss: 0.062236055731773376\n",
      "Epoch 28, Loss: 0.057354338467121124\n",
      "Epoch 29, Loss: 0.07930273562669754\n",
      "Epoch 30, Loss: 0.09050769358873367\n",
      "Epoch 31, Loss: 0.055253684520721436\n",
      "Epoch 32, Loss: 0.1016029566526413\n",
      "Epoch 33, Loss: 0.12812602519989014\n",
      "Epoch 34, Loss: 0.1063852310180664\n",
      "Epoch 35, Loss: 0.1842300444841385\n",
      "Epoch 36, Loss: 0.07562097907066345\n",
      "Epoch 37, Loss: 0.04591985046863556\n",
      "Epoch 38, Loss: 0.11294232308864594\n",
      "Epoch 39, Loss: 0.02605135180056095\n",
      "Epoch 40, Loss: 0.06783221662044525\n",
      "Epoch 41, Loss: 0.08169692754745483\n",
      "Epoch 42, Loss: 0.029291249811649323\n",
      "Epoch 43, Loss: 0.023851552978157997\n",
      "Epoch 44, Loss: 0.021719852462410927\n",
      "Epoch 45, Loss: 0.03171125426888466\n",
      "Epoch 46, Loss: 0.08405587077140808\n",
      "Epoch 47, Loss: 0.04236195236444473\n",
      "Epoch 48, Loss: 0.03340126946568489\n",
      "Epoch 49, Loss: 0.01705588400363922\n",
      "Epoch 50, Loss: 0.03809807077050209\n",
      "Epoch 51, Loss: 0.021291285753250122\n",
      "Epoch 52, Loss: 0.035764794796705246\n",
      "Epoch 53, Loss: 0.019220152869820595\n",
      "Epoch 54, Loss: 0.07657167315483093\n",
      "Epoch 55, Loss: 0.02077757567167282\n",
      "Epoch 56, Loss: 0.013179476372897625\n",
      "Epoch 57, Loss: 0.02352410927414894\n",
      "Epoch 58, Loss: 0.03893060237169266\n",
      "Epoch 59, Loss: 0.025986075401306152\n",
      "Epoch 60, Loss: 0.014833067543804646\n",
      "Epoch 61, Loss: 0.020311204716563225\n",
      "Epoch 62, Loss: 0.019320078194141388\n",
      "Epoch 63, Loss: 0.008162174373865128\n",
      "Epoch 64, Loss: 0.038955312222242355\n",
      "Epoch 65, Loss: 0.01393220480531454\n",
      "Epoch 66, Loss: 0.012460342608392239\n",
      "Epoch 67, Loss: 0.014502114616334438\n",
      "Epoch 68, Loss: 0.008963663130998611\n",
      "Epoch 69, Loss: 0.02603275515139103\n",
      "Epoch 70, Loss: 0.008860270492732525\n",
      "Epoch 71, Loss: 0.008334804326295853\n",
      "Epoch 72, Loss: 0.01604027859866619\n",
      "Epoch 73, Loss: 0.008089304901659489\n",
      "Epoch 74, Loss: 0.0058663515374064445\n",
      "Epoch 75, Loss: 0.020351538434624672\n",
      "Epoch 76, Loss: 0.00850262213498354\n",
      "Epoch 77, Loss: 0.01711311936378479\n",
      "Epoch 78, Loss: 0.00964304804801941\n",
      "Epoch 79, Loss: 0.006740083917975426\n",
      "Epoch 80, Loss: 0.14187458157539368\n",
      "Epoch 81, Loss: 0.0032887861598283052\n",
      "Epoch 82, Loss: 0.010096710175275803\n",
      "Epoch 83, Loss: 0.015202712267637253\n",
      "Epoch 84, Loss: 0.015023329295217991\n",
      "Epoch 85, Loss: 0.012079128995537758\n",
      "Epoch 86, Loss: 0.01174887828528881\n",
      "Epoch 87, Loss: 0.010908108204603195\n",
      "Epoch 88, Loss: 0.005229124799370766\n",
      "Epoch 89, Loss: 0.008479185402393341\n",
      "Epoch 90, Loss: 0.010415204800665379\n",
      "Epoch 91, Loss: 0.0032119997777044773\n",
      "Epoch 92, Loss: 0.02330249734222889\n",
      "Epoch 93, Loss: 0.0044783661141991615\n",
      "Epoch 94, Loss: 0.015342245809733868\n",
      "Epoch 95, Loss: 0.015168990008533001\n",
      "Epoch 96, Loss: 0.021701451390981674\n",
      "Epoch 97, Loss: 0.007864377461373806\n",
      "Epoch 98, Loss: 0.007511857431381941\n",
      "Epoch 99, Loss: 0.013990703970193863\n",
      "Epoch 100, Loss: 0.004723831545561552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.2906830310821533\n",
      "Epoch 1, Loss: 0.5734838843345642\n",
      "Epoch 2, Loss: 0.4854414761066437\n",
      "Epoch 3, Loss: 0.6326517462730408\n",
      "Epoch 4, Loss: 0.2602006196975708\n",
      "Epoch 5, Loss: 0.45206335186958313\n",
      "Epoch 6, Loss: 0.26442426443099976\n",
      "Epoch 7, Loss: 0.649588942527771\n",
      "Epoch 8, Loss: 1.4057697057724\n",
      "Epoch 9, Loss: 0.210330531001091\n",
      "Epoch 10, Loss: 0.3555288314819336\n",
      "Epoch 11, Loss: 0.40569019317626953\n",
      "Epoch 12, Loss: 0.24614456295967102\n",
      "Epoch 13, Loss: 0.1304219514131546\n",
      "Epoch 14, Loss: 0.3510638475418091\n",
      "Epoch 15, Loss: 0.20167787373065948\n",
      "Epoch 16, Loss: 0.4332070052623749\n",
      "Epoch 17, Loss: 0.2384818196296692\n",
      "Epoch 18, Loss: 0.20874594151973724\n",
      "Epoch 19, Loss: 0.12086848169565201\n",
      "Epoch 20, Loss: 0.1248968169093132\n",
      "Epoch 21, Loss: 0.14520712196826935\n",
      "Epoch 22, Loss: 0.264268159866333\n",
      "Epoch 23, Loss: 0.17101511359214783\n",
      "Epoch 24, Loss: 0.21963420510292053\n",
      "Epoch 25, Loss: 0.12136434018611908\n",
      "Epoch 26, Loss: 0.1342782825231552\n",
      "Epoch 27, Loss: 0.14429259300231934\n",
      "Epoch 28, Loss: 0.13222819566726685\n",
      "Epoch 29, Loss: 0.0906597375869751\n",
      "Epoch 30, Loss: 0.0860728994011879\n",
      "Epoch 31, Loss: 0.13466334342956543\n",
      "Epoch 32, Loss: 0.0579783171415329\n",
      "Epoch 33, Loss: 0.04359310120344162\n",
      "Epoch 34, Loss: 0.037052493542432785\n",
      "Epoch 35, Loss: 0.12916529178619385\n",
      "Epoch 36, Loss: 0.08626725524663925\n",
      "Epoch 37, Loss: 0.028505126014351845\n",
      "Epoch 38, Loss: 0.060467593371868134\n",
      "Epoch 39, Loss: 0.043784234672784805\n",
      "Epoch 40, Loss: 0.047857847064733505\n",
      "Epoch 41, Loss: 0.032074544578790665\n",
      "Epoch 42, Loss: 0.01738305576145649\n",
      "Epoch 43, Loss: 0.03459514304995537\n",
      "Epoch 44, Loss: 0.017112191766500473\n",
      "Epoch 45, Loss: 0.03456667810678482\n",
      "Epoch 46, Loss: 0.026256348937749863\n",
      "Epoch 47, Loss: 0.11663892865180969\n",
      "Epoch 48, Loss: 0.024161215871572495\n",
      "Epoch 49, Loss: 0.021574867889285088\n",
      "Epoch 50, Loss: 0.03310561925172806\n",
      "Epoch 51, Loss: 0.03253215551376343\n",
      "Epoch 52, Loss: 0.02721225470304489\n",
      "Epoch 53, Loss: 0.026573363691568375\n",
      "Epoch 54, Loss: 0.021786296740174294\n",
      "Epoch 55, Loss: 0.02917300909757614\n",
      "Epoch 56, Loss: 0.03652104362845421\n",
      "Epoch 57, Loss: 0.01790972240269184\n",
      "Epoch 58, Loss: 0.012108879163861275\n",
      "Epoch 59, Loss: 0.018249545246362686\n",
      "Epoch 60, Loss: 0.05664415657520294\n",
      "Epoch 61, Loss: 0.026790935546159744\n",
      "Epoch 62, Loss: 0.011611835099756718\n",
      "Epoch 63, Loss: 0.021009918302297592\n",
      "Epoch 64, Loss: 0.035502053797245026\n",
      "Epoch 65, Loss: 0.020717309787869453\n",
      "Epoch 66, Loss: 0.020284660160541534\n",
      "Epoch 67, Loss: 0.036714985966682434\n",
      "Epoch 68, Loss: 0.013508450239896774\n",
      "Epoch 69, Loss: 0.013351956382393837\n",
      "Epoch 70, Loss: 0.017818162217736244\n",
      "Epoch 71, Loss: 0.01270928606390953\n",
      "Epoch 72, Loss: 0.014394187368452549\n",
      "Epoch 73, Loss: 0.027102837339043617\n",
      "Epoch 74, Loss: 0.0143138337880373\n",
      "Epoch 75, Loss: 0.013633816502988338\n",
      "Epoch 76, Loss: 0.01075906865298748\n",
      "Epoch 77, Loss: 0.009040828794240952\n",
      "Epoch 78, Loss: 0.011849322356283665\n",
      "Epoch 79, Loss: 0.010308543220162392\n",
      "Epoch 80, Loss: 0.013185013085603714\n",
      "Epoch 81, Loss: 0.014593624509871006\n",
      "Epoch 82, Loss: 0.012452076189219952\n",
      "Epoch 83, Loss: 0.01134069450199604\n",
      "Epoch 84, Loss: 0.009637190960347652\n",
      "Epoch 85, Loss: 0.03447073698043823\n",
      "Epoch 86, Loss: 0.010791603475809097\n",
      "Epoch 87, Loss: 0.014203007332980633\n",
      "Epoch 88, Loss: 0.017719212919473648\n",
      "Epoch 89, Loss: 0.013639066368341446\n",
      "Epoch 90, Loss: 0.01564786024391651\n",
      "Epoch 91, Loss: 0.006532690487802029\n",
      "Epoch 92, Loss: 0.010767343454062939\n",
      "Epoch 93, Loss: 0.007014188449829817\n",
      "Epoch 94, Loss: 0.00496843783184886\n",
      "Epoch 95, Loss: 0.007441192865371704\n",
      "Epoch 96, Loss: 0.019862117245793343\n",
      "Epoch 97, Loss: 0.007192749064415693\n",
      "Epoch 98, Loss: 0.008289574645459652\n",
      "Epoch 99, Loss: 0.0072596725076437\n",
      "Epoch 100, Loss: 0.00816030241549015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3913795948028564\n",
      "Epoch 1, Loss: 0.4888037443161011\n",
      "Epoch 2, Loss: 0.3551711142063141\n",
      "Epoch 3, Loss: 0.6927952170372009\n",
      "Epoch 4, Loss: 0.4461952745914459\n",
      "Epoch 5, Loss: 0.3922687768936157\n",
      "Epoch 6, Loss: 0.5019327402114868\n",
      "Epoch 7, Loss: 0.1683347374200821\n",
      "Epoch 8, Loss: 0.36784830689430237\n",
      "Epoch 9, Loss: 0.3481435775756836\n",
      "Epoch 10, Loss: 0.26630789041519165\n",
      "Epoch 11, Loss: 0.43738502264022827\n",
      "Epoch 12, Loss: 0.4506502151489258\n",
      "Epoch 13, Loss: 0.3495326638221741\n",
      "Epoch 14, Loss: 0.5606974959373474\n",
      "Epoch 15, Loss: 0.2354135811328888\n",
      "Epoch 16, Loss: 0.3183366060256958\n",
      "Epoch 17, Loss: 0.34158140420913696\n",
      "Epoch 18, Loss: 0.23007239401340485\n",
      "Epoch 19, Loss: 0.32839298248291016\n",
      "Epoch 20, Loss: 0.34461140632629395\n",
      "Epoch 21, Loss: 0.21923619508743286\n",
      "Epoch 22, Loss: 0.10337994247674942\n",
      "Epoch 23, Loss: 0.0810215175151825\n",
      "Epoch 24, Loss: 0.10263839364051819\n",
      "Epoch 25, Loss: 0.5491746664047241\n",
      "Epoch 26, Loss: 0.12001926451921463\n",
      "Epoch 27, Loss: 0.0913088396191597\n",
      "Epoch 28, Loss: 0.2211630791425705\n",
      "Epoch 29, Loss: 0.05727115646004677\n",
      "Epoch 30, Loss: 0.2582196593284607\n",
      "Epoch 31, Loss: 0.045094482600688934\n",
      "Epoch 32, Loss: 0.08637575805187225\n",
      "Epoch 33, Loss: 0.0781957358121872\n",
      "Epoch 34, Loss: 0.07701054215431213\n",
      "Epoch 35, Loss: 0.1650860458612442\n",
      "Epoch 36, Loss: 0.02649316005408764\n",
      "Epoch 37, Loss: 0.03066469170153141\n",
      "Epoch 38, Loss: 0.10590396821498871\n",
      "Epoch 39, Loss: 0.12901130318641663\n",
      "Epoch 40, Loss: 0.05740825831890106\n",
      "Epoch 41, Loss: 0.038388561457395554\n",
      "Epoch 42, Loss: 0.027697928249835968\n",
      "Epoch 43, Loss: 0.021127771586179733\n",
      "Epoch 44, Loss: 0.032497331500053406\n",
      "Epoch 45, Loss: 0.0563848540186882\n",
      "Epoch 46, Loss: 0.025879431515932083\n",
      "Epoch 47, Loss: 0.050047867000103\n",
      "Epoch 48, Loss: 0.025694509968161583\n",
      "Epoch 49, Loss: 0.013413265347480774\n",
      "Epoch 50, Loss: 0.03542075678706169\n",
      "Epoch 51, Loss: 0.03300079330801964\n",
      "Epoch 52, Loss: 0.015839051455259323\n",
      "Epoch 53, Loss: 0.04306352883577347\n",
      "Epoch 54, Loss: 0.05193624645471573\n",
      "Epoch 55, Loss: 0.011667079292237759\n",
      "Epoch 56, Loss: 0.04702141880989075\n",
      "Epoch 57, Loss: 0.03358922153711319\n",
      "Epoch 58, Loss: 0.039859771728515625\n",
      "Epoch 59, Loss: 0.017581386491656303\n",
      "Epoch 60, Loss: 0.013938140124082565\n",
      "Epoch 61, Loss: 0.013870545662939548\n",
      "Epoch 62, Loss: 0.03928086906671524\n",
      "Epoch 63, Loss: 0.016673512756824493\n",
      "Epoch 64, Loss: 0.02437635511159897\n",
      "Epoch 65, Loss: 0.007128935772925615\n",
      "Epoch 66, Loss: 0.011509575881063938\n",
      "Epoch 67, Loss: 0.0097044063732028\n",
      "Epoch 68, Loss: 0.014283629134297371\n",
      "Epoch 69, Loss: 0.013270303606987\n",
      "Epoch 70, Loss: 0.011443469673395157\n",
      "Epoch 71, Loss: 0.01320471242070198\n",
      "Epoch 72, Loss: 0.0155550641939044\n",
      "Epoch 73, Loss: 0.03391493856906891\n",
      "Epoch 74, Loss: 0.010017003864049911\n",
      "Epoch 75, Loss: 0.01823544315993786\n",
      "Epoch 76, Loss: 0.04114731773734093\n",
      "Epoch 77, Loss: 0.008756504394114017\n",
      "Epoch 78, Loss: 0.014327113516628742\n",
      "Epoch 79, Loss: 0.009332011453807354\n",
      "Epoch 80, Loss: 0.21051819622516632\n",
      "Epoch 81, Loss: 0.017911342903971672\n",
      "Epoch 82, Loss: 0.016163546591997147\n",
      "Epoch 83, Loss: 0.008208150044083595\n",
      "Epoch 84, Loss: 0.029951708391308784\n",
      "Epoch 85, Loss: 0.022457538172602654\n",
      "Epoch 86, Loss: 0.018716730177402496\n",
      "Epoch 87, Loss: 0.01948731392621994\n",
      "Epoch 88, Loss: 0.009071730077266693\n",
      "Epoch 89, Loss: 0.020970113575458527\n",
      "Epoch 90, Loss: 0.02660375088453293\n",
      "Epoch 91, Loss: 0.004600400570780039\n",
      "Epoch 92, Loss: 0.02061266452074051\n",
      "Epoch 93, Loss: 0.01340087316930294\n",
      "Epoch 94, Loss: 0.007859816774725914\n",
      "Epoch 95, Loss: 0.006839266512542963\n",
      "Epoch 96, Loss: 0.008556093089282513\n",
      "Epoch 97, Loss: 0.008797043934464455\n",
      "Epoch 98, Loss: 0.014309962280094624\n",
      "Epoch 99, Loss: 0.007082263473421335\n",
      "Epoch 100, Loss: 0.01134528499096632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.307306170463562\n",
      "Epoch 1, Loss: 0.9180877208709717\n",
      "Epoch 2, Loss: 0.6625421047210693\n",
      "Epoch 3, Loss: 0.44116851687431335\n",
      "Epoch 4, Loss: 0.7471110820770264\n",
      "Epoch 5, Loss: 0.7820088863372803\n",
      "Epoch 6, Loss: 0.9331990480422974\n",
      "Epoch 7, Loss: 0.3709675073623657\n",
      "Epoch 8, Loss: 0.300053209066391\n",
      "Epoch 9, Loss: 0.5649898052215576\n",
      "Epoch 10, Loss: 0.29423844814300537\n",
      "Epoch 11, Loss: 0.35653311014175415\n",
      "Epoch 12, Loss: 0.3642719089984894\n",
      "Epoch 13, Loss: 0.36051133275032043\n",
      "Epoch 14, Loss: 0.3759652376174927\n",
      "Epoch 15, Loss: 0.25212040543556213\n",
      "Epoch 16, Loss: 0.23775798082351685\n",
      "Epoch 17, Loss: 0.3714209198951721\n",
      "Epoch 18, Loss: 0.12946508824825287\n",
      "Epoch 19, Loss: 0.15527740120887756\n",
      "Epoch 20, Loss: 0.13545632362365723\n",
      "Epoch 21, Loss: 0.23308958113193512\n",
      "Epoch 22, Loss: 0.11342169344425201\n",
      "Epoch 23, Loss: 0.10810068249702454\n",
      "Epoch 24, Loss: 0.17300152778625488\n",
      "Epoch 25, Loss: 0.13803447782993317\n",
      "Epoch 26, Loss: 0.15354345738887787\n",
      "Epoch 27, Loss: 0.10841739922761917\n",
      "Epoch 28, Loss: 0.232150137424469\n",
      "Epoch 29, Loss: 0.06421218812465668\n",
      "Epoch 30, Loss: 0.0631713941693306\n",
      "Epoch 31, Loss: 0.06194557622075081\n",
      "Epoch 32, Loss: 0.06054554879665375\n",
      "Epoch 33, Loss: 0.023295201361179352\n",
      "Epoch 34, Loss: 0.0857345312833786\n",
      "Epoch 35, Loss: 0.09372533112764359\n",
      "Epoch 36, Loss: 0.057918351143598557\n",
      "Epoch 37, Loss: 0.023448728024959564\n",
      "Epoch 38, Loss: 0.05489214137196541\n",
      "Epoch 39, Loss: 0.08915308117866516\n",
      "Epoch 40, Loss: 0.014872021041810513\n",
      "Epoch 41, Loss: 0.06233800947666168\n",
      "Epoch 42, Loss: 0.03608951345086098\n",
      "Epoch 43, Loss: 0.038925476372241974\n",
      "Epoch 44, Loss: 0.04951510205864906\n",
      "Epoch 45, Loss: 0.028616633266210556\n",
      "Epoch 46, Loss: 0.03705392777919769\n",
      "Epoch 47, Loss: 0.04398338869214058\n",
      "Epoch 48, Loss: 0.020042922347784042\n",
      "Epoch 49, Loss: 0.021571798250079155\n",
      "Epoch 50, Loss: 0.01761014014482498\n",
      "Epoch 51, Loss: 0.042967598885297775\n",
      "Epoch 52, Loss: 0.02566337212920189\n",
      "Epoch 53, Loss: 0.028676800429821014\n",
      "Epoch 54, Loss: 0.04333972558379173\n",
      "Epoch 55, Loss: 0.05857907980680466\n",
      "Epoch 56, Loss: 0.02824084646999836\n",
      "Epoch 57, Loss: 0.02095126174390316\n",
      "Epoch 58, Loss: 0.029456334188580513\n",
      "Epoch 59, Loss: 0.018393676728010178\n",
      "Epoch 60, Loss: 0.018245942890644073\n",
      "Epoch 61, Loss: 0.02430795691907406\n",
      "Epoch 62, Loss: 0.014544932171702385\n",
      "Epoch 63, Loss: 0.04959218576550484\n",
      "Epoch 64, Loss: 0.015472665429115295\n",
      "Epoch 65, Loss: 0.016544463112950325\n",
      "Epoch 66, Loss: 0.010336753912270069\n",
      "Epoch 67, Loss: 0.029571542516350746\n",
      "Epoch 68, Loss: 0.017043761909008026\n",
      "Epoch 69, Loss: 0.022093474864959717\n",
      "Epoch 70, Loss: 0.012852262705564499\n",
      "Epoch 71, Loss: 0.06909879297018051\n",
      "Epoch 72, Loss: 0.03672872111201286\n",
      "Epoch 73, Loss: 0.007931657135486603\n",
      "Epoch 74, Loss: 0.02985328435897827\n",
      "Epoch 75, Loss: 0.01539645902812481\n",
      "Epoch 76, Loss: 0.008076501078903675\n",
      "Epoch 77, Loss: 0.009064027108252048\n",
      "Epoch 78, Loss: 0.01120433397591114\n",
      "Epoch 79, Loss: 0.00880274549126625\n",
      "Epoch 80, Loss: 0.03389745578169823\n",
      "Epoch 81, Loss: 0.024770766496658325\n",
      "Epoch 82, Loss: 0.009643283672630787\n",
      "Epoch 83, Loss: 0.010991106741130352\n",
      "Epoch 84, Loss: 0.005602440796792507\n",
      "Epoch 85, Loss: 0.030692435801029205\n",
      "Epoch 86, Loss: 0.01288869883865118\n",
      "Epoch 87, Loss: 0.004843526519834995\n",
      "Epoch 88, Loss: 0.010925800539553165\n",
      "Epoch 89, Loss: 0.009631864726543427\n",
      "Epoch 90, Loss: 0.012886205688118935\n",
      "Epoch 91, Loss: 0.020071091130375862\n",
      "Epoch 92, Loss: 0.01488968264311552\n",
      "Epoch 93, Loss: 0.015578120946884155\n",
      "Epoch 94, Loss: 0.016592539846897125\n",
      "Epoch 95, Loss: 0.02271408773958683\n",
      "Epoch 96, Loss: 0.012626281939446926\n",
      "Epoch 97, Loss: 0.010112413205206394\n",
      "Epoch 98, Loss: 0.006008138880133629\n",
      "Epoch 99, Loss: 0.016722293570637703\n",
      "Epoch 100, Loss: 0.011775887571275234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.4758626222610474\n",
      "Epoch 1, Loss: 0.6784861087799072\n",
      "Epoch 2, Loss: 0.7916715741157532\n",
      "Epoch 3, Loss: 0.7041804790496826\n",
      "Epoch 4, Loss: 0.41265833377838135\n",
      "Epoch 5, Loss: 0.39601930975914\n",
      "Epoch 6, Loss: 0.5517104268074036\n",
      "Epoch 7, Loss: 0.3543253242969513\n",
      "Epoch 8, Loss: 0.5040417909622192\n",
      "Epoch 9, Loss: 0.2553955316543579\n",
      "Epoch 10, Loss: 0.4040995240211487\n",
      "Epoch 11, Loss: 0.5741334557533264\n",
      "Epoch 12, Loss: 0.7006474733352661\n",
      "Epoch 13, Loss: 0.15799972414970398\n",
      "Epoch 14, Loss: 0.48726212978363037\n",
      "Epoch 15, Loss: 0.11437921971082687\n",
      "Epoch 16, Loss: 0.24566854536533356\n",
      "Epoch 17, Loss: 0.3655949532985687\n",
      "Epoch 18, Loss: 0.19741621613502502\n",
      "Epoch 19, Loss: 0.24154478311538696\n",
      "Epoch 20, Loss: 0.1393056958913803\n",
      "Epoch 21, Loss: 0.09386472404003143\n",
      "Epoch 22, Loss: 0.13261812925338745\n",
      "Epoch 23, Loss: 0.09512097388505936\n",
      "Epoch 24, Loss: 0.08671028167009354\n",
      "Epoch 25, Loss: 0.09896469116210938\n",
      "Epoch 26, Loss: 0.1337536871433258\n",
      "Epoch 27, Loss: 0.24098284542560577\n",
      "Epoch 28, Loss: 0.17745690047740936\n",
      "Epoch 29, Loss: 0.0875341072678566\n",
      "Epoch 30, Loss: 0.08794987201690674\n",
      "Epoch 31, Loss: 0.06990525126457214\n",
      "Epoch 32, Loss: 0.23000216484069824\n",
      "Epoch 33, Loss: 0.04800932854413986\n",
      "Epoch 34, Loss: 0.06971016526222229\n",
      "Epoch 35, Loss: 0.028904573991894722\n",
      "Epoch 36, Loss: 0.03409317508339882\n",
      "Epoch 37, Loss: 0.05201795697212219\n",
      "Epoch 38, Loss: 0.030485430732369423\n",
      "Epoch 39, Loss: 0.06739788502454758\n",
      "Epoch 40, Loss: 0.045991916209459305\n",
      "Epoch 41, Loss: 0.18043473362922668\n",
      "Epoch 42, Loss: 0.05473454296588898\n",
      "Epoch 43, Loss: 0.09168305993080139\n",
      "Epoch 44, Loss: 0.04793677106499672\n",
      "Epoch 45, Loss: 0.02690974622964859\n",
      "Epoch 46, Loss: 0.022530846297740936\n",
      "Epoch 47, Loss: 0.05618675425648689\n",
      "Epoch 48, Loss: 0.05323483422398567\n",
      "Epoch 49, Loss: 0.05648652836680412\n",
      "Epoch 50, Loss: 0.020186487585306168\n",
      "Epoch 51, Loss: 0.008654683828353882\n",
      "Epoch 52, Loss: 0.059254322201013565\n",
      "Epoch 53, Loss: 0.01875128783285618\n",
      "Epoch 54, Loss: 0.01480505894869566\n",
      "Epoch 55, Loss: 0.021101079881191254\n",
      "Epoch 56, Loss: 0.01658652350306511\n",
      "Epoch 57, Loss: 0.00863694865256548\n",
      "Epoch 58, Loss: 0.015439916402101517\n",
      "Epoch 59, Loss: 0.04144546389579773\n",
      "Epoch 60, Loss: 0.022814154624938965\n",
      "Epoch 61, Loss: 0.031249769032001495\n",
      "Epoch 62, Loss: 0.018851233646273613\n",
      "Epoch 63, Loss: 0.017069561406970024\n",
      "Epoch 64, Loss: 0.012721123173832893\n",
      "Epoch 65, Loss: 0.013991046696901321\n",
      "Epoch 66, Loss: 0.02006726711988449\n",
      "Epoch 67, Loss: 0.015602903440594673\n",
      "Epoch 68, Loss: 0.03330567479133606\n",
      "Epoch 69, Loss: 0.006302867084741592\n",
      "Epoch 70, Loss: 0.02024373784661293\n",
      "Epoch 71, Loss: 0.010636214166879654\n",
      "Epoch 72, Loss: 0.012824337929487228\n",
      "Epoch 73, Loss: 0.008235807530581951\n",
      "Epoch 74, Loss: 0.02958611026406288\n",
      "Epoch 75, Loss: 0.008381684310734272\n",
      "Epoch 76, Loss: 0.021047767251729965\n",
      "Epoch 77, Loss: 0.009923852980136871\n",
      "Epoch 78, Loss: 0.008329656906425953\n",
      "Epoch 79, Loss: 0.0038158451206982136\n",
      "Epoch 80, Loss: 0.007487464230507612\n",
      "Epoch 81, Loss: 0.009729298762977123\n",
      "Epoch 82, Loss: 0.01075783185660839\n",
      "Epoch 83, Loss: 0.02299787849187851\n",
      "Epoch 84, Loss: 0.016871389001607895\n",
      "Epoch 85, Loss: 0.014053740538656712\n",
      "Epoch 86, Loss: 0.01979699544608593\n",
      "Epoch 87, Loss: 0.00610843813046813\n",
      "Epoch 88, Loss: 0.010699901729822159\n",
      "Epoch 89, Loss: 0.012943808920681477\n",
      "Epoch 90, Loss: 0.007961512543261051\n",
      "Epoch 91, Loss: 0.006430729292333126\n",
      "Epoch 92, Loss: 0.016193509101867676\n",
      "Epoch 93, Loss: 0.007293339353054762\n",
      "Epoch 94, Loss: 0.012735586613416672\n",
      "Epoch 95, Loss: 0.016111155971884727\n",
      "Epoch 96, Loss: 0.007657518610358238\n",
      "Epoch 97, Loss: 0.006166086997836828\n",
      "Epoch 98, Loss: 0.003969450015574694\n",
      "Epoch 99, Loss: 0.009325888007879257\n",
      "Epoch 100, Loss: 0.009003792889416218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3016319274902344\n",
      "Epoch 1, Loss: 0.5027663707733154\n",
      "Epoch 2, Loss: 0.5658995509147644\n",
      "Epoch 3, Loss: 0.6278793811798096\n",
      "Epoch 4, Loss: 0.4292457401752472\n",
      "Epoch 5, Loss: 0.5599588751792908\n",
      "Epoch 6, Loss: 0.7794056534767151\n",
      "Epoch 7, Loss: 0.7977827787399292\n",
      "Epoch 8, Loss: 0.7046719789505005\n",
      "Epoch 9, Loss: 0.4343622922897339\n",
      "Epoch 10, Loss: 0.24320991337299347\n",
      "Epoch 11, Loss: 0.3106463551521301\n",
      "Epoch 12, Loss: 0.3985016644001007\n",
      "Epoch 13, Loss: 0.6971705555915833\n",
      "Epoch 14, Loss: 0.19764956831932068\n",
      "Epoch 15, Loss: 0.28689202666282654\n",
      "Epoch 16, Loss: 0.1758102923631668\n",
      "Epoch 17, Loss: 0.22470921277999878\n",
      "Epoch 18, Loss: 0.39053574204444885\n",
      "Epoch 19, Loss: 0.18005211651325226\n",
      "Epoch 20, Loss: 0.2497781366109848\n",
      "Epoch 21, Loss: 0.29045429825782776\n",
      "Epoch 22, Loss: 0.13504177331924438\n",
      "Epoch 23, Loss: 0.17594791948795319\n",
      "Epoch 24, Loss: 0.09961610287427902\n",
      "Epoch 25, Loss: 0.15401889383792877\n",
      "Epoch 26, Loss: 0.08992157876491547\n",
      "Epoch 27, Loss: 0.050614386796951294\n",
      "Epoch 28, Loss: 0.07714465260505676\n",
      "Epoch 29, Loss: 0.1299017369747162\n",
      "Epoch 30, Loss: 0.043027278035879135\n",
      "Epoch 31, Loss: 0.08546489477157593\n",
      "Epoch 32, Loss: 0.09234683960676193\n",
      "Epoch 33, Loss: 0.05025748908519745\n",
      "Epoch 34, Loss: 0.04298793151974678\n",
      "Epoch 35, Loss: 0.07389220595359802\n",
      "Epoch 36, Loss: 0.1485486775636673\n",
      "Epoch 37, Loss: 0.08986112475395203\n",
      "Epoch 38, Loss: 0.045967038720846176\n",
      "Epoch 39, Loss: 0.06892403215169907\n",
      "Epoch 40, Loss: 0.054940272122621536\n",
      "Epoch 41, Loss: 0.016056830063462257\n",
      "Epoch 42, Loss: 0.0653163492679596\n",
      "Epoch 43, Loss: 0.036846812814474106\n",
      "Epoch 44, Loss: 0.04337763786315918\n",
      "Epoch 45, Loss: 0.045757927000522614\n",
      "Epoch 46, Loss: 0.04463933780789375\n",
      "Epoch 47, Loss: 0.02646360546350479\n",
      "Epoch 48, Loss: 0.019043512642383575\n",
      "Epoch 49, Loss: 0.014992576092481613\n",
      "Epoch 50, Loss: 0.025959130376577377\n",
      "Epoch 51, Loss: 0.031750746071338654\n",
      "Epoch 52, Loss: 0.03891989216208458\n",
      "Epoch 53, Loss: 0.02722877636551857\n",
      "Epoch 54, Loss: 0.028056956827640533\n",
      "Epoch 55, Loss: 0.012393053621053696\n",
      "Epoch 56, Loss: 0.04027585685253143\n",
      "Epoch 57, Loss: 0.014421109110116959\n",
      "Epoch 58, Loss: 0.017857084050774574\n",
      "Epoch 59, Loss: 0.09159988164901733\n",
      "Epoch 60, Loss: 0.01652495749294758\n",
      "Epoch 61, Loss: 0.028857145458459854\n",
      "Epoch 62, Loss: 0.016056274995207787\n",
      "Epoch 63, Loss: 0.04045592248439789\n",
      "Epoch 64, Loss: 0.011764436960220337\n",
      "Epoch 65, Loss: 0.020978117361664772\n",
      "Epoch 66, Loss: 0.016417235136032104\n",
      "Epoch 67, Loss: 0.014256836846470833\n",
      "Epoch 68, Loss: 0.048067495226860046\n",
      "Epoch 69, Loss: 0.009177576750516891\n",
      "Epoch 70, Loss: 0.012163917534053326\n",
      "Epoch 71, Loss: 0.027778029441833496\n",
      "Epoch 72, Loss: 0.012040956877171993\n",
      "Epoch 73, Loss: 0.011422207579016685\n",
      "Epoch 74, Loss: 0.009223252534866333\n",
      "Epoch 75, Loss: 0.036436647176742554\n",
      "Epoch 76, Loss: 0.017738102003932\n",
      "Epoch 77, Loss: 0.005105486139655113\n",
      "Epoch 78, Loss: 0.008177105337381363\n",
      "Epoch 79, Loss: 0.016025295481085777\n",
      "Epoch 80, Loss: 0.011242703534662724\n",
      "Epoch 81, Loss: 0.011344232596457005\n",
      "Epoch 82, Loss: 0.013596796430647373\n",
      "Epoch 83, Loss: 0.013835198245942593\n",
      "Epoch 84, Loss: 0.003906794358044863\n",
      "Epoch 85, Loss: 0.00699313310906291\n",
      "Epoch 86, Loss: 0.022521834820508957\n",
      "Epoch 87, Loss: 0.01028822734951973\n",
      "Epoch 88, Loss: 0.013412515632808208\n",
      "Epoch 89, Loss: 0.015419994480907917\n",
      "Epoch 90, Loss: 0.014103599824011326\n",
      "Epoch 91, Loss: 0.0058314916677773\n",
      "Epoch 92, Loss: 0.012799306772649288\n",
      "Epoch 93, Loss: 0.008407530374825\n",
      "Epoch 94, Loss: 0.024370143190026283\n",
      "Epoch 95, Loss: 0.010687883011996746\n",
      "Epoch 96, Loss: 0.0060524847358465195\n",
      "Epoch 97, Loss: 0.012586493045091629\n",
      "Epoch 98, Loss: 0.01294113788753748\n",
      "Epoch 99, Loss: 0.006858343258500099\n",
      "Epoch 100, Loss: 0.006225260440260172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3342063426971436\n",
      "Epoch 1, Loss: 0.7037330269813538\n",
      "Epoch 2, Loss: 0.3777095377445221\n",
      "Epoch 3, Loss: 0.6670631766319275\n",
      "Epoch 4, Loss: 0.22003774344921112\n",
      "Epoch 5, Loss: 0.16345323622226715\n",
      "Epoch 6, Loss: 0.337056964635849\n",
      "Epoch 7, Loss: 0.41908761858940125\n",
      "Epoch 8, Loss: 0.5835660696029663\n",
      "Epoch 9, Loss: 0.45222270488739014\n",
      "Epoch 10, Loss: 0.5797414779663086\n",
      "Epoch 11, Loss: 0.1796538233757019\n",
      "Epoch 12, Loss: 0.5699863433837891\n",
      "Epoch 13, Loss: 0.2568577229976654\n",
      "Epoch 14, Loss: 0.40021267533302307\n",
      "Epoch 15, Loss: 0.1611967384815216\n",
      "Epoch 16, Loss: 0.1606455147266388\n",
      "Epoch 17, Loss: 0.18111073970794678\n",
      "Epoch 18, Loss: 0.35644665360450745\n",
      "Epoch 19, Loss: 0.08489012718200684\n",
      "Epoch 20, Loss: 0.23182082176208496\n",
      "Epoch 21, Loss: 0.07458523660898209\n",
      "Epoch 22, Loss: 0.16913364827632904\n",
      "Epoch 23, Loss: 0.20028068125247955\n",
      "Epoch 24, Loss: 0.15411359071731567\n",
      "Epoch 25, Loss: 0.08027675747871399\n",
      "Epoch 26, Loss: 0.24811860918998718\n",
      "Epoch 27, Loss: 0.054273590445518494\n",
      "Epoch 28, Loss: 0.2611311972141266\n",
      "Epoch 29, Loss: 0.143244206905365\n",
      "Epoch 30, Loss: 0.07847778499126434\n",
      "Epoch 31, Loss: 0.06130874902009964\n",
      "Epoch 32, Loss: 0.19341230392456055\n",
      "Epoch 33, Loss: 0.06991827487945557\n",
      "Epoch 34, Loss: 0.045929551124572754\n",
      "Epoch 35, Loss: 0.14123612642288208\n",
      "Epoch 36, Loss: 0.05496189370751381\n",
      "Epoch 37, Loss: 0.05680830031633377\n",
      "Epoch 38, Loss: 0.033194974064826965\n",
      "Epoch 39, Loss: 0.03939400985836983\n",
      "Epoch 40, Loss: 0.04138137027621269\n",
      "Epoch 41, Loss: 0.26695185899734497\n",
      "Epoch 42, Loss: 0.02831832505762577\n",
      "Epoch 43, Loss: 0.04052315652370453\n",
      "Epoch 44, Loss: 0.018617117777466774\n",
      "Epoch 45, Loss: 0.038749054074287415\n",
      "Epoch 46, Loss: 0.06159424036741257\n",
      "Epoch 47, Loss: 0.03913479298353195\n",
      "Epoch 48, Loss: 0.041728027164936066\n",
      "Epoch 49, Loss: 0.06211590766906738\n",
      "Epoch 50, Loss: 0.02224382385611534\n",
      "Epoch 51, Loss: 0.019825398921966553\n",
      "Epoch 52, Loss: 0.010590181685984135\n",
      "Epoch 53, Loss: 0.021814724430441856\n",
      "Epoch 54, Loss: 0.02345889061689377\n",
      "Epoch 55, Loss: 0.012956712394952774\n",
      "Epoch 56, Loss: 0.019883915781974792\n",
      "Epoch 57, Loss: 0.020615017041563988\n",
      "Epoch 58, Loss: 0.029680319130420685\n",
      "Epoch 59, Loss: 0.012630188837647438\n",
      "Epoch 60, Loss: 0.018393898382782936\n",
      "Epoch 61, Loss: 0.043158069252967834\n",
      "Epoch 62, Loss: 0.022706029936671257\n",
      "Epoch 63, Loss: 0.03511153161525726\n",
      "Epoch 64, Loss: 0.01426641270518303\n",
      "Epoch 65, Loss: 0.006352103315293789\n",
      "Epoch 66, Loss: 0.01535185519605875\n",
      "Epoch 67, Loss: 0.09006521850824356\n",
      "Epoch 68, Loss: 0.008780349977314472\n",
      "Epoch 69, Loss: 0.02608800306916237\n",
      "Epoch 70, Loss: 0.017096327617764473\n",
      "Epoch 71, Loss: 0.009696715511381626\n",
      "Epoch 72, Loss: 0.009594115428626537\n",
      "Epoch 73, Loss: 0.01835041306912899\n",
      "Epoch 74, Loss: 0.004026659298688173\n",
      "Epoch 75, Loss: 0.009374250657856464\n",
      "Epoch 76, Loss: 0.014774467796087265\n",
      "Epoch 77, Loss: 0.007161084096878767\n",
      "Epoch 78, Loss: 0.023663252592086792\n",
      "Epoch 79, Loss: 0.021387599408626556\n",
      "Epoch 80, Loss: 0.010700101964175701\n",
      "Epoch 81, Loss: 0.024101432412862778\n",
      "Epoch 82, Loss: 0.017372341826558113\n",
      "Epoch 83, Loss: 0.03716041520237923\n",
      "Epoch 84, Loss: 0.008359991014003754\n",
      "Epoch 85, Loss: 0.005173888057470322\n",
      "Epoch 86, Loss: 0.008804911747574806\n",
      "Epoch 87, Loss: 0.010329625569283962\n",
      "Epoch 88, Loss: 0.010668833740055561\n",
      "Epoch 89, Loss: 0.010580268688499928\n",
      "Epoch 90, Loss: 0.015688452869653702\n",
      "Epoch 91, Loss: 0.005371352657675743\n",
      "Epoch 92, Loss: 0.0066020977683365345\n",
      "Epoch 93, Loss: 0.008179990574717522\n",
      "Epoch 94, Loss: 0.007304740604013205\n",
      "Epoch 95, Loss: 0.008816765621304512\n",
      "Epoch 96, Loss: 0.007807282265275717\n",
      "Epoch 97, Loss: 0.011294718831777573\n",
      "Epoch 98, Loss: 0.023892678320407867\n",
      "Epoch 99, Loss: 0.00835034716874361\n",
      "Epoch 100, Loss: 0.0068525103852152824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.2821273803710938\n",
      "Epoch 1, Loss: 1.3075798749923706\n",
      "Epoch 2, Loss: 0.8097065091133118\n",
      "Epoch 3, Loss: 0.3951833248138428\n",
      "Epoch 4, Loss: 0.3555583357810974\n",
      "Epoch 5, Loss: 1.075713872909546\n",
      "Epoch 6, Loss: 0.4035920202732086\n",
      "Epoch 7, Loss: 0.3486437201499939\n",
      "Epoch 8, Loss: 0.2394256293773651\n",
      "Epoch 9, Loss: 0.3954203426837921\n",
      "Epoch 10, Loss: 0.2756810784339905\n",
      "Epoch 11, Loss: 0.3636523187160492\n",
      "Epoch 12, Loss: 0.5343587398529053\n",
      "Epoch 13, Loss: 0.4323331117630005\n",
      "Epoch 14, Loss: 0.1751500964164734\n",
      "Epoch 15, Loss: 0.34029510617256165\n",
      "Epoch 16, Loss: 0.32914313673973083\n",
      "Epoch 17, Loss: 0.17950136959552765\n",
      "Epoch 18, Loss: 0.1586480736732483\n",
      "Epoch 19, Loss: 0.20360147953033447\n",
      "Epoch 20, Loss: 0.3290989398956299\n",
      "Epoch 21, Loss: 0.12017914652824402\n",
      "Epoch 22, Loss: 0.11235745996236801\n",
      "Epoch 23, Loss: 0.09508468210697174\n",
      "Epoch 24, Loss: 0.10005845874547958\n",
      "Epoch 25, Loss: 0.07782285660505295\n",
      "Epoch 26, Loss: 0.1954888552427292\n",
      "Epoch 27, Loss: 0.03129921108484268\n",
      "Epoch 28, Loss: 0.11417487263679504\n",
      "Epoch 29, Loss: 0.1678590327501297\n",
      "Epoch 30, Loss: 0.11735960841178894\n",
      "Epoch 31, Loss: 0.20949193835258484\n",
      "Epoch 32, Loss: 0.0632994994521141\n",
      "Epoch 33, Loss: 0.1280606985092163\n",
      "Epoch 34, Loss: 0.14328104257583618\n",
      "Epoch 35, Loss: 0.035806190222501755\n",
      "Epoch 36, Loss: 0.06762856990098953\n",
      "Epoch 37, Loss: 0.02758469432592392\n",
      "Epoch 38, Loss: 0.09853926301002502\n",
      "Epoch 39, Loss: 0.04761752858757973\n",
      "Epoch 40, Loss: 0.05537231266498566\n",
      "Epoch 41, Loss: 0.02860994078218937\n",
      "Epoch 42, Loss: 0.08024867624044418\n",
      "Epoch 43, Loss: 0.015764664858579636\n",
      "Epoch 44, Loss: 0.04580236226320267\n",
      "Epoch 45, Loss: 0.12039375305175781\n",
      "Epoch 46, Loss: 0.02207692340016365\n",
      "Epoch 47, Loss: 0.07059746235609055\n",
      "Epoch 48, Loss: 0.01501898467540741\n",
      "Epoch 49, Loss: 0.03851018100976944\n",
      "Epoch 50, Loss: 0.0334811732172966\n",
      "Epoch 51, Loss: 0.04972446337342262\n",
      "Epoch 52, Loss: 0.03123551234602928\n",
      "Epoch 53, Loss: 0.0454251728951931\n",
      "Epoch 54, Loss: 0.0711311548948288\n",
      "Epoch 55, Loss: 0.031614698469638824\n",
      "Epoch 56, Loss: 0.020389389246702194\n",
      "Epoch 57, Loss: 0.04451783001422882\n",
      "Epoch 58, Loss: 0.023010214790701866\n",
      "Epoch 59, Loss: 0.010513381101191044\n",
      "Epoch 60, Loss: 0.025230644270777702\n",
      "Epoch 61, Loss: 0.03179369866847992\n",
      "Epoch 62, Loss: 0.03221620246767998\n",
      "Epoch 63, Loss: 0.010899130254983902\n",
      "Epoch 64, Loss: 0.01034601405262947\n",
      "Epoch 65, Loss: 0.03708520531654358\n",
      "Epoch 66, Loss: 0.020947841927409172\n",
      "Epoch 67, Loss: 0.02408536523580551\n",
      "Epoch 68, Loss: 0.022870782762765884\n",
      "Epoch 69, Loss: 0.015413077548146248\n",
      "Epoch 70, Loss: 0.03188369423151016\n",
      "Epoch 71, Loss: 0.0327867716550827\n",
      "Epoch 72, Loss: 0.014214343391358852\n",
      "Epoch 73, Loss: 0.01260051317512989\n",
      "Epoch 74, Loss: 0.011012195609509945\n",
      "Epoch 75, Loss: 0.009148641489446163\n",
      "Epoch 76, Loss: 0.008722600527107716\n",
      "Epoch 77, Loss: 0.032694391906261444\n",
      "Epoch 78, Loss: 0.006535439286381006\n",
      "Epoch 79, Loss: 0.011392822489142418\n",
      "Epoch 80, Loss: 0.015346987172961235\n",
      "Epoch 81, Loss: 0.020532483235001564\n",
      "Epoch 82, Loss: 0.005905670579522848\n",
      "Epoch 83, Loss: 0.013514291495084763\n",
      "Epoch 84, Loss: 0.01194619107991457\n",
      "Epoch 85, Loss: 0.006961571518331766\n",
      "Epoch 86, Loss: 0.012018696404993534\n",
      "Epoch 87, Loss: 0.011210872791707516\n",
      "Epoch 88, Loss: 0.022703344002366066\n",
      "Epoch 89, Loss: 0.00871402770280838\n",
      "Epoch 90, Loss: 0.0056250509805977345\n",
      "Epoch 91, Loss: 0.010144962929189205\n",
      "Epoch 92, Loss: 0.029980791732668877\n",
      "Epoch 93, Loss: 0.014223153702914715\n",
      "Epoch 94, Loss: 0.013722188770771027\n",
      "Epoch 95, Loss: 0.005941419396549463\n",
      "Epoch 96, Loss: 0.006696728989481926\n",
      "Epoch 97, Loss: 0.008748283609747887\n",
      "Epoch 98, Loss: 0.006011612713336945\n",
      "Epoch 99, Loss: 0.01022012997418642\n",
      "Epoch 100, Loss: 0.004368976689875126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3915112018585205\n",
      "Epoch 1, Loss: 0.3571908473968506\n",
      "Epoch 2, Loss: 0.6443101763725281\n",
      "Epoch 3, Loss: 0.5534234046936035\n",
      "Epoch 4, Loss: 0.2822152376174927\n",
      "Epoch 5, Loss: 0.5728272795677185\n",
      "Epoch 6, Loss: 0.5690245032310486\n",
      "Epoch 7, Loss: 0.7525025010108948\n",
      "Epoch 8, Loss: 0.36609163880348206\n",
      "Epoch 9, Loss: 0.8459808826446533\n",
      "Epoch 10, Loss: 0.4619426727294922\n",
      "Epoch 11, Loss: 0.19108057022094727\n",
      "Epoch 12, Loss: 0.322761207818985\n",
      "Epoch 13, Loss: 0.5183649659156799\n",
      "Epoch 14, Loss: 0.2916817367076874\n",
      "Epoch 15, Loss: 0.2461303323507309\n",
      "Epoch 16, Loss: 0.18678449094295502\n",
      "Epoch 17, Loss: 0.20551003515720367\n",
      "Epoch 18, Loss: 0.1688041090965271\n",
      "Epoch 19, Loss: 0.10821385681629181\n",
      "Epoch 20, Loss: 0.213651642203331\n",
      "Epoch 21, Loss: 0.22446958720684052\n",
      "Epoch 22, Loss: 0.2839302718639374\n",
      "Epoch 23, Loss: 0.11295560747385025\n",
      "Epoch 24, Loss: 0.35604965686798096\n",
      "Epoch 25, Loss: 0.24793553352355957\n",
      "Epoch 26, Loss: 0.1511421948671341\n",
      "Epoch 27, Loss: 0.0685146227478981\n",
      "Epoch 28, Loss: 0.09012482315301895\n",
      "Epoch 29, Loss: 0.06522045284509659\n",
      "Epoch 30, Loss: 0.11422589421272278\n",
      "Epoch 31, Loss: 0.11786091327667236\n",
      "Epoch 32, Loss: 0.06799724698066711\n",
      "Epoch 33, Loss: 0.11710184067487717\n",
      "Epoch 34, Loss: 0.09934826195240021\n",
      "Epoch 35, Loss: 0.1125318631529808\n",
      "Epoch 36, Loss: 0.18959714472293854\n",
      "Epoch 37, Loss: 0.11701978743076324\n",
      "Epoch 38, Loss: 0.06647196412086487\n",
      "Epoch 39, Loss: 0.07084014266729355\n",
      "Epoch 40, Loss: 0.01516635250300169\n",
      "Epoch 41, Loss: 0.02882474660873413\n",
      "Epoch 42, Loss: 0.10415033996105194\n",
      "Epoch 43, Loss: 0.024504169821739197\n",
      "Epoch 44, Loss: 0.055277805775403976\n",
      "Epoch 45, Loss: 0.03426853567361832\n",
      "Epoch 46, Loss: 0.08261990547180176\n",
      "Epoch 47, Loss: 0.03585001453757286\n",
      "Epoch 48, Loss: 0.04749050736427307\n",
      "Epoch 49, Loss: 0.05333372578024864\n",
      "Epoch 50, Loss: 0.016701608896255493\n",
      "Epoch 51, Loss: 0.024158518761396408\n",
      "Epoch 52, Loss: 0.06927905231714249\n",
      "Epoch 53, Loss: 0.016063939779996872\n",
      "Epoch 54, Loss: 0.01819673739373684\n",
      "Epoch 55, Loss: 0.02626873180270195\n",
      "Epoch 56, Loss: 0.029180053621530533\n",
      "Epoch 57, Loss: 0.01401824876666069\n",
      "Epoch 58, Loss: 0.016278911381959915\n",
      "Epoch 59, Loss: 0.015985319390892982\n",
      "Epoch 60, Loss: 0.1200568675994873\n",
      "Epoch 61, Loss: 0.011856557801365852\n",
      "Epoch 62, Loss: 0.018269501626491547\n",
      "Epoch 63, Loss: 0.014673988334834576\n",
      "Epoch 64, Loss: 0.0161882434040308\n",
      "Epoch 65, Loss: 0.0273685734719038\n",
      "Epoch 66, Loss: 0.0183399710804224\n",
      "Epoch 67, Loss: 0.01186023373156786\n",
      "Epoch 68, Loss: 0.019877612590789795\n",
      "Epoch 69, Loss: 0.005532300099730492\n",
      "Epoch 70, Loss: 0.02055654674768448\n",
      "Epoch 71, Loss: 0.006074401084333658\n",
      "Epoch 72, Loss: 0.014668289572000504\n",
      "Epoch 73, Loss: 0.010267104022204876\n",
      "Epoch 74, Loss: 0.018656756728887558\n",
      "Epoch 75, Loss: 0.00792604312300682\n",
      "Epoch 76, Loss: 0.012505603954195976\n",
      "Epoch 77, Loss: 0.00884067639708519\n",
      "Epoch 78, Loss: 0.014672698453068733\n",
      "Epoch 79, Loss: 0.006839611567556858\n",
      "Epoch 80, Loss: 0.015291441231966019\n",
      "Epoch 81, Loss: 0.016291508451104164\n",
      "Epoch 82, Loss: 0.008132067508995533\n",
      "Epoch 83, Loss: 0.009668570943176746\n",
      "Epoch 84, Loss: 0.01401812955737114\n",
      "Epoch 85, Loss: 0.013041042722761631\n",
      "Epoch 86, Loss: 0.016287855803966522\n",
      "Epoch 87, Loss: 0.022851411253213882\n",
      "Epoch 88, Loss: 0.009311364032328129\n",
      "Epoch 89, Loss: 0.013299359939992428\n",
      "Epoch 90, Loss: 0.016801418736577034\n",
      "Epoch 91, Loss: 0.006740068085491657\n",
      "Epoch 92, Loss: 0.015020334161818027\n",
      "Epoch 93, Loss: 0.010846968740224838\n",
      "Epoch 94, Loss: 0.02262476086616516\n",
      "Epoch 95, Loss: 0.0058748601004481316\n",
      "Epoch 96, Loss: 0.0050518871285021305\n",
      "Epoch 97, Loss: 0.009803668595850468\n",
      "Epoch 98, Loss: 0.010239274241030216\n",
      "Epoch 99, Loss: 0.012014728039503098\n",
      "Epoch 100, Loss: 0.006348591763526201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3610827922821045\n",
      "Epoch 1, Loss: 0.9395434856414795\n",
      "Epoch 2, Loss: 0.9974538087844849\n",
      "Epoch 3, Loss: 0.6939006447792053\n",
      "Epoch 4, Loss: 0.45186492800712585\n",
      "Epoch 5, Loss: 0.5850940346717834\n",
      "Epoch 6, Loss: 0.6050041317939758\n",
      "Epoch 7, Loss: 1.0484633445739746\n",
      "Epoch 8, Loss: 0.5486547946929932\n",
      "Epoch 9, Loss: 0.6241427659988403\n",
      "Epoch 10, Loss: 0.4638504385948181\n",
      "Epoch 11, Loss: 0.324563592672348\n",
      "Epoch 12, Loss: 0.41008260846138\n",
      "Epoch 13, Loss: 0.26460444927215576\n",
      "Epoch 14, Loss: 0.2196066975593567\n",
      "Epoch 15, Loss: 0.5140147805213928\n",
      "Epoch 16, Loss: 0.3056427240371704\n",
      "Epoch 17, Loss: 0.3062232732772827\n",
      "Epoch 18, Loss: 0.2357613444328308\n",
      "Epoch 19, Loss: 0.24335233867168427\n",
      "Epoch 20, Loss: 0.2668423652648926\n",
      "Epoch 21, Loss: 0.4042690694332123\n",
      "Epoch 22, Loss: 0.1779845505952835\n",
      "Epoch 23, Loss: 0.19986140727996826\n",
      "Epoch 24, Loss: 0.1242523342370987\n",
      "Epoch 25, Loss: 0.1666359305381775\n",
      "Epoch 26, Loss: 0.2763507664203644\n",
      "Epoch 27, Loss: 0.281857430934906\n",
      "Epoch 28, Loss: 0.09216675162315369\n",
      "Epoch 29, Loss: 0.24496275186538696\n",
      "Epoch 30, Loss: 0.08853473514318466\n",
      "Epoch 31, Loss: 0.23021714389324188\n",
      "Epoch 32, Loss: 0.07595125585794449\n",
      "Epoch 33, Loss: 0.23338180780410767\n",
      "Epoch 34, Loss: 0.036479681730270386\n",
      "Epoch 35, Loss: 0.0895049199461937\n",
      "Epoch 36, Loss: 0.0445915162563324\n",
      "Epoch 37, Loss: 0.14683897793293\n",
      "Epoch 38, Loss: 0.07534373551607132\n",
      "Epoch 39, Loss: 0.08571691066026688\n",
      "Epoch 40, Loss: 0.01606244407594204\n",
      "Epoch 41, Loss: 0.03255940228700638\n",
      "Epoch 42, Loss: 0.07709323614835739\n",
      "Epoch 43, Loss: 0.07768186181783676\n",
      "Epoch 44, Loss: 0.026166312396526337\n",
      "Epoch 45, Loss: 0.03438402712345123\n",
      "Epoch 46, Loss: 0.191342294216156\n",
      "Epoch 47, Loss: 0.09006647765636444\n",
      "Epoch 48, Loss: 0.02388252317905426\n",
      "Epoch 49, Loss: 0.03374848514795303\n",
      "Epoch 50, Loss: 0.05623767152428627\n",
      "Epoch 51, Loss: 0.01689215563237667\n",
      "Epoch 52, Loss: 0.02833331562578678\n",
      "Epoch 53, Loss: 0.013569027185440063\n",
      "Epoch 54, Loss: 0.014456276781857014\n",
      "Epoch 55, Loss: 0.01965400204062462\n",
      "Epoch 56, Loss: 0.016923636198043823\n",
      "Epoch 57, Loss: 0.015512843616306782\n",
      "Epoch 58, Loss: 0.021224284544587135\n",
      "Epoch 59, Loss: 0.02405845746397972\n",
      "Epoch 60, Loss: 0.027367718517780304\n",
      "Epoch 61, Loss: 0.010706816799938679\n",
      "Epoch 62, Loss: 0.00922780018299818\n",
      "Epoch 63, Loss: 0.015103921294212341\n",
      "Epoch 64, Loss: 0.04910731315612793\n",
      "Epoch 65, Loss: 0.009276150725781918\n",
      "Epoch 66, Loss: 0.009205072186887264\n",
      "Epoch 67, Loss: 0.03139455243945122\n",
      "Epoch 68, Loss: 0.021779805421829224\n",
      "Epoch 69, Loss: 0.02071686089038849\n",
      "Epoch 70, Loss: 0.02014406956732273\n",
      "Epoch 71, Loss: 0.007264024578034878\n",
      "Epoch 72, Loss: 0.005181504413485527\n",
      "Epoch 73, Loss: 0.011695337481796741\n",
      "Epoch 74, Loss: 0.02281733974814415\n",
      "Epoch 75, Loss: 0.013601415790617466\n",
      "Epoch 76, Loss: 0.005249985493719578\n",
      "Epoch 77, Loss: 0.017459187656641006\n",
      "Epoch 78, Loss: 0.015393737703561783\n",
      "Epoch 79, Loss: 0.030534595251083374\n",
      "Epoch 80, Loss: 0.012064628303050995\n",
      "Epoch 81, Loss: 0.009482109919190407\n",
      "Epoch 82, Loss: 0.005600044969469309\n",
      "Epoch 83, Loss: 0.010578823275864124\n",
      "Epoch 84, Loss: 0.005751627963036299\n",
      "Epoch 85, Loss: 0.011939321644604206\n",
      "Epoch 86, Loss: 0.01032489724457264\n",
      "Epoch 87, Loss: 0.006107084918767214\n",
      "Epoch 88, Loss: 0.012183749116957188\n",
      "Epoch 89, Loss: 0.0336480550467968\n",
      "Epoch 90, Loss: 0.004972071386873722\n",
      "Epoch 91, Loss: 0.0046334657818078995\n",
      "Epoch 92, Loss: 0.01319502480328083\n",
      "Epoch 93, Loss: 0.010091088712215424\n",
      "Epoch 94, Loss: 0.028186701238155365\n",
      "Epoch 95, Loss: 0.01679239422082901\n",
      "Epoch 96, Loss: 0.009889233857393265\n",
      "Epoch 97, Loss: 0.012457437813282013\n",
      "Epoch 98, Loss: 0.017762010917067528\n",
      "Epoch 99, Loss: 0.0037723795976489782\n",
      "Epoch 100, Loss: 0.0053025116212666035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3792243003845215\n",
      "Epoch 1, Loss: 0.5718405842781067\n",
      "Epoch 2, Loss: 0.9130727052688599\n",
      "Epoch 3, Loss: 0.68182373046875\n",
      "Epoch 4, Loss: 0.5438457131385803\n",
      "Epoch 5, Loss: 0.42653873562812805\n",
      "Epoch 6, Loss: 0.19665896892547607\n",
      "Epoch 7, Loss: 0.6056616902351379\n",
      "Epoch 8, Loss: 0.8795993328094482\n",
      "Epoch 9, Loss: 0.5283858180046082\n",
      "Epoch 10, Loss: 0.35662513971328735\n",
      "Epoch 11, Loss: 0.2821876108646393\n",
      "Epoch 12, Loss: 0.31146782636642456\n",
      "Epoch 13, Loss: 0.34133270382881165\n",
      "Epoch 14, Loss: 0.2499013990163803\n",
      "Epoch 15, Loss: 0.17880931496620178\n",
      "Epoch 16, Loss: 0.30026400089263916\n",
      "Epoch 17, Loss: 0.2562014162540436\n",
      "Epoch 18, Loss: 0.11912800371646881\n",
      "Epoch 19, Loss: 0.1472102254629135\n",
      "Epoch 20, Loss: 0.19587716460227966\n",
      "Epoch 21, Loss: 0.1301027536392212\n",
      "Epoch 22, Loss: 0.33472245931625366\n",
      "Epoch 23, Loss: 0.16682901978492737\n",
      "Epoch 24, Loss: 0.21424002945423126\n",
      "Epoch 25, Loss: 0.07091960310935974\n",
      "Epoch 26, Loss: 0.16199444234371185\n",
      "Epoch 27, Loss: 0.17141970992088318\n",
      "Epoch 28, Loss: 0.05507631599903107\n",
      "Epoch 29, Loss: 0.2549534738063812\n",
      "Epoch 30, Loss: 0.08215783536434174\n",
      "Epoch 31, Loss: 0.11810701340436935\n",
      "Epoch 32, Loss: 0.11841891705989838\n",
      "Epoch 33, Loss: 0.21541883051395416\n",
      "Epoch 34, Loss: 0.10969749093055725\n",
      "Epoch 35, Loss: 0.07026591151952744\n",
      "Epoch 36, Loss: 0.06591971963644028\n",
      "Epoch 37, Loss: 0.041875794529914856\n",
      "Epoch 38, Loss: 0.07738707959651947\n",
      "Epoch 39, Loss: 0.12724098563194275\n",
      "Epoch 40, Loss: 0.12246542423963547\n",
      "Epoch 41, Loss: 0.06190718710422516\n",
      "Epoch 42, Loss: 0.037184879183769226\n",
      "Epoch 43, Loss: 0.07831117510795593\n",
      "Epoch 44, Loss: 0.06918153166770935\n",
      "Epoch 45, Loss: 0.04414729028940201\n",
      "Epoch 46, Loss: 0.026882506906986237\n",
      "Epoch 47, Loss: 0.060209259390830994\n",
      "Epoch 48, Loss: 0.01589474454522133\n",
      "Epoch 49, Loss: 0.03874119743704796\n",
      "Epoch 50, Loss: 0.09501710534095764\n",
      "Epoch 51, Loss: 0.024446789175271988\n",
      "Epoch 52, Loss: 0.02233550325036049\n",
      "Epoch 53, Loss: 0.025862790644168854\n",
      "Epoch 54, Loss: 0.03458705171942711\n",
      "Epoch 55, Loss: 0.022691205143928528\n",
      "Epoch 56, Loss: 0.07589352875947952\n",
      "Epoch 57, Loss: 0.027136819437146187\n",
      "Epoch 58, Loss: 0.060216937214136124\n",
      "Epoch 59, Loss: 0.02750467322766781\n",
      "Epoch 60, Loss: 0.024975694715976715\n",
      "Epoch 61, Loss: 0.025069037452340126\n",
      "Epoch 62, Loss: 0.06715747714042664\n",
      "Epoch 63, Loss: 0.03396134823560715\n",
      "Epoch 64, Loss: 0.016096843406558037\n",
      "Epoch 65, Loss: 0.015134924091398716\n",
      "Epoch 66, Loss: 0.007646684069186449\n",
      "Epoch 67, Loss: 0.01218681875616312\n",
      "Epoch 68, Loss: 0.03845507651567459\n",
      "Epoch 69, Loss: 0.021208705380558968\n",
      "Epoch 70, Loss: 0.01974785327911377\n",
      "Epoch 71, Loss: 0.013157153502106667\n",
      "Epoch 72, Loss: 0.003422745503485203\n",
      "Epoch 73, Loss: 0.01846550777554512\n",
      "Epoch 74, Loss: 0.01771729812026024\n",
      "Epoch 75, Loss: 0.05792069435119629\n",
      "Epoch 76, Loss: 0.02367454767227173\n",
      "Epoch 77, Loss: 0.012855255044996738\n",
      "Epoch 78, Loss: 0.017197320237755775\n",
      "Epoch 79, Loss: 0.012592872604727745\n",
      "Epoch 80, Loss: 0.00871371105313301\n",
      "Epoch 81, Loss: 0.0076098632998764515\n",
      "Epoch 82, Loss: 0.02328457124531269\n",
      "Epoch 83, Loss: 0.00956775527447462\n",
      "Epoch 84, Loss: 0.016314085572957993\n",
      "Epoch 85, Loss: 0.006096584256738424\n",
      "Epoch 86, Loss: 0.020112894475460052\n",
      "Epoch 87, Loss: 0.012750168330967426\n",
      "Epoch 88, Loss: 0.008492190390825272\n",
      "Epoch 89, Loss: 0.010029749944806099\n",
      "Epoch 90, Loss: 0.015590007416903973\n",
      "Epoch 91, Loss: 0.009928647428750992\n",
      "Epoch 92, Loss: 0.014628072269260883\n",
      "Epoch 93, Loss: 0.011697698384523392\n",
      "Epoch 94, Loss: 0.014878283254802227\n",
      "Epoch 95, Loss: 0.023813581094145775\n",
      "Epoch 96, Loss: 0.011986102908849716\n",
      "Epoch 97, Loss: 0.00740095553919673\n",
      "Epoch 98, Loss: 0.013033666647970676\n",
      "Epoch 99, Loss: 0.004743578378111124\n",
      "Epoch 100, Loss: 0.012155426666140556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.472402811050415\n",
      "Epoch 1, Loss: 0.3596338927745819\n",
      "Epoch 2, Loss: 0.5171094536781311\n",
      "Epoch 3, Loss: 0.951330840587616\n",
      "Epoch 4, Loss: 0.3170468211174011\n",
      "Epoch 5, Loss: 0.573302686214447\n",
      "Epoch 6, Loss: 0.9356343150138855\n",
      "Epoch 7, Loss: 1.3411098718643188\n",
      "Epoch 8, Loss: 0.43444961309432983\n",
      "Epoch 9, Loss: 0.19719655811786652\n",
      "Epoch 10, Loss: 0.34995242953300476\n",
      "Epoch 11, Loss: 0.497749924659729\n",
      "Epoch 12, Loss: 0.435347318649292\n",
      "Epoch 13, Loss: 0.2210080623626709\n",
      "Epoch 14, Loss: 0.3049665093421936\n",
      "Epoch 15, Loss: 0.3676246106624603\n",
      "Epoch 16, Loss: 0.17848874628543854\n",
      "Epoch 17, Loss: 0.23460984230041504\n",
      "Epoch 18, Loss: 0.07544323801994324\n",
      "Epoch 19, Loss: 0.13469992578029633\n",
      "Epoch 20, Loss: 0.23638640344142914\n",
      "Epoch 21, Loss: 0.12324897199869156\n",
      "Epoch 22, Loss: 0.16403496265411377\n",
      "Epoch 23, Loss: 0.13889950513839722\n",
      "Epoch 24, Loss: 0.13818784058094025\n",
      "Epoch 25, Loss: 0.21905666589736938\n",
      "Epoch 26, Loss: 0.08836327493190765\n",
      "Epoch 27, Loss: 0.1739126443862915\n",
      "Epoch 28, Loss: 0.07736475020647049\n",
      "Epoch 29, Loss: 0.09361004084348679\n",
      "Epoch 30, Loss: 0.12047278881072998\n",
      "Epoch 31, Loss: 0.056170642375946045\n",
      "Epoch 32, Loss: 0.10440526902675629\n",
      "Epoch 33, Loss: 0.1372872143983841\n",
      "Epoch 34, Loss: 0.051517363637685776\n",
      "Epoch 35, Loss: 0.018774963915348053\n",
      "Epoch 36, Loss: 0.044183507561683655\n",
      "Epoch 37, Loss: 0.03744129836559296\n",
      "Epoch 38, Loss: 0.0400424525141716\n",
      "Epoch 39, Loss: 0.03949062526226044\n",
      "Epoch 40, Loss: 0.029493795707821846\n",
      "Epoch 41, Loss: 0.030977053567767143\n",
      "Epoch 42, Loss: 0.01801203191280365\n",
      "Epoch 43, Loss: 0.07624485343694687\n",
      "Epoch 44, Loss: 0.08409001678228378\n",
      "Epoch 45, Loss: 0.03952794522047043\n",
      "Epoch 46, Loss: 0.015614824369549751\n",
      "Epoch 47, Loss: 0.06904637068510056\n",
      "Epoch 48, Loss: 0.017553193494677544\n",
      "Epoch 49, Loss: 0.0235755555331707\n",
      "Epoch 50, Loss: 0.023291483521461487\n",
      "Epoch 51, Loss: 0.021824143826961517\n",
      "Epoch 52, Loss: 0.012078690342605114\n",
      "Epoch 53, Loss: 0.008047443814575672\n",
      "Epoch 54, Loss: 0.02227199822664261\n",
      "Epoch 55, Loss: 0.009456093423068523\n",
      "Epoch 56, Loss: 0.0352751798927784\n",
      "Epoch 57, Loss: 0.011416354216635227\n",
      "Epoch 58, Loss: 0.00998360849916935\n",
      "Epoch 59, Loss: 0.008395354263484478\n",
      "Epoch 60, Loss: 0.02111532725393772\n",
      "Epoch 61, Loss: 0.01367463544011116\n",
      "Epoch 62, Loss: 0.025961805135011673\n",
      "Epoch 63, Loss: 0.01805189996957779\n",
      "Epoch 64, Loss: 0.014378509484231472\n",
      "Epoch 65, Loss: 0.03832005336880684\n",
      "Epoch 66, Loss: 0.0039802249521017075\n",
      "Epoch 67, Loss: 0.016356706619262695\n",
      "Epoch 68, Loss: 0.01200068835169077\n",
      "Epoch 69, Loss: 0.0065155900083482265\n",
      "Epoch 70, Loss: 0.006139108911156654\n",
      "Epoch 71, Loss: 0.007973643019795418\n",
      "Epoch 72, Loss: 0.015404166653752327\n",
      "Epoch 73, Loss: 0.015142705291509628\n",
      "Epoch 74, Loss: 0.010210910812020302\n",
      "Epoch 75, Loss: 0.021744079887866974\n",
      "Epoch 76, Loss: 0.014698139391839504\n",
      "Epoch 77, Loss: 0.009885664097964764\n",
      "Epoch 78, Loss: 0.014396374113857746\n",
      "Epoch 79, Loss: 0.004342616535723209\n",
      "Epoch 80, Loss: 0.014261303469538689\n",
      "Epoch 81, Loss: 0.015139099210500717\n",
      "Epoch 82, Loss: 0.012055881321430206\n",
      "Epoch 83, Loss: 0.0061425985768437386\n",
      "Epoch 84, Loss: 0.01367967203259468\n",
      "Epoch 85, Loss: 0.01337793841958046\n",
      "Epoch 86, Loss: 0.005101284012198448\n",
      "Epoch 87, Loss: 0.009729105979204178\n",
      "Epoch 88, Loss: 0.008423353545367718\n",
      "Epoch 89, Loss: 0.014088751748204231\n",
      "Epoch 90, Loss: 0.01013399288058281\n",
      "Epoch 91, Loss: 0.008402803912758827\n",
      "Epoch 92, Loss: 0.01822478137910366\n",
      "Epoch 93, Loss: 0.005669644568115473\n",
      "Epoch 94, Loss: 0.008066479116678238\n",
      "Epoch 95, Loss: 0.005553515162318945\n",
      "Epoch 96, Loss: 0.019320152699947357\n",
      "Epoch 97, Loss: 0.0022836318239569664\n",
      "Epoch 98, Loss: 0.013502041809260845\n",
      "Epoch 99, Loss: 0.010115350596606731\n",
      "Epoch 100, Loss: 0.007055310532450676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.1877321004867554\n",
      "Epoch 1, Loss: 0.814881443977356\n",
      "Epoch 2, Loss: 0.36354929208755493\n",
      "Epoch 3, Loss: 0.5440176129341125\n",
      "Epoch 4, Loss: 0.6547613143920898\n",
      "Epoch 5, Loss: 0.6486807465553284\n",
      "Epoch 6, Loss: 0.7125940918922424\n",
      "Epoch 7, Loss: 0.2599281668663025\n",
      "Epoch 8, Loss: 0.23821085691452026\n",
      "Epoch 9, Loss: 0.4493630826473236\n",
      "Epoch 10, Loss: 0.42379942536354065\n",
      "Epoch 11, Loss: 0.30755025148391724\n",
      "Epoch 12, Loss: 0.3311326801776886\n",
      "Epoch 13, Loss: 0.5913896560668945\n",
      "Epoch 14, Loss: 0.2160961627960205\n",
      "Epoch 15, Loss: 0.5922543406486511\n",
      "Epoch 16, Loss: 0.1384860724210739\n",
      "Epoch 17, Loss: 0.29054126143455505\n",
      "Epoch 18, Loss: 0.13010995090007782\n",
      "Epoch 19, Loss: 0.20661185681819916\n",
      "Epoch 20, Loss: 0.10528537631034851\n",
      "Epoch 21, Loss: 0.15076574683189392\n",
      "Epoch 22, Loss: 0.17391808331012726\n",
      "Epoch 23, Loss: 0.14027546346187592\n",
      "Epoch 24, Loss: 0.1201503574848175\n",
      "Epoch 25, Loss: 0.09382364153862\n",
      "Epoch 26, Loss: 0.08404969424009323\n",
      "Epoch 27, Loss: 0.18632705509662628\n",
      "Epoch 28, Loss: 0.04717569053173065\n",
      "Epoch 29, Loss: 0.09427053481340408\n",
      "Epoch 30, Loss: 0.0811619907617569\n",
      "Epoch 31, Loss: 0.03604184836149216\n",
      "Epoch 32, Loss: 0.09273949265480042\n",
      "Epoch 33, Loss: 0.15008684992790222\n",
      "Epoch 34, Loss: 0.042050644755363464\n",
      "Epoch 35, Loss: 0.10034537315368652\n",
      "Epoch 36, Loss: 0.09780319035053253\n",
      "Epoch 37, Loss: 0.01803797110915184\n",
      "Epoch 38, Loss: 0.08312934637069702\n",
      "Epoch 39, Loss: 0.06766307353973389\n",
      "Epoch 40, Loss: 0.061427757143974304\n",
      "Epoch 41, Loss: 0.01747925952076912\n",
      "Epoch 42, Loss: 0.029230764135718346\n",
      "Epoch 43, Loss: 0.05030257999897003\n",
      "Epoch 44, Loss: 0.07123445719480515\n",
      "Epoch 45, Loss: 0.04655168950557709\n",
      "Epoch 46, Loss: 0.014027517288923264\n",
      "Epoch 47, Loss: 0.07016899436712265\n",
      "Epoch 48, Loss: 0.03493468463420868\n",
      "Epoch 49, Loss: 0.02393769472837448\n",
      "Epoch 50, Loss: 0.04918896406888962\n",
      "Epoch 51, Loss: 0.018437150865793228\n",
      "Epoch 52, Loss: 0.04854561388492584\n",
      "Epoch 53, Loss: 0.03887678682804108\n",
      "Epoch 54, Loss: 0.009217025712132454\n",
      "Epoch 55, Loss: 0.03575793281197548\n",
      "Epoch 56, Loss: 0.03171904385089874\n",
      "Epoch 57, Loss: 0.014068045653402805\n",
      "Epoch 58, Loss: 0.03018816001713276\n",
      "Epoch 59, Loss: 0.015333084389567375\n",
      "Epoch 60, Loss: 0.010371197015047073\n",
      "Epoch 61, Loss: 0.014292662031948566\n",
      "Epoch 62, Loss: 0.018141239881515503\n",
      "Epoch 63, Loss: 0.021921776235103607\n",
      "Epoch 64, Loss: 0.09099972993135452\n",
      "Epoch 65, Loss: 0.0712735652923584\n",
      "Epoch 66, Loss: 0.021469727158546448\n",
      "Epoch 67, Loss: 0.03508371114730835\n",
      "Epoch 68, Loss: 0.00887493696063757\n",
      "Epoch 69, Loss: 0.01574822887778282\n",
      "Epoch 70, Loss: 0.008312121033668518\n",
      "Epoch 71, Loss: 0.009603272192180157\n",
      "Epoch 72, Loss: 0.01680813916027546\n",
      "Epoch 73, Loss: 0.011576849035918713\n",
      "Epoch 74, Loss: 0.01696055568754673\n",
      "Epoch 75, Loss: 0.03257365524768829\n",
      "Epoch 76, Loss: 0.010127546265721321\n",
      "Epoch 77, Loss: 0.025537671521306038\n",
      "Epoch 78, Loss: 0.012016239576041698\n",
      "Epoch 79, Loss: 0.004102342762053013\n",
      "Epoch 80, Loss: 0.014134377241134644\n",
      "Epoch 81, Loss: 0.018602145835757256\n",
      "Epoch 82, Loss: 0.006692715920507908\n",
      "Epoch 83, Loss: 0.010055290535092354\n",
      "Epoch 84, Loss: 0.01007947325706482\n",
      "Epoch 85, Loss: 0.03388096019625664\n",
      "Epoch 86, Loss: 0.013977413065731525\n",
      "Epoch 87, Loss: 0.008121076039969921\n",
      "Epoch 88, Loss: 0.009912699460983276\n",
      "Epoch 89, Loss: 0.009363006800413132\n",
      "Epoch 90, Loss: 0.011014983057975769\n",
      "Epoch 91, Loss: 0.007307976484298706\n",
      "Epoch 92, Loss: 0.010936080478131771\n",
      "Epoch 93, Loss: 0.007078748662024736\n",
      "Epoch 94, Loss: 0.010824196971952915\n",
      "Epoch 95, Loss: 0.006252763327211142\n",
      "Epoch 96, Loss: 0.01288975402712822\n",
      "Epoch 97, Loss: 0.008330415934324265\n",
      "Epoch 98, Loss: 0.013678601011633873\n",
      "Epoch 99, Loss: 0.00906118843704462\n",
      "Epoch 100, Loss: 0.2833186984062195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.546100378036499\n",
      "Epoch 1, Loss: 0.5294045209884644\n",
      "Epoch 2, Loss: 1.0015524625778198\n",
      "Epoch 3, Loss: 0.808986485004425\n",
      "Epoch 4, Loss: 0.8240805864334106\n",
      "Epoch 5, Loss: 0.3937614858150482\n",
      "Epoch 6, Loss: 0.4718891680240631\n",
      "Epoch 7, Loss: 0.5973986387252808\n",
      "Epoch 8, Loss: 0.3179357349872589\n",
      "Epoch 9, Loss: 0.3581376075744629\n",
      "Epoch 10, Loss: 0.4259899854660034\n",
      "Epoch 11, Loss: 0.3784583508968353\n",
      "Epoch 12, Loss: 0.1679391711950302\n",
      "Epoch 13, Loss: 0.3763950765132904\n",
      "Epoch 14, Loss: 0.09470676630735397\n",
      "Epoch 15, Loss: 0.11564871668815613\n",
      "Epoch 16, Loss: 0.26046621799468994\n",
      "Epoch 17, Loss: 0.18706358969211578\n",
      "Epoch 18, Loss: 0.2526193857192993\n",
      "Epoch 19, Loss: 0.43919306993484497\n",
      "Epoch 20, Loss: 0.08802863955497742\n",
      "Epoch 21, Loss: 0.08734292536973953\n",
      "Epoch 22, Loss: 0.21920691430568695\n",
      "Epoch 23, Loss: 0.24801485240459442\n",
      "Epoch 24, Loss: 0.20482072234153748\n",
      "Epoch 25, Loss: 0.07377859950065613\n",
      "Epoch 26, Loss: 0.10791770368814468\n",
      "Epoch 27, Loss: 0.22723537683486938\n",
      "Epoch 28, Loss: 0.0956500917673111\n",
      "Epoch 29, Loss: 0.13700248301029205\n",
      "Epoch 30, Loss: 0.013637067750096321\n",
      "Epoch 31, Loss: 0.13659827411174774\n",
      "Epoch 32, Loss: 0.04270986095070839\n",
      "Epoch 33, Loss: 0.06320936232805252\n",
      "Epoch 34, Loss: 0.09928987920284271\n",
      "Epoch 35, Loss: 0.06722524017095566\n",
      "Epoch 36, Loss: 0.04863475635647774\n",
      "Epoch 37, Loss: 0.015696978196501732\n",
      "Epoch 38, Loss: 0.06952594220638275\n",
      "Epoch 39, Loss: 0.02172953262925148\n",
      "Epoch 40, Loss: 0.07898570597171783\n",
      "Epoch 41, Loss: 0.11963723599910736\n",
      "Epoch 42, Loss: 0.025971584022045135\n",
      "Epoch 43, Loss: 0.17711956799030304\n",
      "Epoch 44, Loss: 0.02286526933312416\n",
      "Epoch 45, Loss: 0.021697944030165672\n",
      "Epoch 46, Loss: 0.07414496690034866\n",
      "Epoch 47, Loss: 0.12174493819475174\n",
      "Epoch 48, Loss: 0.045530807226896286\n",
      "Epoch 49, Loss: 0.051723215728998184\n",
      "Epoch 50, Loss: 0.04212739318609238\n",
      "Epoch 51, Loss: 0.011214771308004856\n",
      "Epoch 52, Loss: 0.06836501508951187\n",
      "Epoch 53, Loss: 0.018263544887304306\n",
      "Epoch 54, Loss: 0.026250084862113\n",
      "Epoch 55, Loss: 0.02478630095720291\n",
      "Epoch 56, Loss: 0.017298178747296333\n",
      "Epoch 57, Loss: 0.026063986122608185\n",
      "Epoch 58, Loss: 0.024529170244932175\n",
      "Epoch 59, Loss: 0.03746520355343819\n",
      "Epoch 60, Loss: 0.017743714153766632\n",
      "Epoch 61, Loss: 0.019003858789801598\n",
      "Epoch 62, Loss: 0.008279269561171532\n",
      "Epoch 63, Loss: 0.03930996358394623\n",
      "Epoch 64, Loss: 0.023737844079732895\n",
      "Epoch 65, Loss: 0.009015564806759357\n",
      "Epoch 66, Loss: 0.03449622169137001\n",
      "Epoch 67, Loss: 0.04240982234477997\n",
      "Epoch 68, Loss: 0.025428470224142075\n",
      "Epoch 69, Loss: 0.009302882477641106\n",
      "Epoch 70, Loss: 0.006939100567251444\n",
      "Epoch 71, Loss: 0.022393159568309784\n",
      "Epoch 72, Loss: 0.014946560375392437\n",
      "Epoch 73, Loss: 0.019272275269031525\n",
      "Epoch 74, Loss: 0.03601718321442604\n",
      "Epoch 75, Loss: 0.033712975680828094\n",
      "Epoch 76, Loss: 0.018062366172671318\n",
      "Epoch 77, Loss: 0.020789392292499542\n",
      "Epoch 78, Loss: 0.012899025343358517\n",
      "Epoch 79, Loss: 0.01336736511439085\n",
      "Epoch 80, Loss: 0.009877615608274937\n",
      "Epoch 81, Loss: 0.023046249523758888\n",
      "Epoch 82, Loss: 0.010155369527637959\n",
      "Epoch 83, Loss: 0.0067722913809120655\n",
      "Epoch 84, Loss: 0.012273190543055534\n",
      "Epoch 85, Loss: 0.014923620969057083\n",
      "Epoch 86, Loss: 0.006178983952850103\n",
      "Epoch 87, Loss: 0.010322894901037216\n",
      "Epoch 88, Loss: 0.009664616547524929\n",
      "Epoch 89, Loss: 0.016366353258490562\n",
      "Epoch 90, Loss: 0.00766669400036335\n",
      "Epoch 91, Loss: 0.007169301155954599\n",
      "Epoch 92, Loss: 0.015701156109571457\n",
      "Epoch 93, Loss: 0.0065116435289382935\n",
      "Epoch 94, Loss: 0.008915971964597702\n",
      "Epoch 95, Loss: 0.012113121338188648\n",
      "Epoch 96, Loss: 0.013811726123094559\n",
      "Epoch 97, Loss: 0.005773527082055807\n",
      "Epoch 98, Loss: 0.009875258430838585\n",
      "Epoch 99, Loss: 0.004855811595916748\n",
      "Epoch 100, Loss: 0.00544546265155077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.4314570426940918\n",
      "Epoch 1, Loss: 0.6979097127914429\n",
      "Epoch 2, Loss: 1.116674542427063\n",
      "Epoch 3, Loss: 0.5054311752319336\n",
      "Epoch 4, Loss: 1.3749855756759644\n",
      "Epoch 5, Loss: 0.6079561710357666\n",
      "Epoch 6, Loss: 0.7364670634269714\n",
      "Epoch 7, Loss: 0.3133176565170288\n",
      "Epoch 8, Loss: 0.5274736881256104\n",
      "Epoch 9, Loss: 1.0054702758789062\n",
      "Epoch 10, Loss: 0.15826621651649475\n",
      "Epoch 11, Loss: 0.4091067612171173\n",
      "Epoch 12, Loss: 0.26173391938209534\n",
      "Epoch 13, Loss: 0.20208901166915894\n",
      "Epoch 14, Loss: 0.26623907685279846\n",
      "Epoch 15, Loss: 0.1586570143699646\n",
      "Epoch 16, Loss: 0.18848960101604462\n",
      "Epoch 17, Loss: 0.2851365804672241\n",
      "Epoch 18, Loss: 0.29887017607688904\n",
      "Epoch 19, Loss: 0.24359141290187836\n",
      "Epoch 20, Loss: 0.3991333246231079\n",
      "Epoch 21, Loss: 0.22049763798713684\n",
      "Epoch 22, Loss: 0.27403566241264343\n",
      "Epoch 23, Loss: 0.16238920390605927\n",
      "Epoch 24, Loss: 0.14187616109848022\n",
      "Epoch 25, Loss: 0.12740474939346313\n",
      "Epoch 26, Loss: 0.07664378732442856\n",
      "Epoch 27, Loss: 0.08727427572011948\n",
      "Epoch 28, Loss: 0.05382801592350006\n",
      "Epoch 29, Loss: 0.2954879701137543\n",
      "Epoch 30, Loss: 0.06020631268620491\n",
      "Epoch 31, Loss: 0.16257412731647491\n",
      "Epoch 32, Loss: 0.16324478387832642\n",
      "Epoch 33, Loss: 0.0389060340821743\n",
      "Epoch 34, Loss: 0.03496848791837692\n",
      "Epoch 35, Loss: 0.09975264966487885\n",
      "Epoch 36, Loss: 0.041465409100055695\n",
      "Epoch 37, Loss: 0.059827499091625214\n",
      "Epoch 38, Loss: 0.022087134420871735\n",
      "Epoch 39, Loss: 0.04545007273554802\n",
      "Epoch 40, Loss: 0.024689145386219025\n",
      "Epoch 41, Loss: 0.03817400708794594\n",
      "Epoch 42, Loss: 0.03325148671865463\n",
      "Epoch 43, Loss: 0.0206603966653347\n",
      "Epoch 44, Loss: 0.05089397728443146\n",
      "Epoch 45, Loss: 0.014255119487643242\n",
      "Epoch 46, Loss: 0.05366067215800285\n",
      "Epoch 47, Loss: 0.02339678630232811\n",
      "Epoch 48, Loss: 0.03552345931529999\n",
      "Epoch 49, Loss: 0.04262819141149521\n",
      "Epoch 50, Loss: 0.02395446226000786\n",
      "Epoch 51, Loss: 0.08232812583446503\n",
      "Epoch 52, Loss: 0.015323145315051079\n",
      "Epoch 53, Loss: 0.023266861215233803\n",
      "Epoch 54, Loss: 0.05736684054136276\n",
      "Epoch 55, Loss: 0.01998315006494522\n",
      "Epoch 56, Loss: 0.027027331292629242\n",
      "Epoch 57, Loss: 0.006796746049076319\n",
      "Epoch 58, Loss: 0.08636195957660675\n",
      "Epoch 59, Loss: 0.019418122246861458\n",
      "Epoch 60, Loss: 0.024126393720507622\n",
      "Epoch 61, Loss: 0.020147554576396942\n",
      "Epoch 62, Loss: 0.02553398720920086\n",
      "Epoch 63, Loss: 0.0065001556649804115\n",
      "Epoch 64, Loss: 0.007749458309262991\n",
      "Epoch 65, Loss: 0.007772859651595354\n",
      "Epoch 66, Loss: 0.023149902001023293\n",
      "Epoch 67, Loss: 0.02041775733232498\n",
      "Epoch 68, Loss: 0.03311985358595848\n",
      "Epoch 69, Loss: 0.0185542032122612\n",
      "Epoch 70, Loss: 0.028174689039587975\n",
      "Epoch 71, Loss: 0.022603273391723633\n",
      "Epoch 72, Loss: 0.015241455286741257\n",
      "Epoch 73, Loss: 0.010753531008958817\n",
      "Epoch 74, Loss: 0.011500652879476547\n",
      "Epoch 75, Loss: 0.007844548672437668\n",
      "Epoch 76, Loss: 0.01584736816585064\n",
      "Epoch 77, Loss: 0.016968509182333946\n",
      "Epoch 78, Loss: 0.010743189603090286\n",
      "Epoch 79, Loss: 0.018295777961611748\n",
      "Epoch 80, Loss: 0.0178818516433239\n",
      "Epoch 81, Loss: 0.018910536542534828\n",
      "Epoch 82, Loss: 0.008592605590820312\n",
      "Epoch 83, Loss: 0.01045609638094902\n",
      "Epoch 84, Loss: 0.007093785330653191\n",
      "Epoch 85, Loss: 0.016095347702503204\n",
      "Epoch 86, Loss: 0.01893525756895542\n",
      "Epoch 87, Loss: 0.014873211272060871\n",
      "Epoch 88, Loss: 0.009710323065519333\n",
      "Epoch 89, Loss: 0.009942671284079552\n",
      "Epoch 90, Loss: 0.0075651430524885654\n",
      "Epoch 91, Loss: 0.010015430860221386\n",
      "Epoch 92, Loss: 0.009311852045357227\n",
      "Epoch 93, Loss: 0.011867652647197247\n",
      "Epoch 94, Loss: 0.002818587701767683\n",
      "Epoch 95, Loss: 0.010062804445624352\n",
      "Epoch 96, Loss: 0.007058069109916687\n",
      "Epoch 97, Loss: 0.005645548924803734\n",
      "Epoch 98, Loss: 0.00943504087626934\n",
      "Epoch 99, Loss: 0.0282462015748024\n",
      "Epoch 100, Loss: 0.008031213656067848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.399329662322998\n",
      "Epoch 1, Loss: 1.96774423122406\n",
      "Epoch 2, Loss: 0.41746392846107483\n",
      "Epoch 3, Loss: 0.4479297399520874\n",
      "Epoch 4, Loss: 0.3864883482456207\n",
      "Epoch 5, Loss: 0.3920307457447052\n",
      "Epoch 6, Loss: 0.7458210587501526\n",
      "Epoch 7, Loss: 0.38830411434173584\n",
      "Epoch 8, Loss: 0.5149976015090942\n",
      "Epoch 9, Loss: 0.40753263235092163\n",
      "Epoch 10, Loss: 0.4534914791584015\n",
      "Epoch 11, Loss: 0.26774704456329346\n",
      "Epoch 12, Loss: 0.32586050033569336\n",
      "Epoch 13, Loss: 0.1806817650794983\n",
      "Epoch 14, Loss: 0.39178040623664856\n",
      "Epoch 15, Loss: 0.2582038640975952\n",
      "Epoch 16, Loss: 0.13311010599136353\n",
      "Epoch 17, Loss: 0.2645834684371948\n",
      "Epoch 18, Loss: 0.2549331486225128\n",
      "Epoch 19, Loss: 0.19060809910297394\n",
      "Epoch 20, Loss: 0.13031528890132904\n",
      "Epoch 21, Loss: 0.13450652360916138\n",
      "Epoch 22, Loss: 0.06122877076268196\n",
      "Epoch 23, Loss: 0.10467585921287537\n",
      "Epoch 24, Loss: 0.15886610746383667\n",
      "Epoch 25, Loss: 0.15333616733551025\n",
      "Epoch 26, Loss: 0.1455332338809967\n",
      "Epoch 27, Loss: 0.1686885803937912\n",
      "Epoch 28, Loss: 0.08825553953647614\n",
      "Epoch 29, Loss: 0.09669286012649536\n",
      "Epoch 30, Loss: 0.09127749502658844\n",
      "Epoch 31, Loss: 0.02731647901237011\n",
      "Epoch 32, Loss: 0.10364756733179092\n",
      "Epoch 33, Loss: 0.04551863297820091\n",
      "Epoch 34, Loss: 0.04447370767593384\n",
      "Epoch 35, Loss: 0.1590973287820816\n",
      "Epoch 36, Loss: 0.05720590054988861\n",
      "Epoch 37, Loss: 0.042777881026268005\n",
      "Epoch 38, Loss: 0.062280528247356415\n",
      "Epoch 39, Loss: 0.01769608072936535\n",
      "Epoch 40, Loss: 0.07479244470596313\n",
      "Epoch 41, Loss: 0.05310999974608421\n",
      "Epoch 42, Loss: 0.05387786403298378\n",
      "Epoch 43, Loss: 0.08417097479104996\n",
      "Epoch 44, Loss: 0.05012772977352142\n",
      "Epoch 45, Loss: 0.02283286675810814\n",
      "Epoch 46, Loss: 0.04673342406749725\n",
      "Epoch 47, Loss: 0.012486116960644722\n",
      "Epoch 48, Loss: 0.020735444501042366\n",
      "Epoch 49, Loss: 0.04215375334024429\n",
      "Epoch 50, Loss: 0.07077977806329727\n",
      "Epoch 51, Loss: 0.026520196348428726\n",
      "Epoch 52, Loss: 0.0164652056992054\n",
      "Epoch 53, Loss: 0.02016272395849228\n",
      "Epoch 54, Loss: 0.03583386540412903\n",
      "Epoch 55, Loss: 0.05257822573184967\n",
      "Epoch 56, Loss: 0.04082866385579109\n",
      "Epoch 57, Loss: 0.016063466668128967\n",
      "Epoch 58, Loss: 0.01688298024237156\n",
      "Epoch 59, Loss: 0.01551901176571846\n",
      "Epoch 60, Loss: 0.01733984611928463\n",
      "Epoch 61, Loss: 0.016194576397538185\n",
      "Epoch 62, Loss: 0.025354085490107536\n",
      "Epoch 63, Loss: 0.059751614928245544\n",
      "Epoch 64, Loss: 0.02766956016421318\n",
      "Epoch 65, Loss: 0.01846962794661522\n",
      "Epoch 66, Loss: 0.019706496968865395\n",
      "Epoch 67, Loss: 0.020263001322746277\n",
      "Epoch 68, Loss: 0.008174431510269642\n",
      "Epoch 69, Loss: 0.006561385001987219\n",
      "Epoch 70, Loss: 0.02171006053686142\n",
      "Epoch 71, Loss: 0.014798790216445923\n",
      "Epoch 72, Loss: 0.018873779103159904\n",
      "Epoch 73, Loss: 0.013468099758028984\n",
      "Epoch 74, Loss: 0.006809965707361698\n",
      "Epoch 75, Loss: 0.04828722029924393\n",
      "Epoch 76, Loss: 0.019362539052963257\n",
      "Epoch 77, Loss: 0.009006751701235771\n",
      "Epoch 78, Loss: 0.013407516293227673\n",
      "Epoch 79, Loss: 0.014324769377708435\n",
      "Epoch 80, Loss: 0.004323767498135567\n",
      "Epoch 81, Loss: 0.019918302074074745\n",
      "Epoch 82, Loss: 0.024422282353043556\n",
      "Epoch 83, Loss: 0.014445500448346138\n",
      "Epoch 84, Loss: 0.024481281638145447\n",
      "Epoch 85, Loss: 0.01684538461267948\n",
      "Epoch 86, Loss: 0.013463218696415424\n",
      "Epoch 87, Loss: 0.011700427159667015\n",
      "Epoch 88, Loss: 0.049443453550338745\n",
      "Epoch 89, Loss: 0.03860495984554291\n",
      "Epoch 90, Loss: 0.016101878136396408\n",
      "Epoch 91, Loss: 0.011784672737121582\n",
      "Epoch 92, Loss: 0.0040778727270662785\n",
      "Epoch 93, Loss: 0.00890235137194395\n",
      "Epoch 94, Loss: 0.005469034891575575\n",
      "Epoch 95, Loss: 0.0098370760679245\n",
      "Epoch 96, Loss: 0.010530360974371433\n",
      "Epoch 97, Loss: 0.006842117290943861\n",
      "Epoch 98, Loss: 0.005589069798588753\n",
      "Epoch 99, Loss: 0.006320469081401825\n",
      "Epoch 100, Loss: 0.005762733519077301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3468151092529297\n",
      "Epoch 1, Loss: 1.0201292037963867\n",
      "Epoch 2, Loss: 0.462634414434433\n",
      "Epoch 3, Loss: 0.3582043945789337\n",
      "Epoch 4, Loss: 0.3981814384460449\n",
      "Epoch 5, Loss: 0.3213443160057068\n",
      "Epoch 6, Loss: 0.5463208556175232\n",
      "Epoch 7, Loss: 0.474914014339447\n",
      "Epoch 8, Loss: 0.33502474427223206\n",
      "Epoch 9, Loss: 0.3478185534477234\n",
      "Epoch 10, Loss: 0.2050284743309021\n",
      "Epoch 11, Loss: 0.49127280712127686\n",
      "Epoch 12, Loss: 0.09854995459318161\n",
      "Epoch 13, Loss: 0.19353830814361572\n",
      "Epoch 14, Loss: 0.6018840670585632\n",
      "Epoch 15, Loss: 0.5198314189910889\n",
      "Epoch 16, Loss: 0.21733607351779938\n",
      "Epoch 17, Loss: 0.1063559278845787\n",
      "Epoch 18, Loss: 0.14022761583328247\n",
      "Epoch 19, Loss: 0.17118218541145325\n",
      "Epoch 20, Loss: 0.12151852995157242\n",
      "Epoch 21, Loss: 0.24049012362957\n",
      "Epoch 22, Loss: 0.07868561893701553\n",
      "Epoch 23, Loss: 0.1499621421098709\n",
      "Epoch 24, Loss: 0.10933661460876465\n",
      "Epoch 25, Loss: 0.2548266053199768\n",
      "Epoch 26, Loss: 0.038936275988817215\n",
      "Epoch 27, Loss: 0.10847510397434235\n",
      "Epoch 28, Loss: 0.05092746764421463\n",
      "Epoch 29, Loss: 0.10696881264448166\n",
      "Epoch 30, Loss: 0.07039198279380798\n",
      "Epoch 31, Loss: 0.07351680845022202\n",
      "Epoch 32, Loss: 0.06832065433263779\n",
      "Epoch 33, Loss: 0.05191803351044655\n",
      "Epoch 34, Loss: 0.03835229575634003\n",
      "Epoch 35, Loss: 0.028502874076366425\n",
      "Epoch 36, Loss: 0.06378012150526047\n",
      "Epoch 37, Loss: 0.05022035539150238\n",
      "Epoch 38, Loss: 0.05343971401453018\n",
      "Epoch 39, Loss: 0.06634219735860825\n",
      "Epoch 40, Loss: 0.03933887183666229\n",
      "Epoch 41, Loss: 0.09302828460931778\n",
      "Epoch 42, Loss: 0.022287517786026\n",
      "Epoch 43, Loss: 0.04068132862448692\n",
      "Epoch 44, Loss: 0.07801496237516403\n",
      "Epoch 45, Loss: 0.03139834851026535\n",
      "Epoch 46, Loss: 0.13811323046684265\n",
      "Epoch 47, Loss: 0.11139045655727386\n",
      "Epoch 48, Loss: 0.07719705998897552\n",
      "Epoch 49, Loss: 0.01402433030307293\n",
      "Epoch 50, Loss: 0.009172780439257622\n",
      "Epoch 51, Loss: 0.03386007249355316\n",
      "Epoch 52, Loss: 0.008243822492659092\n",
      "Epoch 53, Loss: 0.006957239471375942\n",
      "Epoch 54, Loss: 0.018998241052031517\n",
      "Epoch 55, Loss: 0.009241611696779728\n",
      "Epoch 56, Loss: 0.02448674850165844\n",
      "Epoch 57, Loss: 0.01670835167169571\n",
      "Epoch 58, Loss: 0.02338205836713314\n",
      "Epoch 59, Loss: 0.018882710486650467\n",
      "Epoch 60, Loss: 0.05198279023170471\n",
      "Epoch 61, Loss: 0.023679321631789207\n",
      "Epoch 62, Loss: 0.008165685459971428\n",
      "Epoch 63, Loss: 0.02154822088778019\n",
      "Epoch 64, Loss: 0.02039051428437233\n",
      "Epoch 65, Loss: 0.032228365540504456\n",
      "Epoch 66, Loss: 0.0117151765152812\n",
      "Epoch 67, Loss: 0.013557839207351208\n",
      "Epoch 68, Loss: 0.013862278312444687\n",
      "Epoch 69, Loss: 0.02021862380206585\n",
      "Epoch 70, Loss: 0.014292160980403423\n",
      "Epoch 71, Loss: 0.06536004692316055\n",
      "Epoch 72, Loss: 0.03755110502243042\n",
      "Epoch 73, Loss: 0.01434586476534605\n",
      "Epoch 74, Loss: 0.0319998562335968\n",
      "Epoch 75, Loss: 0.010821250267326832\n",
      "Epoch 76, Loss: 0.020813070237636566\n",
      "Epoch 77, Loss: 0.009429587051272392\n",
      "Epoch 78, Loss: 0.015141425654292107\n",
      "Epoch 79, Loss: 0.023430490866303444\n",
      "Epoch 80, Loss: 0.029439644888043404\n",
      "Epoch 81, Loss: 0.011085540987551212\n",
      "Epoch 82, Loss: 0.0075956424698233604\n",
      "Epoch 83, Loss: 0.019767476245760918\n",
      "Epoch 84, Loss: 0.007256477139890194\n",
      "Epoch 85, Loss: 0.01317660417407751\n",
      "Epoch 86, Loss: 0.005391380749642849\n",
      "Epoch 87, Loss: 0.008350861258804798\n",
      "Epoch 88, Loss: 0.01029870193451643\n",
      "Epoch 89, Loss: 0.028514351695775986\n",
      "Epoch 90, Loss: 0.012680631130933762\n",
      "Epoch 91, Loss: 0.009156523272395134\n",
      "Epoch 92, Loss: 0.01523507758975029\n",
      "Epoch 93, Loss: 0.018680362030863762\n",
      "Epoch 94, Loss: 0.008152895607054234\n",
      "Epoch 95, Loss: 0.004766663070768118\n",
      "Epoch 96, Loss: 0.02293132059276104\n",
      "Epoch 97, Loss: 0.010839487425982952\n",
      "Epoch 98, Loss: 0.010805140249431133\n",
      "Epoch 99, Loss: 0.004759408067911863\n",
      "Epoch 100, Loss: 0.006000025663524866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3759568929672241\n",
      "Epoch 1, Loss: 0.5097171068191528\n",
      "Epoch 2, Loss: 0.8025163412094116\n",
      "Epoch 3, Loss: 0.39046216011047363\n",
      "Epoch 4, Loss: 0.8187434673309326\n",
      "Epoch 5, Loss: 0.6725366115570068\n",
      "Epoch 6, Loss: 0.7261967062950134\n",
      "Epoch 7, Loss: 0.2519298791885376\n",
      "Epoch 8, Loss: 0.7347333431243896\n",
      "Epoch 9, Loss: 0.2861412465572357\n",
      "Epoch 10, Loss: 0.20262952148914337\n",
      "Epoch 11, Loss: 0.3952673375606537\n",
      "Epoch 12, Loss: 0.36291754245758057\n",
      "Epoch 13, Loss: 0.21825408935546875\n",
      "Epoch 14, Loss: 0.43340039253234863\n",
      "Epoch 15, Loss: 0.5759027004241943\n",
      "Epoch 16, Loss: 0.13770581781864166\n",
      "Epoch 17, Loss: 0.18745967745780945\n",
      "Epoch 18, Loss: 0.2190818041563034\n",
      "Epoch 19, Loss: 0.3017512559890747\n",
      "Epoch 20, Loss: 0.17510640621185303\n",
      "Epoch 21, Loss: 0.14929044246673584\n",
      "Epoch 22, Loss: 0.1929212212562561\n",
      "Epoch 23, Loss: 0.1370338797569275\n",
      "Epoch 24, Loss: 0.21744988858699799\n",
      "Epoch 25, Loss: 0.05589458718895912\n",
      "Epoch 26, Loss: 0.04230917990207672\n",
      "Epoch 27, Loss: 0.15933172404766083\n",
      "Epoch 28, Loss: 0.09621528536081314\n",
      "Epoch 29, Loss: 0.17829746007919312\n",
      "Epoch 30, Loss: 0.09338226169347763\n",
      "Epoch 31, Loss: 0.03137771040201187\n",
      "Epoch 32, Loss: 0.14215901494026184\n",
      "Epoch 33, Loss: 0.1935010701417923\n",
      "Epoch 34, Loss: 0.12707315385341644\n",
      "Epoch 35, Loss: 0.11401069164276123\n",
      "Epoch 36, Loss: 0.07044601440429688\n",
      "Epoch 37, Loss: 0.10181443393230438\n",
      "Epoch 38, Loss: 0.05086697265505791\n",
      "Epoch 39, Loss: 0.06256112456321716\n",
      "Epoch 40, Loss: 0.03735131770372391\n",
      "Epoch 41, Loss: 0.09374412894248962\n",
      "Epoch 42, Loss: 0.03042846918106079\n",
      "Epoch 43, Loss: 0.020389152690768242\n",
      "Epoch 44, Loss: 0.04881514608860016\n",
      "Epoch 45, Loss: 0.04554649442434311\n",
      "Epoch 46, Loss: 0.11097750067710876\n",
      "Epoch 47, Loss: 0.0558210089802742\n",
      "Epoch 48, Loss: 0.038727983832359314\n",
      "Epoch 49, Loss: 0.03804384171962738\n",
      "Epoch 50, Loss: 0.015609260648488998\n",
      "Epoch 51, Loss: 0.03297905996441841\n",
      "Epoch 52, Loss: 0.024721931666135788\n",
      "Epoch 53, Loss: 0.023661518469452858\n",
      "Epoch 54, Loss: 0.04269503429532051\n",
      "Epoch 55, Loss: 0.02415456622838974\n",
      "Epoch 56, Loss: 0.09429417550563812\n",
      "Epoch 57, Loss: 0.08458909392356873\n",
      "Epoch 58, Loss: 0.028188109397888184\n",
      "Epoch 59, Loss: 0.02992374636232853\n",
      "Epoch 60, Loss: 0.03009653091430664\n",
      "Epoch 61, Loss: 0.022702518850564957\n",
      "Epoch 62, Loss: 0.020635120570659637\n",
      "Epoch 63, Loss: 0.017378145828843117\n",
      "Epoch 64, Loss: 0.013055969960987568\n",
      "Epoch 65, Loss: 0.01676834002137184\n",
      "Epoch 66, Loss: 0.007370756007730961\n",
      "Epoch 67, Loss: 0.08139754086732864\n",
      "Epoch 68, Loss: 0.049747634679079056\n",
      "Epoch 69, Loss: 0.013013485819101334\n",
      "Epoch 70, Loss: 0.0403963103890419\n",
      "Epoch 71, Loss: 0.014401490800082684\n",
      "Epoch 72, Loss: 0.021327205002307892\n",
      "Epoch 73, Loss: 0.016148574650287628\n",
      "Epoch 74, Loss: 0.016655612736940384\n",
      "Epoch 75, Loss: 0.03735654428601265\n",
      "Epoch 76, Loss: 0.0308283269405365\n",
      "Epoch 77, Loss: 0.052401069551706314\n",
      "Epoch 78, Loss: 0.011907363310456276\n",
      "Epoch 79, Loss: 0.007948736660182476\n",
      "Epoch 80, Loss: 0.010014481842517853\n",
      "Epoch 81, Loss: 0.008844729512929916\n",
      "Epoch 82, Loss: 0.01817118190228939\n",
      "Epoch 83, Loss: 0.006415140815079212\n",
      "Epoch 84, Loss: 0.11703881621360779\n",
      "Epoch 85, Loss: 0.00896767619997263\n",
      "Epoch 86, Loss: 0.02897075191140175\n",
      "Epoch 87, Loss: 0.010559318587183952\n",
      "Epoch 88, Loss: 0.00602343212813139\n",
      "Epoch 89, Loss: 0.006134651601314545\n",
      "Epoch 90, Loss: 0.03507021814584732\n",
      "Epoch 91, Loss: 0.011547048576176167\n",
      "Epoch 92, Loss: 0.0035388311371207237\n",
      "Epoch 93, Loss: 0.007886968553066254\n",
      "Epoch 94, Loss: 0.0074638924561440945\n",
      "Epoch 95, Loss: 0.00644326489418745\n",
      "Epoch 96, Loss: 0.009059421718120575\n",
      "Epoch 97, Loss: 0.010470489971339703\n",
      "Epoch 98, Loss: 0.013538748025894165\n",
      "Epoch 99, Loss: 0.024544166401028633\n",
      "Epoch 100, Loss: 0.015872985124588013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.4309613704681396\n",
      "Epoch 1, Loss: 0.7575916647911072\n",
      "Epoch 2, Loss: 0.4662347435951233\n",
      "Epoch 3, Loss: 0.6225182414054871\n",
      "Epoch 4, Loss: 0.5705574750900269\n",
      "Epoch 5, Loss: 0.4686538875102997\n",
      "Epoch 6, Loss: 0.3656892776489258\n",
      "Epoch 7, Loss: 1.1425983905792236\n",
      "Epoch 8, Loss: 0.27266353368759155\n",
      "Epoch 9, Loss: 0.3524245619773865\n",
      "Epoch 10, Loss: 0.825829267501831\n",
      "Epoch 11, Loss: 0.7349245548248291\n",
      "Epoch 12, Loss: 0.230892151594162\n",
      "Epoch 13, Loss: 0.33454784750938416\n",
      "Epoch 14, Loss: 0.5437451601028442\n",
      "Epoch 15, Loss: 0.20309172570705414\n",
      "Epoch 16, Loss: 0.21012873947620392\n",
      "Epoch 17, Loss: 0.16161882877349854\n",
      "Epoch 18, Loss: 0.27975040674209595\n",
      "Epoch 19, Loss: 0.21521444618701935\n",
      "Epoch 20, Loss: 0.2593478262424469\n",
      "Epoch 21, Loss: 0.19381524622440338\n",
      "Epoch 22, Loss: 0.23135249316692352\n",
      "Epoch 23, Loss: 0.043640900403261185\n",
      "Epoch 24, Loss: 0.0989016517996788\n",
      "Epoch 25, Loss: 0.1975420117378235\n",
      "Epoch 26, Loss: 0.19791042804718018\n",
      "Epoch 27, Loss: 0.1880614310503006\n",
      "Epoch 28, Loss: 0.3304389715194702\n",
      "Epoch 29, Loss: 0.10120716691017151\n",
      "Epoch 30, Loss: 0.09992372989654541\n",
      "Epoch 31, Loss: 0.1593649983406067\n",
      "Epoch 32, Loss: 0.041130222380161285\n",
      "Epoch 33, Loss: 0.056027863174676895\n",
      "Epoch 34, Loss: 0.0574786514043808\n",
      "Epoch 35, Loss: 0.04983888939023018\n",
      "Epoch 36, Loss: 0.07568570971488953\n",
      "Epoch 37, Loss: 0.09197451919317245\n",
      "Epoch 38, Loss: 0.11134306341409683\n",
      "Epoch 39, Loss: 0.09180551767349243\n",
      "Epoch 40, Loss: 0.07176114618778229\n",
      "Epoch 41, Loss: 0.0098856957629323\n",
      "Epoch 42, Loss: 0.14675937592983246\n",
      "Epoch 43, Loss: 0.08401837944984436\n",
      "Epoch 44, Loss: 0.11055844277143478\n",
      "Epoch 45, Loss: 0.10320714116096497\n",
      "Epoch 46, Loss: 0.0513920858502388\n",
      "Epoch 47, Loss: 0.04671819135546684\n",
      "Epoch 48, Loss: 0.03783967345952988\n",
      "Epoch 49, Loss: 0.0224247258156538\n",
      "Epoch 50, Loss: 0.021059000864624977\n",
      "Epoch 51, Loss: 0.04850341007113457\n",
      "Epoch 52, Loss: 0.027523549273610115\n",
      "Epoch 53, Loss: 0.036734044551849365\n",
      "Epoch 54, Loss: 0.017739245668053627\n",
      "Epoch 55, Loss: 0.20002296566963196\n",
      "Epoch 56, Loss: 0.05354282259941101\n",
      "Epoch 57, Loss: 0.030460285022854805\n",
      "Epoch 58, Loss: 0.039044223725795746\n",
      "Epoch 59, Loss: 0.06099507585167885\n",
      "Epoch 60, Loss: 0.03859094902873039\n",
      "Epoch 61, Loss: 0.01239898893982172\n",
      "Epoch 62, Loss: 0.020579664036631584\n",
      "Epoch 63, Loss: 0.007547939661890268\n",
      "Epoch 64, Loss: 0.026830092072486877\n",
      "Epoch 65, Loss: 0.032972272485494614\n",
      "Epoch 66, Loss: 0.020869459956884384\n",
      "Epoch 67, Loss: 0.031019316986203194\n",
      "Epoch 68, Loss: 0.027853943407535553\n",
      "Epoch 69, Loss: 0.012342466972768307\n",
      "Epoch 70, Loss: 0.01681482046842575\n",
      "Epoch 71, Loss: 0.016795706003904343\n",
      "Epoch 72, Loss: 0.01676686480641365\n",
      "Epoch 73, Loss: 0.010896413587033749\n",
      "Epoch 74, Loss: 0.02199930138885975\n",
      "Epoch 75, Loss: 0.016878217458724976\n",
      "Epoch 76, Loss: 0.018311699852347374\n",
      "Epoch 77, Loss: 0.029283765703439713\n",
      "Epoch 78, Loss: 0.018418679013848305\n",
      "Epoch 79, Loss: 0.018991287797689438\n",
      "Epoch 80, Loss: 0.009749841876327991\n",
      "Epoch 81, Loss: 0.023090774193406105\n",
      "Epoch 82, Loss: 0.01578015647828579\n",
      "Epoch 83, Loss: 0.03937983512878418\n",
      "Epoch 84, Loss: 0.010790807195007801\n",
      "Epoch 85, Loss: 0.00600300170481205\n",
      "Epoch 86, Loss: 0.006786895450204611\n",
      "Epoch 87, Loss: 0.04437574744224548\n",
      "Epoch 88, Loss: 0.004127490799874067\n",
      "Epoch 89, Loss: 0.015572592616081238\n",
      "Epoch 90, Loss: 0.030337609350681305\n",
      "Epoch 91, Loss: 0.014594856649637222\n",
      "Epoch 92, Loss: 0.0062609342858195305\n",
      "Epoch 93, Loss: 0.048310182988643646\n",
      "Epoch 94, Loss: 0.04257528483867645\n",
      "Epoch 95, Loss: 0.009359423071146011\n",
      "Epoch 96, Loss: 0.006124855950474739\n",
      "Epoch 97, Loss: 0.011070260778069496\n",
      "Epoch 98, Loss: 0.006499336566776037\n",
      "Epoch 99, Loss: 0.005845349282026291\n",
      "Epoch 100, Loss: 0.009808728471398354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.4845423698425293\n",
      "Epoch 1, Loss: 0.46988433599472046\n",
      "Epoch 2, Loss: 0.6493868827819824\n",
      "Epoch 3, Loss: 0.9308452606201172\n",
      "Epoch 4, Loss: 0.47838857769966125\n",
      "Epoch 5, Loss: 0.648037314414978\n",
      "Epoch 6, Loss: 0.30615925788879395\n",
      "Epoch 7, Loss: 0.24092096090316772\n",
      "Epoch 8, Loss: 0.2830710709095001\n",
      "Epoch 9, Loss: 0.3713195323944092\n",
      "Epoch 10, Loss: 0.5520244836807251\n",
      "Epoch 11, Loss: 0.7212357521057129\n",
      "Epoch 12, Loss: 0.24725352227687836\n",
      "Epoch 13, Loss: 0.34331783652305603\n",
      "Epoch 14, Loss: 0.08879115432500839\n",
      "Epoch 15, Loss: 0.22483499348163605\n",
      "Epoch 16, Loss: 0.37938255071640015\n",
      "Epoch 17, Loss: 0.25049877166748047\n",
      "Epoch 18, Loss: 0.2059662640094757\n",
      "Epoch 19, Loss: 0.08720111846923828\n",
      "Epoch 20, Loss: 0.13443565368652344\n",
      "Epoch 21, Loss: 0.27209749817848206\n",
      "Epoch 22, Loss: 0.2718871235847473\n",
      "Epoch 23, Loss: 0.11204596608877182\n",
      "Epoch 24, Loss: 0.3232809603214264\n",
      "Epoch 25, Loss: 0.08120081573724747\n",
      "Epoch 26, Loss: 0.04330272600054741\n",
      "Epoch 27, Loss: 0.1585223376750946\n",
      "Epoch 28, Loss: 0.25680679082870483\n",
      "Epoch 29, Loss: 0.06390837579965591\n",
      "Epoch 30, Loss: 0.032202694565057755\n",
      "Epoch 31, Loss: 0.12214365601539612\n",
      "Epoch 32, Loss: 0.08381719142198563\n",
      "Epoch 33, Loss: 0.17353476583957672\n",
      "Epoch 34, Loss: 0.029871119186282158\n",
      "Epoch 35, Loss: 0.04651447758078575\n",
      "Epoch 36, Loss: 0.1302642673254013\n",
      "Epoch 37, Loss: 0.11444336920976639\n",
      "Epoch 38, Loss: 0.11048348248004913\n",
      "Epoch 39, Loss: 0.18001651763916016\n",
      "Epoch 40, Loss: 0.019338661804795265\n",
      "Epoch 41, Loss: 0.0908229649066925\n",
      "Epoch 42, Loss: 0.02343422919511795\n",
      "Epoch 43, Loss: 0.04019065201282501\n",
      "Epoch 44, Loss: 0.04340674728155136\n",
      "Epoch 45, Loss: 0.04387062415480614\n",
      "Epoch 46, Loss: 0.035976510494947433\n",
      "Epoch 47, Loss: 0.025482995435595512\n",
      "Epoch 48, Loss: 0.05167225003242493\n",
      "Epoch 49, Loss: 0.050198450684547424\n",
      "Epoch 50, Loss: 0.014438431710004807\n",
      "Epoch 51, Loss: 0.030696583911776543\n",
      "Epoch 52, Loss: 0.018474942073225975\n",
      "Epoch 53, Loss: 0.028864413499832153\n",
      "Epoch 54, Loss: 0.021508842706680298\n",
      "Epoch 55, Loss: 0.015670593827962875\n",
      "Epoch 56, Loss: 0.03540445864200592\n",
      "Epoch 57, Loss: 0.03829888999462128\n",
      "Epoch 58, Loss: 0.00903589278459549\n",
      "Epoch 59, Loss: 0.021301232278347015\n",
      "Epoch 60, Loss: 0.014632459729909897\n",
      "Epoch 61, Loss: 0.00976942665874958\n",
      "Epoch 62, Loss: 0.014858433045446873\n",
      "Epoch 63, Loss: 0.022842692211270332\n",
      "Epoch 64, Loss: 0.003725451650097966\n",
      "Epoch 65, Loss: 0.017959661781787872\n",
      "Epoch 66, Loss: 0.026338480412960052\n",
      "Epoch 67, Loss: 0.01606559380888939\n",
      "Epoch 68, Loss: 0.007115911226719618\n",
      "Epoch 69, Loss: 0.007805986329913139\n",
      "Epoch 70, Loss: 0.009023429825901985\n",
      "Epoch 71, Loss: 0.025478627532720566\n",
      "Epoch 72, Loss: 0.007950727827847004\n",
      "Epoch 73, Loss: 0.05275346711277962\n",
      "Epoch 74, Loss: 0.017193442210555077\n",
      "Epoch 75, Loss: 0.013294034637510777\n",
      "Epoch 76, Loss: 0.007929613813757896\n",
      "Epoch 77, Loss: 0.009453076869249344\n",
      "Epoch 78, Loss: 0.022993100807070732\n",
      "Epoch 79, Loss: 0.05014238506555557\n",
      "Epoch 80, Loss: 0.016401542350649834\n",
      "Epoch 81, Loss: 0.03181581571698189\n",
      "Epoch 82, Loss: 0.01850009895861149\n",
      "Epoch 83, Loss: 0.021295033395290375\n",
      "Epoch 84, Loss: 0.010019087232649326\n",
      "Epoch 85, Loss: 0.03773052245378494\n",
      "Epoch 86, Loss: 0.008186119608581066\n",
      "Epoch 87, Loss: 0.005333802197128534\n",
      "Epoch 88, Loss: 0.005919858813285828\n",
      "Epoch 89, Loss: 0.00846115592867136\n",
      "Epoch 90, Loss: 0.001666459022089839\n",
      "Epoch 91, Loss: 0.004168800078332424\n",
      "Epoch 92, Loss: 0.004912618547677994\n",
      "Epoch 93, Loss: 0.010297665372490883\n",
      "Epoch 94, Loss: 0.0047090561129152775\n",
      "Epoch 95, Loss: 0.013196195475757122\n",
      "Epoch 96, Loss: 0.006816206034272909\n",
      "Epoch 97, Loss: 0.0031130071729421616\n",
      "Epoch 98, Loss: 0.0072097498923540115\n",
      "Epoch 99, Loss: 0.09675510227680206\n",
      "Epoch 100, Loss: 0.007101053837686777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.407391905784607\n",
      "Epoch 1, Loss: 0.6797402501106262\n",
      "Epoch 2, Loss: 1.247821569442749\n",
      "Epoch 3, Loss: 1.0520769357681274\n",
      "Epoch 4, Loss: 0.4626442492008209\n",
      "Epoch 5, Loss: 0.6881530284881592\n",
      "Epoch 6, Loss: 1.601432204246521\n",
      "Epoch 7, Loss: 0.45485231280326843\n",
      "Epoch 8, Loss: 0.625679075717926\n",
      "Epoch 9, Loss: 0.6188792586326599\n",
      "Epoch 10, Loss: 0.3019935190677643\n",
      "Epoch 11, Loss: 0.6327693462371826\n",
      "Epoch 12, Loss: 0.5739868879318237\n",
      "Epoch 13, Loss: 0.21149665117263794\n",
      "Epoch 14, Loss: 0.40014147758483887\n",
      "Epoch 15, Loss: 0.25966930389404297\n",
      "Epoch 16, Loss: 0.2757314443588257\n",
      "Epoch 17, Loss: 0.23325592279434204\n",
      "Epoch 18, Loss: 0.43568694591522217\n",
      "Epoch 19, Loss: 0.1530170440673828\n",
      "Epoch 20, Loss: 0.23652611672878265\n",
      "Epoch 21, Loss: 0.2404487431049347\n",
      "Epoch 22, Loss: 0.06765852123498917\n",
      "Epoch 23, Loss: 0.09051914513111115\n",
      "Epoch 24, Loss: 0.13518117368221283\n",
      "Epoch 25, Loss: 0.10044871270656586\n",
      "Epoch 26, Loss: 0.07341020554304123\n",
      "Epoch 27, Loss: 0.21413888037204742\n",
      "Epoch 28, Loss: 0.09593682736158371\n",
      "Epoch 29, Loss: 0.09866168349981308\n",
      "Epoch 30, Loss: 0.10076072812080383\n",
      "Epoch 31, Loss: 0.014711052179336548\n",
      "Epoch 32, Loss: 0.094985730946064\n",
      "Epoch 33, Loss: 0.13999255001544952\n",
      "Epoch 34, Loss: 0.1060614138841629\n",
      "Epoch 35, Loss: 0.09936267882585526\n",
      "Epoch 36, Loss: 0.046981751918792725\n",
      "Epoch 37, Loss: 0.03977684676647186\n",
      "Epoch 38, Loss: 0.0330633744597435\n",
      "Epoch 39, Loss: 0.05120672285556793\n",
      "Epoch 40, Loss: 0.0791843831539154\n",
      "Epoch 41, Loss: 0.07716632634401321\n",
      "Epoch 42, Loss: 0.05606784299015999\n",
      "Epoch 43, Loss: 0.08565638214349747\n",
      "Epoch 44, Loss: 0.03443804383277893\n",
      "Epoch 45, Loss: 0.016912493854761124\n",
      "Epoch 46, Loss: 0.0467449389398098\n",
      "Epoch 47, Loss: 0.024241015315055847\n",
      "Epoch 48, Loss: 0.04455850273370743\n",
      "Epoch 49, Loss: 0.029360957443714142\n",
      "Epoch 50, Loss: 0.03002752549946308\n",
      "Epoch 51, Loss: 0.03286479413509369\n",
      "Epoch 52, Loss: 0.02733808197081089\n",
      "Epoch 53, Loss: 0.06393764913082123\n",
      "Epoch 54, Loss: 0.05877937376499176\n",
      "Epoch 55, Loss: 0.01597735844552517\n",
      "Epoch 56, Loss: 0.05770637467503548\n",
      "Epoch 57, Loss: 0.014497469179332256\n",
      "Epoch 58, Loss: 0.015422680415213108\n",
      "Epoch 59, Loss: 0.019004393368959427\n",
      "Epoch 60, Loss: 0.04565544053912163\n",
      "Epoch 61, Loss: 0.01643199846148491\n",
      "Epoch 62, Loss: 0.0072976574301719666\n",
      "Epoch 63, Loss: 0.028105292469263077\n",
      "Epoch 64, Loss: 0.015513057820498943\n",
      "Epoch 65, Loss: 0.013662661425769329\n",
      "Epoch 66, Loss: 0.003661978989839554\n",
      "Epoch 67, Loss: 0.009675485081970692\n",
      "Epoch 68, Loss: 0.007141714915633202\n",
      "Epoch 69, Loss: 0.009010666981339455\n",
      "Epoch 70, Loss: 0.02382812276482582\n",
      "Epoch 71, Loss: 0.011421370320022106\n",
      "Epoch 72, Loss: 0.01069277711212635\n",
      "Epoch 73, Loss: 0.014025051146745682\n",
      "Epoch 74, Loss: 0.010777329094707966\n",
      "Epoch 75, Loss: 0.0055768173187971115\n",
      "Epoch 76, Loss: 0.011485802009701729\n",
      "Epoch 77, Loss: 0.010436326265335083\n",
      "Epoch 78, Loss: 0.006000053137540817\n",
      "Epoch 79, Loss: 0.024273298680782318\n",
      "Epoch 80, Loss: 0.006646808702498674\n",
      "Epoch 81, Loss: 0.04852098226547241\n",
      "Epoch 82, Loss: 0.01972024142742157\n",
      "Epoch 83, Loss: 0.005556537304073572\n",
      "Epoch 84, Loss: 0.016734713688492775\n",
      "Epoch 85, Loss: 0.02279287949204445\n",
      "Epoch 86, Loss: 0.03625050187110901\n",
      "Epoch 87, Loss: 0.012505649589002132\n",
      "Epoch 88, Loss: 0.012224321253597736\n",
      "Epoch 89, Loss: 0.011038295924663544\n",
      "Epoch 90, Loss: 0.005770470947027206\n",
      "Epoch 91, Loss: 0.006609425880014896\n",
      "Epoch 92, Loss: 0.0078031206503510475\n",
      "Epoch 93, Loss: 0.008283848874270916\n",
      "Epoch 94, Loss: 0.007142375688999891\n",
      "Epoch 95, Loss: 0.007305563427507877\n",
      "Epoch 96, Loss: 0.0051180776208639145\n",
      "Epoch 97, Loss: 0.012588690035045147\n",
      "Epoch 98, Loss: 0.007719715591520071\n",
      "Epoch 99, Loss: 0.010402650572359562\n",
      "Epoch 100, Loss: 0.014615633524954319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.4285731315612793\n",
      "Epoch 1, Loss: 0.35961663722991943\n",
      "Epoch 2, Loss: 0.7980830669403076\n",
      "Epoch 3, Loss: 0.7500565052032471\n",
      "Epoch 4, Loss: 0.6313101649284363\n",
      "Epoch 5, Loss: 0.5839491486549377\n",
      "Epoch 6, Loss: 0.4765923321247101\n",
      "Epoch 7, Loss: 0.3835338056087494\n",
      "Epoch 8, Loss: 0.47858306765556335\n",
      "Epoch 9, Loss: 0.31085264682769775\n",
      "Epoch 10, Loss: 0.6693718433380127\n",
      "Epoch 11, Loss: 0.19759893417358398\n",
      "Epoch 12, Loss: 0.49468475580215454\n",
      "Epoch 13, Loss: 0.4558374583721161\n",
      "Epoch 14, Loss: 0.19452829658985138\n",
      "Epoch 15, Loss: 0.24562032520771027\n",
      "Epoch 16, Loss: 0.1881639063358307\n",
      "Epoch 17, Loss: 0.4133535325527191\n",
      "Epoch 18, Loss: 0.1489459127187729\n",
      "Epoch 19, Loss: 0.35193151235580444\n",
      "Epoch 20, Loss: 0.37263673543930054\n",
      "Epoch 21, Loss: 0.20664848387241364\n",
      "Epoch 22, Loss: 0.19343572854995728\n",
      "Epoch 23, Loss: 0.2977027893066406\n",
      "Epoch 24, Loss: 0.24352484941482544\n",
      "Epoch 25, Loss: 0.2612406015396118\n",
      "Epoch 26, Loss: 0.22178471088409424\n",
      "Epoch 27, Loss: 0.09170642495155334\n",
      "Epoch 28, Loss: 0.13177861273288727\n",
      "Epoch 29, Loss: 0.30833494663238525\n",
      "Epoch 30, Loss: 0.25452062487602234\n",
      "Epoch 31, Loss: 0.07875718176364899\n",
      "Epoch 32, Loss: 0.049920618534088135\n",
      "Epoch 33, Loss: 0.1996152102947235\n",
      "Epoch 34, Loss: 0.05606404319405556\n",
      "Epoch 35, Loss: 0.08944521844387054\n",
      "Epoch 36, Loss: 0.0581810399889946\n",
      "Epoch 37, Loss: 0.08573418110609055\n",
      "Epoch 38, Loss: 0.07876154780387878\n",
      "Epoch 39, Loss: 0.01419017743319273\n",
      "Epoch 40, Loss: 0.06582603603601456\n",
      "Epoch 41, Loss: 0.04803843051195145\n",
      "Epoch 42, Loss: 0.039788875728845596\n",
      "Epoch 43, Loss: 0.0806853324174881\n",
      "Epoch 44, Loss: 0.061328452080488205\n",
      "Epoch 45, Loss: 0.02033020555973053\n",
      "Epoch 46, Loss: 0.02924131602048874\n",
      "Epoch 47, Loss: 0.06122346594929695\n",
      "Epoch 48, Loss: 0.031461939215660095\n",
      "Epoch 49, Loss: 0.10205558687448502\n",
      "Epoch 50, Loss: 0.041331276297569275\n",
      "Epoch 51, Loss: 0.022460848093032837\n",
      "Epoch 52, Loss: 0.030872635543346405\n",
      "Epoch 53, Loss: 0.014198294840753078\n",
      "Epoch 54, Loss: 0.043763790279626846\n",
      "Epoch 55, Loss: 0.030005518347024918\n",
      "Epoch 56, Loss: 0.04864579066634178\n",
      "Epoch 57, Loss: 0.023880643770098686\n",
      "Epoch 58, Loss: 0.0496651716530323\n",
      "Epoch 59, Loss: 0.020266659557819366\n",
      "Epoch 60, Loss: 0.05127352476119995\n",
      "Epoch 61, Loss: 0.03808186575770378\n",
      "Epoch 62, Loss: 0.047397080808877945\n",
      "Epoch 63, Loss: 0.0234688613563776\n",
      "Epoch 64, Loss: 0.05691041424870491\n",
      "Epoch 65, Loss: 0.02141747623682022\n",
      "Epoch 66, Loss: 0.028139399364590645\n",
      "Epoch 67, Loss: 0.013284627348184586\n",
      "Epoch 68, Loss: 0.016268305480480194\n",
      "Epoch 69, Loss: 0.01688903570175171\n",
      "Epoch 70, Loss: 0.020553719252347946\n",
      "Epoch 71, Loss: 0.017574992030858994\n",
      "Epoch 72, Loss: 0.015111993998289108\n",
      "Epoch 73, Loss: 0.021439243108034134\n",
      "Epoch 74, Loss: 0.021900303661823273\n",
      "Epoch 75, Loss: 0.007454936858266592\n",
      "Epoch 76, Loss: 0.028349194675683975\n",
      "Epoch 77, Loss: 0.02120050974190235\n",
      "Epoch 78, Loss: 0.030643301084637642\n",
      "Epoch 79, Loss: 0.011173989623785019\n",
      "Epoch 80, Loss: 0.0310027077794075\n",
      "Epoch 81, Loss: 0.020707007497549057\n",
      "Epoch 82, Loss: 0.01391643937677145\n",
      "Epoch 83, Loss: 0.007706412114202976\n",
      "Epoch 84, Loss: 0.01826007105410099\n",
      "Epoch 85, Loss: 0.01276229228824377\n",
      "Epoch 86, Loss: 0.013026256114244461\n",
      "Epoch 87, Loss: 0.012242194265127182\n",
      "Epoch 88, Loss: 0.00878029502928257\n",
      "Epoch 89, Loss: 0.005335040390491486\n",
      "Epoch 90, Loss: 0.008390353061258793\n",
      "Epoch 91, Loss: 0.01162654347717762\n",
      "Epoch 92, Loss: 0.014462434686720371\n",
      "Epoch 93, Loss: 0.03460724651813507\n",
      "Epoch 94, Loss: 0.009594591334462166\n",
      "Epoch 95, Loss: 0.009093886241316795\n",
      "Epoch 96, Loss: 0.008056937716901302\n",
      "Epoch 97, Loss: 0.008604214526712894\n",
      "Epoch 98, Loss: 0.00811140425503254\n",
      "Epoch 99, Loss: 0.024050427600741386\n",
      "Epoch 100, Loss: 0.01734066940844059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.6590638160705566\n",
      "Epoch 1, Loss: 0.5132060050964355\n",
      "Epoch 2, Loss: 0.6164244413375854\n",
      "Epoch 3, Loss: 1.0789604187011719\n",
      "Epoch 4, Loss: 0.7138796448707581\n",
      "Epoch 5, Loss: 0.39331090450286865\n",
      "Epoch 6, Loss: 0.8221439719200134\n",
      "Epoch 7, Loss: 0.3727550804615021\n",
      "Epoch 8, Loss: 0.5858302116394043\n",
      "Epoch 9, Loss: 0.45401376485824585\n",
      "Epoch 10, Loss: 0.42284566164016724\n",
      "Epoch 11, Loss: 0.19246472418308258\n",
      "Epoch 12, Loss: 0.14758378267288208\n",
      "Epoch 13, Loss: 0.41141900420188904\n",
      "Epoch 14, Loss: 0.15722529590129852\n",
      "Epoch 15, Loss: 0.21808487176895142\n",
      "Epoch 16, Loss: 0.2215009182691574\n",
      "Epoch 17, Loss: 0.20596949756145477\n",
      "Epoch 18, Loss: 0.24805086851119995\n",
      "Epoch 19, Loss: 0.29110366106033325\n",
      "Epoch 20, Loss: 0.2609809637069702\n",
      "Epoch 21, Loss: 0.217984139919281\n",
      "Epoch 22, Loss: 0.15564560890197754\n",
      "Epoch 23, Loss: 0.0955529436469078\n",
      "Epoch 24, Loss: 0.29997655749320984\n",
      "Epoch 25, Loss: 0.16195929050445557\n",
      "Epoch 26, Loss: 0.12893694639205933\n",
      "Epoch 27, Loss: 0.32935941219329834\n",
      "Epoch 28, Loss: 0.10810454189777374\n",
      "Epoch 29, Loss: 0.10580799728631973\n",
      "Epoch 30, Loss: 0.2578343451023102\n",
      "Epoch 31, Loss: 0.06017370522022247\n",
      "Epoch 32, Loss: 0.07996740937232971\n",
      "Epoch 33, Loss: 0.2039041966199875\n",
      "Epoch 34, Loss: 0.040926817804574966\n",
      "Epoch 35, Loss: 0.09642314910888672\n",
      "Epoch 36, Loss: 0.04111411049962044\n",
      "Epoch 37, Loss: 0.03038991242647171\n",
      "Epoch 38, Loss: 0.07498763501644135\n",
      "Epoch 39, Loss: 0.09199700504541397\n",
      "Epoch 40, Loss: 0.04378913342952728\n",
      "Epoch 41, Loss: 0.03525322675704956\n",
      "Epoch 42, Loss: 0.07005555927753448\n",
      "Epoch 43, Loss: 0.025794796645641327\n",
      "Epoch 44, Loss: 0.04468804597854614\n",
      "Epoch 45, Loss: 0.03375929221510887\n",
      "Epoch 46, Loss: 0.03196817636489868\n",
      "Epoch 47, Loss: 0.017613844946026802\n",
      "Epoch 48, Loss: 0.01700560748577118\n",
      "Epoch 49, Loss: 0.057595815509557724\n",
      "Epoch 50, Loss: 0.05463259294629097\n",
      "Epoch 51, Loss: 0.09089677035808563\n",
      "Epoch 52, Loss: 0.05744185671210289\n",
      "Epoch 53, Loss: 0.022153042256832123\n",
      "Epoch 54, Loss: 0.06781430542469025\n",
      "Epoch 55, Loss: 0.027725858613848686\n",
      "Epoch 56, Loss: 0.011834653094410896\n",
      "Epoch 57, Loss: 0.015799997374415398\n",
      "Epoch 58, Loss: 0.04921351373195648\n",
      "Epoch 59, Loss: 0.07333435118198395\n",
      "Epoch 60, Loss: 0.03299594298005104\n",
      "Epoch 61, Loss: 0.0207973625510931\n",
      "Epoch 62, Loss: 0.012406566180288792\n",
      "Epoch 63, Loss: 0.05057542026042938\n",
      "Epoch 64, Loss: 0.014012078754603863\n",
      "Epoch 65, Loss: 0.01953548938035965\n",
      "Epoch 66, Loss: 0.010299399495124817\n",
      "Epoch 67, Loss: 0.01911565288901329\n",
      "Epoch 68, Loss: 0.020728502422571182\n",
      "Epoch 69, Loss: 0.02997726947069168\n",
      "Epoch 70, Loss: 0.04461560398340225\n",
      "Epoch 71, Loss: 0.031027469784021378\n",
      "Epoch 72, Loss: 0.036541566252708435\n",
      "Epoch 73, Loss: 0.02157866582274437\n",
      "Epoch 74, Loss: 0.01170098315924406\n",
      "Epoch 75, Loss: 0.01035219058394432\n",
      "Epoch 76, Loss: 0.02335553988814354\n",
      "Epoch 77, Loss: 0.025066224858164787\n",
      "Epoch 78, Loss: 0.010033871978521347\n",
      "Epoch 79, Loss: 0.014427821151912212\n",
      "Epoch 80, Loss: 0.012533110566437244\n",
      "Epoch 81, Loss: 0.021094169467687607\n",
      "Epoch 82, Loss: 0.01361932698637247\n",
      "Epoch 83, Loss: 0.05200372263789177\n",
      "Epoch 84, Loss: 0.00803869403898716\n",
      "Epoch 85, Loss: 0.014881327748298645\n",
      "Epoch 86, Loss: 0.006808961741626263\n",
      "Epoch 87, Loss: 0.006558116991072893\n",
      "Epoch 88, Loss: 0.006096703000366688\n",
      "Epoch 89, Loss: 0.010464522987604141\n",
      "Epoch 90, Loss: 0.012571197003126144\n",
      "Epoch 91, Loss: 0.0135654266923666\n",
      "Epoch 92, Loss: 0.00591993797570467\n",
      "Epoch 93, Loss: 0.010312640108168125\n",
      "Epoch 94, Loss: 0.03023003228008747\n",
      "Epoch 95, Loss: 0.01348219346255064\n",
      "Epoch 96, Loss: 0.0058318874798715115\n",
      "Epoch 97, Loss: 0.008031357079744339\n",
      "Epoch 98, Loss: 0.006167263258248568\n",
      "Epoch 99, Loss: 0.011527003720402718\n",
      "Epoch 100, Loss: 0.054786890745162964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.371457815170288\n",
      "Epoch 1, Loss: 0.6902607679367065\n",
      "Epoch 2, Loss: 0.4218289852142334\n",
      "Epoch 3, Loss: 0.5482367277145386\n",
      "Epoch 4, Loss: 0.5164965391159058\n",
      "Epoch 5, Loss: 0.24966208636760712\n",
      "Epoch 6, Loss: 0.33754682540893555\n",
      "Epoch 7, Loss: 0.73177170753479\n",
      "Epoch 8, Loss: 0.40199244022369385\n",
      "Epoch 9, Loss: 0.38424813747406006\n",
      "Epoch 10, Loss: 0.3664436638355255\n",
      "Epoch 11, Loss: 0.2739969491958618\n",
      "Epoch 12, Loss: 0.36334460973739624\n",
      "Epoch 13, Loss: 0.1961311548948288\n",
      "Epoch 14, Loss: 0.17833366990089417\n",
      "Epoch 15, Loss: 0.26043832302093506\n",
      "Epoch 16, Loss: 0.24809496104717255\n",
      "Epoch 17, Loss: 0.15965040028095245\n",
      "Epoch 18, Loss: 0.11839568614959717\n",
      "Epoch 19, Loss: 0.14062227308750153\n",
      "Epoch 20, Loss: 0.23536880314350128\n",
      "Epoch 21, Loss: 0.5121304988861084\n",
      "Epoch 22, Loss: 0.0994468554854393\n",
      "Epoch 23, Loss: 0.09813323616981506\n",
      "Epoch 24, Loss: 0.23195046186447144\n",
      "Epoch 25, Loss: 0.07598941773176193\n",
      "Epoch 26, Loss: 0.49512025713920593\n",
      "Epoch 27, Loss: 0.08470771461725235\n",
      "Epoch 28, Loss: 0.1094321757555008\n",
      "Epoch 29, Loss: 0.058054402470588684\n",
      "Epoch 30, Loss: 0.05657510459423065\n",
      "Epoch 31, Loss: 0.17688867449760437\n",
      "Epoch 32, Loss: 0.10793578624725342\n",
      "Epoch 33, Loss: 0.08824918419122696\n",
      "Epoch 34, Loss: 0.08554166555404663\n",
      "Epoch 35, Loss: 0.04549708589911461\n",
      "Epoch 36, Loss: 0.1362757533788681\n",
      "Epoch 37, Loss: 0.13219083845615387\n",
      "Epoch 38, Loss: 0.08853001147508621\n",
      "Epoch 39, Loss: 0.034970421344041824\n",
      "Epoch 40, Loss: 0.09535100311040878\n",
      "Epoch 41, Loss: 0.051141951233148575\n",
      "Epoch 42, Loss: 0.05361147224903107\n",
      "Epoch 43, Loss: 0.058841101825237274\n",
      "Epoch 44, Loss: 0.05126608908176422\n",
      "Epoch 45, Loss: 0.010244475677609444\n",
      "Epoch 46, Loss: 0.08737806230783463\n",
      "Epoch 47, Loss: 0.018951883539557457\n",
      "Epoch 48, Loss: 0.029296644032001495\n",
      "Epoch 49, Loss: 0.027505770325660706\n",
      "Epoch 50, Loss: 0.015775052830576897\n",
      "Epoch 51, Loss: 0.04679271951317787\n",
      "Epoch 52, Loss: 0.052056074142456055\n",
      "Epoch 53, Loss: 0.044632136821746826\n",
      "Epoch 54, Loss: 0.026487920433282852\n",
      "Epoch 55, Loss: 0.017545800656080246\n",
      "Epoch 56, Loss: 0.019977137446403503\n",
      "Epoch 57, Loss: 0.020477168262004852\n",
      "Epoch 58, Loss: 0.016015034168958664\n",
      "Epoch 59, Loss: 0.03378766030073166\n",
      "Epoch 60, Loss: 0.024284524843096733\n",
      "Epoch 61, Loss: 0.017755120992660522\n",
      "Epoch 62, Loss: 0.006184724625200033\n",
      "Epoch 63, Loss: 0.03852570056915283\n",
      "Epoch 64, Loss: 0.009245440363883972\n",
      "Epoch 65, Loss: 0.023566000163555145\n",
      "Epoch 66, Loss: 0.013246512040495872\n",
      "Epoch 67, Loss: 0.026414014399051666\n",
      "Epoch 68, Loss: 0.016007594764232635\n",
      "Epoch 69, Loss: 0.012162857688963413\n",
      "Epoch 70, Loss: 0.03726863116025925\n",
      "Epoch 71, Loss: 0.012441867962479591\n",
      "Epoch 72, Loss: 0.010230103507637978\n",
      "Epoch 73, Loss: 0.011026285588741302\n",
      "Epoch 74, Loss: 0.014717374928295612\n",
      "Epoch 75, Loss: 0.014959459193050861\n",
      "Epoch 76, Loss: 0.015268526040017605\n",
      "Epoch 77, Loss: 0.010553460568189621\n",
      "Epoch 78, Loss: 0.017042767256498337\n",
      "Epoch 79, Loss: 0.009937816299498081\n",
      "Epoch 80, Loss: 0.016591452062129974\n",
      "Epoch 81, Loss: 0.012934618629515171\n",
      "Epoch 82, Loss: 0.005576559342443943\n",
      "Epoch 83, Loss: 0.04685531556606293\n",
      "Epoch 84, Loss: 0.013035716488957405\n",
      "Epoch 85, Loss: 0.01497057918459177\n",
      "Epoch 86, Loss: 0.01779981516301632\n",
      "Epoch 87, Loss: 0.012516088783740997\n",
      "Epoch 88, Loss: 0.010206280276179314\n",
      "Epoch 89, Loss: 0.013947829604148865\n",
      "Epoch 90, Loss: 0.0097893625497818\n",
      "Epoch 91, Loss: 0.008826559409499168\n",
      "Epoch 92, Loss: 0.020577825605869293\n",
      "Epoch 93, Loss: 0.008774792775511742\n",
      "Epoch 94, Loss: 0.00965835154056549\n",
      "Epoch 95, Loss: 0.008456931449472904\n",
      "Epoch 96, Loss: 0.01109409425407648\n",
      "Epoch 97, Loss: 0.013292222283780575\n",
      "Epoch 98, Loss: 0.006493112072348595\n",
      "Epoch 99, Loss: 0.007527714129537344\n",
      "Epoch 100, Loss: 0.01438609417527914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.463031530380249\n",
      "Epoch 1, Loss: 1.1656975746154785\n",
      "Epoch 2, Loss: 0.46582236886024475\n",
      "Epoch 3, Loss: 0.8614597320556641\n",
      "Epoch 4, Loss: 0.32117921113967896\n",
      "Epoch 5, Loss: 0.9151473641395569\n",
      "Epoch 6, Loss: 0.2360154241323471\n",
      "Epoch 7, Loss: 0.29968583583831787\n",
      "Epoch 8, Loss: 0.5602585077285767\n",
      "Epoch 9, Loss: 0.1833457350730896\n",
      "Epoch 10, Loss: 0.5022753477096558\n",
      "Epoch 11, Loss: 0.17493844032287598\n",
      "Epoch 12, Loss: 0.11289742588996887\n",
      "Epoch 13, Loss: 0.36399781703948975\n",
      "Epoch 14, Loss: 0.5361640453338623\n",
      "Epoch 15, Loss: 0.09314853698015213\n",
      "Epoch 16, Loss: 0.3167917728424072\n",
      "Epoch 17, Loss: 0.18278765678405762\n",
      "Epoch 18, Loss: 0.15220941603183746\n",
      "Epoch 19, Loss: 0.12452957034111023\n",
      "Epoch 20, Loss: 0.3033997118473053\n",
      "Epoch 21, Loss: 0.1474764049053192\n",
      "Epoch 22, Loss: 0.08562661707401276\n",
      "Epoch 23, Loss: 0.1620938628911972\n",
      "Epoch 24, Loss: 0.1260397732257843\n",
      "Epoch 25, Loss: 0.1894979625940323\n",
      "Epoch 26, Loss: 0.1362655609846115\n",
      "Epoch 27, Loss: 0.08192421495914459\n",
      "Epoch 28, Loss: 0.4561234712600708\n",
      "Epoch 29, Loss: 0.20679205656051636\n",
      "Epoch 30, Loss: 0.06500270962715149\n",
      "Epoch 31, Loss: 0.08498083800077438\n",
      "Epoch 32, Loss: 0.19707761704921722\n",
      "Epoch 33, Loss: 0.05586849898099899\n",
      "Epoch 34, Loss: 0.11661937832832336\n",
      "Epoch 35, Loss: 0.0728122666478157\n",
      "Epoch 36, Loss: 0.07856310158967972\n",
      "Epoch 37, Loss: 0.1670888364315033\n",
      "Epoch 38, Loss: 0.05079902336001396\n",
      "Epoch 39, Loss: 0.09978963434696198\n",
      "Epoch 40, Loss: 0.12694266438484192\n",
      "Epoch 41, Loss: 0.07098627835512161\n",
      "Epoch 42, Loss: 0.07779976725578308\n",
      "Epoch 43, Loss: 0.07994753867387772\n",
      "Epoch 44, Loss: 0.07280139625072479\n",
      "Epoch 45, Loss: 0.0408293716609478\n",
      "Epoch 46, Loss: 0.07114848494529724\n",
      "Epoch 47, Loss: 0.15694041550159454\n",
      "Epoch 48, Loss: 0.0375320240855217\n",
      "Epoch 49, Loss: 0.04348614439368248\n",
      "Epoch 50, Loss: 0.044584959745407104\n",
      "Epoch 51, Loss: 0.08910953998565674\n",
      "Epoch 52, Loss: 0.04792967066168785\n",
      "Epoch 53, Loss: 0.049009423702955246\n",
      "Epoch 54, Loss: 0.026414481922984123\n",
      "Epoch 55, Loss: 0.018394503742456436\n",
      "Epoch 56, Loss: 0.015874849632382393\n",
      "Epoch 57, Loss: 0.05338868871331215\n",
      "Epoch 58, Loss: 0.06743807345628738\n",
      "Epoch 59, Loss: 0.03834114968776703\n",
      "Epoch 60, Loss: 0.031925465911626816\n",
      "Epoch 61, Loss: 0.01961139403283596\n",
      "Epoch 62, Loss: 0.03261810541152954\n",
      "Epoch 63, Loss: 0.04621129482984543\n",
      "Epoch 64, Loss: 0.0220445916056633\n",
      "Epoch 65, Loss: 0.030826397240161896\n",
      "Epoch 66, Loss: 0.04649893566966057\n",
      "Epoch 67, Loss: 0.017133107408881187\n",
      "Epoch 68, Loss: 0.1250530332326889\n",
      "Epoch 69, Loss: 0.015280391089618206\n",
      "Epoch 70, Loss: 0.06598769128322601\n",
      "Epoch 71, Loss: 0.016241783276200294\n",
      "Epoch 72, Loss: 0.008622007444500923\n",
      "Epoch 73, Loss: 0.013189274817705154\n",
      "Epoch 74, Loss: 0.018313102424144745\n",
      "Epoch 75, Loss: 0.01879044435918331\n",
      "Epoch 76, Loss: 0.01570776291191578\n",
      "Epoch 77, Loss: 0.011530686169862747\n",
      "Epoch 78, Loss: 0.01156571414321661\n",
      "Epoch 79, Loss: 0.014072307385504246\n",
      "Epoch 80, Loss: 0.011093683540821075\n",
      "Epoch 81, Loss: 0.021651554852724075\n",
      "Epoch 82, Loss: 0.006823664531111717\n",
      "Epoch 83, Loss: 0.12927497923374176\n",
      "Epoch 84, Loss: 0.00946392584592104\n",
      "Epoch 85, Loss: 0.012015236541628838\n",
      "Epoch 86, Loss: 0.008399071171879768\n",
      "Epoch 87, Loss: 0.012930161319673061\n",
      "Epoch 88, Loss: 0.006380182225257158\n",
      "Epoch 89, Loss: 0.04019483923912048\n",
      "Epoch 90, Loss: 0.011045009829103947\n",
      "Epoch 91, Loss: 0.018900243565440178\n",
      "Epoch 92, Loss: 0.014175504446029663\n",
      "Epoch 93, Loss: 0.017581332474946976\n",
      "Epoch 94, Loss: 0.028815902769565582\n",
      "Epoch 95, Loss: 0.019039427861571312\n",
      "Epoch 96, Loss: 0.006339839659631252\n",
      "Epoch 97, Loss: 0.005180521868169308\n",
      "Epoch 98, Loss: 0.011372670531272888\n",
      "Epoch 99, Loss: 0.008488696999847889\n",
      "Epoch 100, Loss: 0.009661140851676464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3201252222061157\n",
      "Epoch 1, Loss: 0.6171558499336243\n",
      "Epoch 2, Loss: 0.3622777760028839\n",
      "Epoch 3, Loss: 0.9756473898887634\n",
      "Epoch 4, Loss: 0.9001827239990234\n",
      "Epoch 5, Loss: 0.8599100708961487\n",
      "Epoch 6, Loss: 0.36669978499412537\n",
      "Epoch 7, Loss: 0.45866858959198\n",
      "Epoch 8, Loss: 1.0359598398208618\n",
      "Epoch 9, Loss: 0.35759055614471436\n",
      "Epoch 10, Loss: 0.24740904569625854\n",
      "Epoch 11, Loss: 0.3649352490901947\n",
      "Epoch 12, Loss: 0.4710748493671417\n",
      "Epoch 13, Loss: 0.192251056432724\n",
      "Epoch 14, Loss: 0.14215469360351562\n",
      "Epoch 15, Loss: 0.3242831826210022\n",
      "Epoch 16, Loss: 0.28901734948158264\n",
      "Epoch 17, Loss: 0.11781144142150879\n",
      "Epoch 18, Loss: 0.11457836627960205\n",
      "Epoch 19, Loss: 0.20814208686351776\n",
      "Epoch 20, Loss: 0.09202194213867188\n",
      "Epoch 21, Loss: 0.16764409840106964\n",
      "Epoch 22, Loss: 0.16179069876670837\n",
      "Epoch 23, Loss: 0.07790078222751617\n",
      "Epoch 24, Loss: 0.25324100255966187\n",
      "Epoch 25, Loss: 0.24589817225933075\n",
      "Epoch 26, Loss: 0.1936803162097931\n",
      "Epoch 27, Loss: 0.18710936605930328\n",
      "Epoch 28, Loss: 0.10540204495191574\n",
      "Epoch 29, Loss: 0.059998974204063416\n",
      "Epoch 30, Loss: 0.10556957125663757\n",
      "Epoch 31, Loss: 0.1529988795518875\n",
      "Epoch 32, Loss: 0.07074001431465149\n",
      "Epoch 33, Loss: 0.045378752052783966\n",
      "Epoch 34, Loss: 0.19449204206466675\n",
      "Epoch 35, Loss: 0.05964536964893341\n",
      "Epoch 36, Loss: 0.026598788797855377\n",
      "Epoch 37, Loss: 0.07270795106887817\n",
      "Epoch 38, Loss: 0.07524222880601883\n",
      "Epoch 39, Loss: 0.1441473364830017\n",
      "Epoch 40, Loss: 0.04987345635890961\n",
      "Epoch 41, Loss: 0.04337204620242119\n",
      "Epoch 42, Loss: 0.015031922608613968\n",
      "Epoch 43, Loss: 0.0342196561396122\n",
      "Epoch 44, Loss: 0.06542518734931946\n",
      "Epoch 45, Loss: 0.02742590755224228\n",
      "Epoch 46, Loss: 0.030535340309143066\n",
      "Epoch 47, Loss: 0.012547207064926624\n",
      "Epoch 48, Loss: 0.01759287714958191\n",
      "Epoch 49, Loss: 0.07572054117918015\n",
      "Epoch 50, Loss: 0.04156982898712158\n",
      "Epoch 51, Loss: 0.013222689740359783\n",
      "Epoch 52, Loss: 0.06970236450433731\n",
      "Epoch 53, Loss: 0.011174791492521763\n",
      "Epoch 54, Loss: 0.05358213931322098\n",
      "Epoch 55, Loss: 0.008694063872098923\n",
      "Epoch 56, Loss: 0.013295079581439495\n",
      "Epoch 57, Loss: 0.006200894713401794\n",
      "Epoch 58, Loss: 0.011857145465910435\n",
      "Epoch 59, Loss: 0.021628092974424362\n",
      "Epoch 60, Loss: 0.011671073734760284\n",
      "Epoch 61, Loss: 0.014964005909860134\n",
      "Epoch 62, Loss: 0.027255050837993622\n",
      "Epoch 63, Loss: 0.023443657904863358\n",
      "Epoch 64, Loss: 0.029056953266263008\n",
      "Epoch 65, Loss: 0.01147183682769537\n",
      "Epoch 66, Loss: 0.006738365162163973\n",
      "Epoch 67, Loss: 0.017808720469474792\n",
      "Epoch 68, Loss: 0.01023270282894373\n",
      "Epoch 69, Loss: 0.024598456919193268\n",
      "Epoch 70, Loss: 0.011112438514828682\n",
      "Epoch 71, Loss: 0.014078878797590733\n",
      "Epoch 72, Loss: 0.015225225128233433\n",
      "Epoch 73, Loss: 0.018100647255778313\n",
      "Epoch 74, Loss: 0.00905620213598013\n",
      "Epoch 75, Loss: 0.01447416003793478\n",
      "Epoch 76, Loss: 0.02545149251818657\n",
      "Epoch 77, Loss: 0.01601199433207512\n",
      "Epoch 78, Loss: 0.009273131377995014\n",
      "Epoch 79, Loss: 0.015708113089203835\n",
      "Epoch 80, Loss: 0.009162216447293758\n",
      "Epoch 81, Loss: 0.022365780547261238\n",
      "Epoch 82, Loss: 0.017132405191659927\n",
      "Epoch 83, Loss: 0.01859772577881813\n",
      "Epoch 84, Loss: 0.02078041434288025\n",
      "Epoch 85, Loss: 0.020170075818896294\n",
      "Epoch 86, Loss: 0.010683616623282433\n",
      "Epoch 87, Loss: 0.016448991373181343\n",
      "Epoch 88, Loss: 0.010547880083322525\n",
      "Epoch 89, Loss: 0.016737433150410652\n",
      "Epoch 90, Loss: 0.011453961953520775\n",
      "Epoch 91, Loss: 0.01976279355585575\n",
      "Epoch 92, Loss: 0.01222290936857462\n",
      "Epoch 93, Loss: 0.008680876344442368\n",
      "Epoch 94, Loss: 0.013887633569538593\n",
      "Epoch 95, Loss: 0.006730823311954737\n",
      "Epoch 96, Loss: 0.015688179060816765\n",
      "Epoch 97, Loss: 0.022343341261148453\n",
      "Epoch 98, Loss: 0.011828693561255932\n",
      "Epoch 99, Loss: 0.013509795069694519\n",
      "Epoch 100, Loss: 0.006475829519331455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.4010099172592163\n",
      "Epoch 1, Loss: 0.9243937730789185\n",
      "Epoch 2, Loss: 1.0177708864212036\n",
      "Epoch 3, Loss: 0.714386522769928\n",
      "Epoch 4, Loss: 0.5011082887649536\n",
      "Epoch 5, Loss: 0.5821778774261475\n",
      "Epoch 6, Loss: 0.6386481523513794\n",
      "Epoch 7, Loss: 0.3624153435230255\n",
      "Epoch 8, Loss: 0.6626272797584534\n",
      "Epoch 9, Loss: 0.3242511451244354\n",
      "Epoch 10, Loss: 0.24893535673618317\n",
      "Epoch 11, Loss: 0.29114970564842224\n",
      "Epoch 12, Loss: 0.1807909607887268\n",
      "Epoch 13, Loss: 0.3459244966506958\n",
      "Epoch 14, Loss: 0.17494291067123413\n",
      "Epoch 15, Loss: 0.17546828091144562\n",
      "Epoch 16, Loss: 0.16950811445713043\n",
      "Epoch 17, Loss: 0.27920642495155334\n",
      "Epoch 18, Loss: 0.14826731383800507\n",
      "Epoch 19, Loss: 0.3175956606864929\n",
      "Epoch 20, Loss: 0.13620702922344208\n",
      "Epoch 21, Loss: 0.39166954159736633\n",
      "Epoch 22, Loss: 0.11648283898830414\n",
      "Epoch 23, Loss: 0.14144624769687653\n",
      "Epoch 24, Loss: 0.1190362349152565\n",
      "Epoch 25, Loss: 0.07982043921947479\n",
      "Epoch 26, Loss: 0.20601455867290497\n",
      "Epoch 27, Loss: 0.14615441858768463\n",
      "Epoch 28, Loss: 0.06754615902900696\n",
      "Epoch 29, Loss: 0.10207439213991165\n",
      "Epoch 30, Loss: 0.17072497308254242\n",
      "Epoch 31, Loss: 0.08905334025621414\n",
      "Epoch 32, Loss: 0.08479518443346024\n",
      "Epoch 33, Loss: 0.1418522447347641\n",
      "Epoch 34, Loss: 0.12958195805549622\n",
      "Epoch 35, Loss: 0.04370662569999695\n",
      "Epoch 36, Loss: 0.03686688467860222\n",
      "Epoch 37, Loss: 0.04044731706380844\n",
      "Epoch 38, Loss: 0.03271922469139099\n",
      "Epoch 39, Loss: 0.028346167877316475\n",
      "Epoch 40, Loss: 0.04549802467226982\n",
      "Epoch 41, Loss: 0.045574989169836044\n",
      "Epoch 42, Loss: 0.0653005987405777\n",
      "Epoch 43, Loss: 0.03818442299962044\n",
      "Epoch 44, Loss: 0.029563728719949722\n",
      "Epoch 45, Loss: 0.0371774323284626\n",
      "Epoch 46, Loss: 0.05290542170405388\n",
      "Epoch 47, Loss: 0.0814087763428688\n",
      "Epoch 48, Loss: 0.023261452093720436\n",
      "Epoch 49, Loss: 0.03412812948226929\n",
      "Epoch 50, Loss: 0.041848812252283096\n",
      "Epoch 51, Loss: 0.03437844291329384\n",
      "Epoch 52, Loss: 0.014689143747091293\n",
      "Epoch 53, Loss: 0.028167523443698883\n",
      "Epoch 54, Loss: 0.013926844112575054\n",
      "Epoch 55, Loss: 0.02512316405773163\n",
      "Epoch 56, Loss: 0.019159317016601562\n",
      "Epoch 57, Loss: 0.012958900071680546\n",
      "Epoch 58, Loss: 0.027223220095038414\n",
      "Epoch 59, Loss: 0.015720099210739136\n",
      "Epoch 60, Loss: 0.02956312894821167\n",
      "Epoch 61, Loss: 0.011190344579517841\n",
      "Epoch 62, Loss: 0.010280204005539417\n",
      "Epoch 63, Loss: 0.01393046323210001\n",
      "Epoch 64, Loss: 0.0127088138833642\n",
      "Epoch 65, Loss: 0.007906642742455006\n",
      "Epoch 66, Loss: 0.012929847463965416\n",
      "Epoch 67, Loss: 0.011468511074781418\n",
      "Epoch 68, Loss: 0.017379052937030792\n",
      "Epoch 69, Loss: 0.01372899953275919\n",
      "Epoch 70, Loss: 0.006539001129567623\n",
      "Epoch 71, Loss: 0.0360141284763813\n",
      "Epoch 72, Loss: 0.013800238259136677\n",
      "Epoch 73, Loss: 0.013848410919308662\n",
      "Epoch 74, Loss: 0.010525453835725784\n",
      "Epoch 75, Loss: 0.006104046478867531\n",
      "Epoch 76, Loss: 0.015588285401463509\n",
      "Epoch 77, Loss: 0.014427732676267624\n",
      "Epoch 78, Loss: 0.00803015660494566\n",
      "Epoch 79, Loss: 0.003952509257942438\n",
      "Epoch 80, Loss: 0.0063311089761555195\n",
      "Epoch 81, Loss: 0.008965139277279377\n",
      "Epoch 82, Loss: 0.004609978757798672\n",
      "Epoch 83, Loss: 0.015005220659077168\n",
      "Epoch 84, Loss: 0.030910674482584\n",
      "Epoch 85, Loss: 0.010451379232108593\n",
      "Epoch 86, Loss: 0.012394248507916927\n",
      "Epoch 87, Loss: 0.01863817125558853\n",
      "Epoch 88, Loss: 0.005812285002321005\n",
      "Epoch 89, Loss: 0.008280954323709011\n",
      "Epoch 90, Loss: 0.020194076001644135\n",
      "Epoch 91, Loss: 0.00703850295394659\n",
      "Epoch 92, Loss: 0.0021759825758635998\n",
      "Epoch 93, Loss: 0.017476391047239304\n",
      "Epoch 94, Loss: 0.02098909765481949\n",
      "Epoch 95, Loss: 0.010398373007774353\n",
      "Epoch 96, Loss: 0.011986605823040009\n",
      "Epoch 97, Loss: 0.019136542454361916\n",
      "Epoch 98, Loss: 0.006779100745916367\n",
      "Epoch 99, Loss: 0.013417864218354225\n",
      "Epoch 100, Loss: 0.0129497479647398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3413360118865967\n",
      "Epoch 1, Loss: 0.35237789154052734\n",
      "Epoch 2, Loss: 0.8340297937393188\n",
      "Epoch 3, Loss: 0.26832255721092224\n",
      "Epoch 4, Loss: 0.6839349865913391\n",
      "Epoch 5, Loss: 0.7542530298233032\n",
      "Epoch 6, Loss: 0.8069131970405579\n",
      "Epoch 7, Loss: 0.36069029569625854\n",
      "Epoch 8, Loss: 0.3384898900985718\n",
      "Epoch 9, Loss: 0.2326076775789261\n",
      "Epoch 10, Loss: 0.8091433048248291\n",
      "Epoch 11, Loss: 0.41841524839401245\n",
      "Epoch 12, Loss: 0.4237041175365448\n",
      "Epoch 13, Loss: 0.3381119966506958\n",
      "Epoch 14, Loss: 0.37918317317962646\n",
      "Epoch 15, Loss: 0.33805274963378906\n",
      "Epoch 16, Loss: 0.21658645570278168\n",
      "Epoch 17, Loss: 0.30372747778892517\n",
      "Epoch 18, Loss: 0.16049325466156006\n",
      "Epoch 19, Loss: 0.06292837858200073\n",
      "Epoch 20, Loss: 0.07362360507249832\n",
      "Epoch 21, Loss: 0.23011620342731476\n",
      "Epoch 22, Loss: 0.18559782207012177\n",
      "Epoch 23, Loss: 0.16362425684928894\n",
      "Epoch 24, Loss: 0.17148207128047943\n",
      "Epoch 25, Loss: 0.15946151316165924\n",
      "Epoch 26, Loss: 0.08206495642662048\n",
      "Epoch 27, Loss: 0.1375042051076889\n",
      "Epoch 28, Loss: 0.06528343260288239\n",
      "Epoch 29, Loss: 0.2370707243680954\n",
      "Epoch 30, Loss: 0.12179529666900635\n",
      "Epoch 31, Loss: 0.085372194647789\n",
      "Epoch 32, Loss: 0.05805329605937004\n",
      "Epoch 33, Loss: 0.07328358292579651\n",
      "Epoch 34, Loss: 0.12117281556129456\n",
      "Epoch 35, Loss: 0.04854121804237366\n",
      "Epoch 36, Loss: 0.035873815417289734\n",
      "Epoch 37, Loss: 0.05566534027457237\n",
      "Epoch 38, Loss: 0.06478510797023773\n",
      "Epoch 39, Loss: 0.06853658705949783\n",
      "Epoch 40, Loss: 0.029980596154928207\n",
      "Epoch 41, Loss: 0.04064236581325531\n",
      "Epoch 42, Loss: 0.09719645977020264\n",
      "Epoch 43, Loss: 0.06910553574562073\n",
      "Epoch 44, Loss: 0.05508943647146225\n",
      "Epoch 45, Loss: 0.031570445746183395\n",
      "Epoch 46, Loss: 0.019852198660373688\n",
      "Epoch 47, Loss: 0.042178548872470856\n",
      "Epoch 48, Loss: 0.12213008850812912\n",
      "Epoch 49, Loss: 0.008981532417237759\n",
      "Epoch 50, Loss: 0.04307578504085541\n",
      "Epoch 51, Loss: 0.02928374521434307\n",
      "Epoch 52, Loss: 0.027713363990187645\n",
      "Epoch 53, Loss: 0.06041403487324715\n",
      "Epoch 54, Loss: 0.008607492782175541\n",
      "Epoch 55, Loss: 0.02818538434803486\n",
      "Epoch 56, Loss: 0.010856164619326591\n",
      "Epoch 57, Loss: 0.00564111303538084\n",
      "Epoch 58, Loss: 0.04939835146069527\n",
      "Epoch 59, Loss: 0.01664007641375065\n",
      "Epoch 60, Loss: 0.016786955296993256\n",
      "Epoch 61, Loss: 0.05742926150560379\n",
      "Epoch 62, Loss: 0.0198364295065403\n",
      "Epoch 63, Loss: 0.06760752201080322\n",
      "Epoch 64, Loss: 0.012893576174974442\n",
      "Epoch 65, Loss: 0.013465335592627525\n",
      "Epoch 66, Loss: 0.016016237437725067\n",
      "Epoch 67, Loss: 0.012364858761429787\n",
      "Epoch 68, Loss: 0.005910202860832214\n",
      "Epoch 69, Loss: 0.018655169755220413\n",
      "Epoch 70, Loss: 0.015537611208856106\n",
      "Epoch 71, Loss: 0.015215383842587471\n",
      "Epoch 72, Loss: 0.007384559139609337\n",
      "Epoch 73, Loss: 0.008473114110529423\n",
      "Epoch 74, Loss: 0.012923836708068848\n",
      "Epoch 75, Loss: 0.039072245359420776\n",
      "Epoch 76, Loss: 0.019942857325077057\n",
      "Epoch 77, Loss: 0.01695779524743557\n",
      "Epoch 78, Loss: 0.05634864792227745\n",
      "Epoch 79, Loss: 0.01320467609912157\n",
      "Epoch 80, Loss: 0.007587714120745659\n",
      "Epoch 81, Loss: 0.0067075882107019424\n",
      "Epoch 82, Loss: 0.008671284653246403\n",
      "Epoch 83, Loss: 0.010112255811691284\n",
      "Epoch 84, Loss: 0.017070045694708824\n",
      "Epoch 85, Loss: 0.013041187077760696\n",
      "Epoch 86, Loss: 0.010846216231584549\n",
      "Epoch 87, Loss: 0.015163189731538296\n",
      "Epoch 88, Loss: 0.010509091429412365\n",
      "Epoch 89, Loss: 0.004529982339590788\n",
      "Epoch 90, Loss: 0.005438658408820629\n",
      "Epoch 91, Loss: 0.006656863261014223\n",
      "Epoch 92, Loss: 0.010877829045057297\n",
      "Epoch 93, Loss: 0.013884597457945347\n",
      "Epoch 94, Loss: 0.007911617867648602\n",
      "Epoch 95, Loss: 0.006769852712750435\n",
      "Epoch 96, Loss: 0.0026283329352736473\n",
      "Epoch 97, Loss: 0.011692607775330544\n",
      "Epoch 98, Loss: 0.020058130845427513\n",
      "Epoch 99, Loss: 0.009744218550622463\n",
      "Epoch 100, Loss: 0.004430647008121014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3961046934127808\n",
      "Epoch 1, Loss: 0.25508880615234375\n",
      "Epoch 2, Loss: 0.6733825206756592\n",
      "Epoch 3, Loss: 1.2167701721191406\n",
      "Epoch 4, Loss: 0.6099104881286621\n",
      "Epoch 5, Loss: 0.9361473917961121\n",
      "Epoch 6, Loss: 0.3971423804759979\n",
      "Epoch 7, Loss: 0.5554075837135315\n",
      "Epoch 8, Loss: 0.30126380920410156\n",
      "Epoch 9, Loss: 0.2520790994167328\n",
      "Epoch 10, Loss: 0.31181371212005615\n",
      "Epoch 11, Loss: 0.34573686122894287\n",
      "Epoch 12, Loss: 0.24254769086837769\n",
      "Epoch 13, Loss: 0.26642873883247375\n",
      "Epoch 14, Loss: 0.4273526668548584\n",
      "Epoch 15, Loss: 0.26067423820495605\n",
      "Epoch 16, Loss: 0.24991294741630554\n",
      "Epoch 17, Loss: 0.09170905500650406\n",
      "Epoch 18, Loss: 0.1873272955417633\n",
      "Epoch 19, Loss: 0.12849432229995728\n",
      "Epoch 20, Loss: 0.22136402130126953\n",
      "Epoch 21, Loss: 0.09017186611890793\n",
      "Epoch 22, Loss: 0.2244603931903839\n",
      "Epoch 23, Loss: 0.24702054262161255\n",
      "Epoch 24, Loss: 0.10101232677698135\n",
      "Epoch 25, Loss: 0.11917728930711746\n",
      "Epoch 26, Loss: 0.1435115933418274\n",
      "Epoch 27, Loss: 0.1419130116701126\n",
      "Epoch 28, Loss: 0.03376056253910065\n",
      "Epoch 29, Loss: 0.13097910583019257\n",
      "Epoch 30, Loss: 0.059745948761701584\n",
      "Epoch 31, Loss: 0.055708155035972595\n",
      "Epoch 32, Loss: 0.060462143272161484\n",
      "Epoch 33, Loss: 0.018925992771983147\n",
      "Epoch 34, Loss: 0.09446081519126892\n",
      "Epoch 35, Loss: 0.04498401656746864\n",
      "Epoch 36, Loss: 0.10310783982276917\n",
      "Epoch 37, Loss: 0.09137757867574692\n",
      "Epoch 38, Loss: 0.044406723231077194\n",
      "Epoch 39, Loss: 0.040437351912260056\n",
      "Epoch 40, Loss: 0.04894692078232765\n",
      "Epoch 41, Loss: 0.032272737473249435\n",
      "Epoch 42, Loss: 0.09381190687417984\n",
      "Epoch 43, Loss: 0.013824397698044777\n",
      "Epoch 44, Loss: 0.028669049963355064\n",
      "Epoch 45, Loss: 0.04768413305282593\n",
      "Epoch 46, Loss: 0.05400427430868149\n",
      "Epoch 47, Loss: 0.046048808842897415\n",
      "Epoch 48, Loss: 0.04231586307287216\n",
      "Epoch 49, Loss: 0.05114501714706421\n",
      "Epoch 50, Loss: 0.04879257082939148\n",
      "Epoch 51, Loss: 0.018187370151281357\n",
      "Epoch 52, Loss: 0.1009281575679779\n",
      "Epoch 53, Loss: 0.03340661898255348\n",
      "Epoch 54, Loss: 0.011016418226063251\n",
      "Epoch 55, Loss: 0.03191150352358818\n",
      "Epoch 56, Loss: 0.016970647498965263\n",
      "Epoch 57, Loss: 0.016046442091464996\n",
      "Epoch 58, Loss: 0.03782428801059723\n",
      "Epoch 59, Loss: 0.020078053697943687\n",
      "Epoch 60, Loss: 0.03628506883978844\n",
      "Epoch 61, Loss: 0.023313365876674652\n",
      "Epoch 62, Loss: 0.011708867736160755\n",
      "Epoch 63, Loss: 0.010932649485766888\n",
      "Epoch 64, Loss: 0.013931112363934517\n",
      "Epoch 65, Loss: 0.014604773372411728\n",
      "Epoch 66, Loss: 0.013046381063759327\n",
      "Epoch 67, Loss: 0.03331775218248367\n",
      "Epoch 68, Loss: 0.027041878551244736\n",
      "Epoch 69, Loss: 0.0033281208015978336\n",
      "Epoch 70, Loss: 0.011664402671158314\n",
      "Epoch 71, Loss: 0.022579748183488846\n",
      "Epoch 72, Loss: 0.024550804868340492\n",
      "Epoch 73, Loss: 0.01336586195975542\n",
      "Epoch 74, Loss: 0.00961625762283802\n",
      "Epoch 75, Loss: 0.009175213053822517\n",
      "Epoch 76, Loss: 0.12299350649118423\n",
      "Epoch 77, Loss: 0.017016148194670677\n",
      "Epoch 78, Loss: 0.07412487268447876\n",
      "Epoch 79, Loss: 0.017789361998438835\n",
      "Epoch 80, Loss: 0.011451760306954384\n",
      "Epoch 81, Loss: 0.004191484302282333\n",
      "Epoch 82, Loss: 0.012371850199997425\n",
      "Epoch 83, Loss: 0.01861177571117878\n",
      "Epoch 84, Loss: 0.005632140673696995\n",
      "Epoch 85, Loss: 0.009275532327592373\n",
      "Epoch 86, Loss: 0.021863851696252823\n",
      "Epoch 87, Loss: 0.006491204723715782\n",
      "Epoch 88, Loss: 0.018951496109366417\n",
      "Epoch 89, Loss: 0.010226290673017502\n",
      "Epoch 90, Loss: 0.02369995415210724\n",
      "Epoch 91, Loss: 0.017733488231897354\n",
      "Epoch 92, Loss: 0.01024390384554863\n",
      "Epoch 93, Loss: 0.02450876496732235\n",
      "Epoch 94, Loss: 0.007981386035680771\n",
      "Epoch 95, Loss: 0.008611672557890415\n",
      "Epoch 96, Loss: 0.01301612239331007\n",
      "Epoch 97, Loss: 0.007751539349555969\n",
      "Epoch 98, Loss: 0.016948608681559563\n",
      "Epoch 99, Loss: 0.005418085027486086\n",
      "Epoch 100, Loss: 0.012646768242120743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3717098236083984\n",
      "Epoch 1, Loss: 0.7392813563346863\n",
      "Epoch 2, Loss: 0.5095198154449463\n",
      "Epoch 3, Loss: 0.6431936621665955\n",
      "Epoch 4, Loss: 0.3566422462463379\n",
      "Epoch 5, Loss: 0.9420287013053894\n",
      "Epoch 6, Loss: 0.28295576572418213\n",
      "Epoch 7, Loss: 0.6902280449867249\n",
      "Epoch 8, Loss: 0.4141676127910614\n",
      "Epoch 9, Loss: 0.17428068816661835\n",
      "Epoch 10, Loss: 0.6159339547157288\n",
      "Epoch 11, Loss: 0.4302901327610016\n",
      "Epoch 12, Loss: 0.3308262526988983\n",
      "Epoch 13, Loss: 0.5230944156646729\n",
      "Epoch 14, Loss: 0.32070860266685486\n",
      "Epoch 15, Loss: 0.44397157430648804\n",
      "Epoch 16, Loss: 0.10747669637203217\n",
      "Epoch 17, Loss: 0.2253333181142807\n",
      "Epoch 18, Loss: 0.1485983431339264\n",
      "Epoch 19, Loss: 0.35420969128608704\n",
      "Epoch 20, Loss: 0.17800754308700562\n",
      "Epoch 21, Loss: 0.13215672969818115\n",
      "Epoch 22, Loss: 0.08796171844005585\n",
      "Epoch 23, Loss: 0.5954228639602661\n",
      "Epoch 24, Loss: 0.11587613075971603\n",
      "Epoch 25, Loss: 0.06899859011173248\n",
      "Epoch 26, Loss: 0.04838469624519348\n",
      "Epoch 27, Loss: 0.08456011861562729\n",
      "Epoch 28, Loss: 0.036520522087812424\n",
      "Epoch 29, Loss: 0.10780289769172668\n",
      "Epoch 30, Loss: 0.03511958569288254\n",
      "Epoch 31, Loss: 0.0630505308508873\n",
      "Epoch 32, Loss: 0.10445750504732132\n",
      "Epoch 33, Loss: 0.19529680907726288\n",
      "Epoch 34, Loss: 0.03084247000515461\n",
      "Epoch 35, Loss: 0.1410466432571411\n",
      "Epoch 36, Loss: 0.08024613559246063\n",
      "Epoch 37, Loss: 0.10729175060987473\n",
      "Epoch 38, Loss: 0.18735139071941376\n",
      "Epoch 39, Loss: 0.1849355548620224\n",
      "Epoch 40, Loss: 0.05995382368564606\n",
      "Epoch 41, Loss: 0.06248810514807701\n",
      "Epoch 42, Loss: 0.044116146862506866\n",
      "Epoch 43, Loss: 0.0327141210436821\n",
      "Epoch 44, Loss: 0.08542818576097488\n",
      "Epoch 45, Loss: 0.03695707768201828\n",
      "Epoch 46, Loss: 0.03263390436768532\n",
      "Epoch 47, Loss: 0.031759943813085556\n",
      "Epoch 48, Loss: 0.023844536393880844\n",
      "Epoch 49, Loss: 0.09725435078144073\n",
      "Epoch 50, Loss: 0.02139091305434704\n",
      "Epoch 51, Loss: 0.053303662687540054\n",
      "Epoch 52, Loss: 0.042344290763139725\n",
      "Epoch 53, Loss: 0.022469790652394295\n",
      "Epoch 54, Loss: 0.05073113739490509\n",
      "Epoch 55, Loss: 0.027073191478848457\n",
      "Epoch 56, Loss: 0.03980647027492523\n",
      "Epoch 57, Loss: 0.010998442769050598\n",
      "Epoch 58, Loss: 0.028304193168878555\n",
      "Epoch 59, Loss: 0.028668615967035294\n",
      "Epoch 60, Loss: 0.016516290605068207\n",
      "Epoch 61, Loss: 0.021786987781524658\n",
      "Epoch 62, Loss: 0.014925862662494183\n",
      "Epoch 63, Loss: 0.014679670333862305\n",
      "Epoch 64, Loss: 0.015153502114117146\n",
      "Epoch 65, Loss: 0.019778039306402206\n",
      "Epoch 66, Loss: 0.09776252508163452\n",
      "Epoch 67, Loss: 0.010412735864520073\n",
      "Epoch 68, Loss: 0.018497779965400696\n",
      "Epoch 69, Loss: 0.05127590522170067\n",
      "Epoch 70, Loss: 0.020283298566937447\n",
      "Epoch 71, Loss: 0.021193580701947212\n",
      "Epoch 72, Loss: 0.09980132430791855\n",
      "Epoch 73, Loss: 0.04156447947025299\n",
      "Epoch 74, Loss: 0.004631592892110348\n",
      "Epoch 75, Loss: 0.012284130789339542\n",
      "Epoch 76, Loss: 0.024661166593432426\n",
      "Epoch 77, Loss: 0.005665692966431379\n",
      "Epoch 78, Loss: 0.01494970265775919\n",
      "Epoch 79, Loss: 0.012072388082742691\n",
      "Epoch 80, Loss: 0.016907457262277603\n",
      "Epoch 81, Loss: 0.009618677198886871\n",
      "Epoch 82, Loss: 0.03158561512827873\n",
      "Epoch 83, Loss: 0.024904834106564522\n",
      "Epoch 84, Loss: 0.016163289546966553\n",
      "Epoch 85, Loss: 0.00816475972533226\n",
      "Epoch 86, Loss: 0.010289612226188183\n",
      "Epoch 87, Loss: 0.01377064362168312\n",
      "Epoch 88, Loss: 0.012492186389863491\n",
      "Epoch 89, Loss: 0.0054979948326945305\n",
      "Epoch 90, Loss: 0.006427018903195858\n",
      "Epoch 91, Loss: 0.014013494364917278\n",
      "Epoch 92, Loss: 0.02289409562945366\n",
      "Epoch 93, Loss: 0.018375135958194733\n",
      "Epoch 94, Loss: 0.004769486840814352\n",
      "Epoch 95, Loss: 0.01237243041396141\n",
      "Epoch 96, Loss: 0.013622257858514786\n",
      "Epoch 97, Loss: 0.003632158972322941\n",
      "Epoch 98, Loss: 0.00758854066953063\n",
      "Epoch 99, Loss: 0.003697618842124939\n",
      "Epoch 100, Loss: 0.004841431975364685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.4255367517471313\n",
      "Epoch 1, Loss: 0.5748427510261536\n",
      "Epoch 2, Loss: 0.2109891027212143\n",
      "Epoch 3, Loss: 0.46496474742889404\n",
      "Epoch 4, Loss: 0.9166056513786316\n",
      "Epoch 5, Loss: 0.41059815883636475\n",
      "Epoch 6, Loss: 0.3004743456840515\n",
      "Epoch 7, Loss: 0.9049707055091858\n",
      "Epoch 8, Loss: 0.7099635004997253\n",
      "Epoch 9, Loss: 1.0659769773483276\n",
      "Epoch 10, Loss: 0.26879262924194336\n",
      "Epoch 11, Loss: 0.24305322766304016\n",
      "Epoch 12, Loss: 0.4918821156024933\n",
      "Epoch 13, Loss: 0.20436795055866241\n",
      "Epoch 14, Loss: 0.13764911890029907\n",
      "Epoch 15, Loss: 0.23456764221191406\n",
      "Epoch 16, Loss: 0.2056431770324707\n",
      "Epoch 17, Loss: 0.237318217754364\n",
      "Epoch 18, Loss: 0.09995409101247787\n",
      "Epoch 19, Loss: 0.07012209296226501\n",
      "Epoch 20, Loss: 0.10451187938451767\n",
      "Epoch 21, Loss: 0.15010769665241241\n",
      "Epoch 22, Loss: 0.19607430696487427\n",
      "Epoch 23, Loss: 0.3640104830265045\n",
      "Epoch 24, Loss: 0.26091787219047546\n",
      "Epoch 25, Loss: 0.242592915892601\n",
      "Epoch 26, Loss: 0.11450479924678802\n",
      "Epoch 27, Loss: 0.2048417031764984\n",
      "Epoch 28, Loss: 0.06856175512075424\n",
      "Epoch 29, Loss: 0.27591410279273987\n",
      "Epoch 30, Loss: 0.055068399757146835\n",
      "Epoch 31, Loss: 0.024059327319264412\n",
      "Epoch 32, Loss: 0.13092009723186493\n",
      "Epoch 33, Loss: 0.15666726231575012\n",
      "Epoch 34, Loss: 0.025812653824687004\n",
      "Epoch 35, Loss: 0.07559187710285187\n",
      "Epoch 36, Loss: 0.06679292023181915\n",
      "Epoch 37, Loss: 0.06663694977760315\n",
      "Epoch 38, Loss: 0.048072699457407\n",
      "Epoch 39, Loss: 0.0662769079208374\n",
      "Epoch 40, Loss: 0.023275375366210938\n",
      "Epoch 41, Loss: 0.07724404335021973\n",
      "Epoch 42, Loss: 0.12345580011606216\n",
      "Epoch 43, Loss: 0.03424593806266785\n",
      "Epoch 44, Loss: 0.14931991696357727\n",
      "Epoch 45, Loss: 0.03214814141392708\n",
      "Epoch 46, Loss: 0.010527461767196655\n",
      "Epoch 47, Loss: 0.019289519637823105\n",
      "Epoch 48, Loss: 0.041056811809539795\n",
      "Epoch 49, Loss: 0.03366108611226082\n",
      "Epoch 50, Loss: 0.012039247900247574\n",
      "Epoch 51, Loss: 0.04875824600458145\n",
      "Epoch 52, Loss: 0.010107157751917839\n",
      "Epoch 53, Loss: 0.05472201108932495\n",
      "Epoch 54, Loss: 0.03458315506577492\n",
      "Epoch 55, Loss: 0.034455135464668274\n",
      "Epoch 56, Loss: 0.011684417724609375\n",
      "Epoch 57, Loss: 0.03301374241709709\n",
      "Epoch 58, Loss: 0.04602937027812004\n",
      "Epoch 59, Loss: 0.04927636682987213\n",
      "Epoch 60, Loss: 0.01711038127541542\n",
      "Epoch 61, Loss: 0.016474468633532524\n",
      "Epoch 62, Loss: 0.116365447640419\n",
      "Epoch 63, Loss: 0.06979267299175262\n",
      "Epoch 64, Loss: 0.013156238943338394\n",
      "Epoch 65, Loss: 0.013422071002423763\n",
      "Epoch 66, Loss: 0.01923329196870327\n",
      "Epoch 67, Loss: 0.025706250220537186\n",
      "Epoch 68, Loss: 0.033994629979133606\n",
      "Epoch 69, Loss: 0.025258798152208328\n",
      "Epoch 70, Loss: 0.02067359909415245\n",
      "Epoch 71, Loss: 0.023121872916817665\n",
      "Epoch 72, Loss: 0.0398680679500103\n",
      "Epoch 73, Loss: 0.015481125563383102\n",
      "Epoch 74, Loss: 0.03476736322045326\n",
      "Epoch 75, Loss: 0.02756129577755928\n",
      "Epoch 76, Loss: 0.016269179061055183\n",
      "Epoch 77, Loss: 0.019412077963352203\n",
      "Epoch 78, Loss: 0.018812861293554306\n",
      "Epoch 79, Loss: 0.017996080219745636\n",
      "Epoch 80, Loss: 0.028449075296521187\n",
      "Epoch 81, Loss: 0.0198669396340847\n",
      "Epoch 82, Loss: 0.013514318503439426\n",
      "Epoch 83, Loss: 0.01749182678759098\n",
      "Epoch 84, Loss: 0.018852917477488518\n",
      "Epoch 85, Loss: 0.01032781507819891\n",
      "Epoch 86, Loss: 0.006795545574277639\n",
      "Epoch 87, Loss: 0.01012890599668026\n",
      "Epoch 88, Loss: 0.01824360340833664\n",
      "Epoch 89, Loss: 0.017183834686875343\n",
      "Epoch 90, Loss: 0.00413857214152813\n",
      "Epoch 91, Loss: 0.010149026289582253\n",
      "Epoch 92, Loss: 0.005754888989031315\n",
      "Epoch 93, Loss: 0.008037763647735119\n",
      "Epoch 94, Loss: 0.06326562911272049\n",
      "Epoch 95, Loss: 0.006985732354223728\n",
      "Epoch 96, Loss: 0.013163638301193714\n",
      "Epoch 97, Loss: 0.018383406102657318\n",
      "Epoch 98, Loss: 0.003870096057653427\n",
      "Epoch 99, Loss: 0.0071402969770133495\n",
      "Epoch 100, Loss: 0.005871943663805723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3588402271270752\n",
      "Epoch 1, Loss: 0.7654795050621033\n",
      "Epoch 2, Loss: 0.6501099467277527\n",
      "Epoch 3, Loss: 0.5083739757537842\n",
      "Epoch 4, Loss: 0.52851402759552\n",
      "Epoch 5, Loss: 0.33046624064445496\n",
      "Epoch 6, Loss: 0.5125850439071655\n",
      "Epoch 7, Loss: 0.36515891551971436\n",
      "Epoch 8, Loss: 0.5215492844581604\n",
      "Epoch 9, Loss: 0.3150206506252289\n",
      "Epoch 10, Loss: 0.38506221771240234\n",
      "Epoch 11, Loss: 1.0265491008758545\n",
      "Epoch 12, Loss: 0.2988680601119995\n",
      "Epoch 13, Loss: 0.288703978061676\n",
      "Epoch 14, Loss: 0.25432249903678894\n",
      "Epoch 15, Loss: 0.413456529378891\n",
      "Epoch 16, Loss: 0.30364593863487244\n",
      "Epoch 17, Loss: 0.45248958468437195\n",
      "Epoch 18, Loss: 0.11940639466047287\n",
      "Epoch 19, Loss: 0.17633622884750366\n",
      "Epoch 20, Loss: 0.4838968813419342\n",
      "Epoch 21, Loss: 0.1327604502439499\n",
      "Epoch 22, Loss: 0.16191264986991882\n",
      "Epoch 23, Loss: 0.2624495029449463\n",
      "Epoch 24, Loss: 0.2752283215522766\n",
      "Epoch 25, Loss: 0.18383237719535828\n",
      "Epoch 26, Loss: 0.09424330294132233\n",
      "Epoch 27, Loss: 0.06390222907066345\n",
      "Epoch 28, Loss: 0.0976283848285675\n",
      "Epoch 29, Loss: 0.06307251751422882\n",
      "Epoch 30, Loss: 0.1721002757549286\n",
      "Epoch 31, Loss: 0.19231447577476501\n",
      "Epoch 32, Loss: 0.11277925968170166\n",
      "Epoch 33, Loss: 0.053086284548044205\n",
      "Epoch 34, Loss: 0.08375731110572815\n",
      "Epoch 35, Loss: 0.038620274513959885\n",
      "Epoch 36, Loss: 0.06753087043762207\n",
      "Epoch 37, Loss: 0.03152906894683838\n",
      "Epoch 38, Loss: 0.04395746812224388\n",
      "Epoch 39, Loss: 0.058655425906181335\n",
      "Epoch 40, Loss: 0.03998031094670296\n",
      "Epoch 41, Loss: 0.05684439465403557\n",
      "Epoch 42, Loss: 0.08626561611890793\n",
      "Epoch 43, Loss: 0.19392436742782593\n",
      "Epoch 44, Loss: 0.024961840361356735\n",
      "Epoch 45, Loss: 0.026752419769763947\n",
      "Epoch 46, Loss: 0.026430796831846237\n",
      "Epoch 47, Loss: 0.025097815319895744\n",
      "Epoch 48, Loss: 0.03378450497984886\n",
      "Epoch 49, Loss: 0.03779679536819458\n",
      "Epoch 50, Loss: 0.0225435271859169\n",
      "Epoch 51, Loss: 0.02409927174448967\n",
      "Epoch 52, Loss: 0.08575490117073059\n",
      "Epoch 53, Loss: 0.016267267987132072\n",
      "Epoch 54, Loss: 0.016851594671607018\n",
      "Epoch 55, Loss: 0.008533998392522335\n",
      "Epoch 56, Loss: 0.019228972494602203\n",
      "Epoch 57, Loss: 0.006620513740926981\n",
      "Epoch 58, Loss: 0.015692155808210373\n",
      "Epoch 59, Loss: 0.013035189360380173\n",
      "Epoch 60, Loss: 0.013560902327299118\n",
      "Epoch 61, Loss: 0.01300056092441082\n",
      "Epoch 62, Loss: 0.04827607050538063\n",
      "Epoch 63, Loss: 0.0291470754891634\n",
      "Epoch 64, Loss: 0.012677949853241444\n",
      "Epoch 65, Loss: 0.024729864671826363\n",
      "Epoch 66, Loss: 0.028286941349506378\n",
      "Epoch 67, Loss: 0.013458125293254852\n",
      "Epoch 68, Loss: 0.011206954717636108\n",
      "Epoch 69, Loss: 0.01752082258462906\n",
      "Epoch 70, Loss: 0.02285071089863777\n",
      "Epoch 71, Loss: 0.018777260556817055\n",
      "Epoch 72, Loss: 0.011510840617120266\n",
      "Epoch 73, Loss: 0.010276030749082565\n",
      "Epoch 74, Loss: 0.011033418588340282\n",
      "Epoch 75, Loss: 0.014806604944169521\n",
      "Epoch 76, Loss: 0.013931389898061752\n",
      "Epoch 77, Loss: 0.010816479101777077\n",
      "Epoch 78, Loss: 0.01262903492897749\n",
      "Epoch 79, Loss: 0.008555018343031406\n",
      "Epoch 80, Loss: 0.00933376606553793\n",
      "Epoch 81, Loss: 0.03110121376812458\n",
      "Epoch 82, Loss: 0.01696643978357315\n",
      "Epoch 83, Loss: 0.011070835404098034\n",
      "Epoch 84, Loss: 0.01922501251101494\n",
      "Epoch 85, Loss: 0.012979786843061447\n",
      "Epoch 86, Loss: 0.03391845524311066\n",
      "Epoch 87, Loss: 0.014146572910249233\n",
      "Epoch 88, Loss: 0.020438918843865395\n",
      "Epoch 89, Loss: 0.010348165407776833\n",
      "Epoch 90, Loss: 0.0034228505101054907\n",
      "Epoch 91, Loss: 0.015515784732997417\n",
      "Epoch 92, Loss: 0.004623576067388058\n",
      "Epoch 93, Loss: 0.015997186303138733\n",
      "Epoch 94, Loss: 0.02949076145887375\n",
      "Epoch 95, Loss: 0.011831541545689106\n",
      "Epoch 96, Loss: 0.008887965232133865\n",
      "Epoch 97, Loss: 0.01960575580596924\n",
      "Epoch 98, Loss: 0.053986892104148865\n",
      "Epoch 99, Loss: 0.010076847858726978\n",
      "Epoch 100, Loss: 0.004034931305795908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.2961782217025757\n",
      "Epoch 1, Loss: 0.41269826889038086\n",
      "Epoch 2, Loss: 0.26341497898101807\n",
      "Epoch 3, Loss: 0.45232364535331726\n",
      "Epoch 4, Loss: 0.6425098776817322\n",
      "Epoch 5, Loss: 0.3691446781158447\n",
      "Epoch 6, Loss: 0.3914741277694702\n",
      "Epoch 7, Loss: 0.3926394581794739\n",
      "Epoch 8, Loss: 0.4023767113685608\n",
      "Epoch 9, Loss: 0.4976734519004822\n",
      "Epoch 10, Loss: 0.17557314038276672\n",
      "Epoch 11, Loss: 0.2173391431570053\n",
      "Epoch 12, Loss: 0.3815866708755493\n",
      "Epoch 13, Loss: 0.1840689778327942\n",
      "Epoch 14, Loss: 0.37488847970962524\n",
      "Epoch 15, Loss: 0.37095025181770325\n",
      "Epoch 16, Loss: 0.27423524856567383\n",
      "Epoch 17, Loss: 0.11160506308078766\n",
      "Epoch 18, Loss: 0.45586225390434265\n",
      "Epoch 19, Loss: 0.3073185086250305\n",
      "Epoch 20, Loss: 0.10693326592445374\n",
      "Epoch 21, Loss: 0.35247907042503357\n",
      "Epoch 22, Loss: 0.15981976687908173\n",
      "Epoch 23, Loss: 0.06832312792539597\n",
      "Epoch 24, Loss: 0.4808570444583893\n",
      "Epoch 25, Loss: 0.14590702950954437\n",
      "Epoch 26, Loss: 0.11401858925819397\n",
      "Epoch 27, Loss: 0.06900272518396378\n",
      "Epoch 28, Loss: 0.08554024994373322\n",
      "Epoch 29, Loss: 0.06870483607053757\n",
      "Epoch 30, Loss: 0.08313942700624466\n",
      "Epoch 31, Loss: 0.13664142787456512\n",
      "Epoch 32, Loss: 0.05967732146382332\n",
      "Epoch 33, Loss: 0.03828293830156326\n",
      "Epoch 34, Loss: 0.05628491938114166\n",
      "Epoch 35, Loss: 0.05766040086746216\n",
      "Epoch 36, Loss: 0.07190719246864319\n",
      "Epoch 37, Loss: 0.07624717056751251\n",
      "Epoch 38, Loss: 0.06064264103770256\n",
      "Epoch 39, Loss: 0.020410748198628426\n",
      "Epoch 40, Loss: 0.016128789633512497\n",
      "Epoch 41, Loss: 0.0633348673582077\n",
      "Epoch 42, Loss: 0.037440601736307144\n",
      "Epoch 43, Loss: 0.023091789335012436\n",
      "Epoch 44, Loss: 0.05653611943125725\n",
      "Epoch 45, Loss: 0.0050932876765728\n",
      "Epoch 46, Loss: 0.03624214231967926\n",
      "Epoch 47, Loss: 0.02141036093235016\n",
      "Epoch 48, Loss: 0.05889998376369476\n",
      "Epoch 49, Loss: 0.07777397334575653\n",
      "Epoch 50, Loss: 0.023068055510520935\n",
      "Epoch 51, Loss: 0.026363112032413483\n",
      "Epoch 52, Loss: 0.025084905326366425\n",
      "Epoch 53, Loss: 0.011194043792784214\n",
      "Epoch 54, Loss: 0.03251485526561737\n",
      "Epoch 55, Loss: 0.013114409521222115\n",
      "Epoch 56, Loss: 0.011831346899271011\n",
      "Epoch 57, Loss: 0.03120068460702896\n",
      "Epoch 58, Loss: 0.02339215576648712\n",
      "Epoch 59, Loss: 0.02630646713078022\n",
      "Epoch 60, Loss: 0.029214974492788315\n",
      "Epoch 61, Loss: 0.02454039268195629\n",
      "Epoch 62, Loss: 0.012201733887195587\n",
      "Epoch 63, Loss: 0.030280252918601036\n",
      "Epoch 64, Loss: 0.010047120973467827\n",
      "Epoch 65, Loss: 0.020834030583500862\n",
      "Epoch 66, Loss: 0.016483057290315628\n",
      "Epoch 67, Loss: 0.010178040713071823\n",
      "Epoch 68, Loss: 0.009149568155407906\n",
      "Epoch 69, Loss: 0.010703650303184986\n",
      "Epoch 70, Loss: 0.012560905888676643\n",
      "Epoch 71, Loss: 0.014506702311336994\n",
      "Epoch 72, Loss: 0.030199041590094566\n",
      "Epoch 73, Loss: 0.014074083417654037\n",
      "Epoch 74, Loss: 0.010811750777065754\n",
      "Epoch 75, Loss: 0.009895464405417442\n",
      "Epoch 76, Loss: 0.008580350317060947\n",
      "Epoch 77, Loss: 0.03446385636925697\n",
      "Epoch 78, Loss: 0.010443557985126972\n",
      "Epoch 79, Loss: 0.024414293467998505\n",
      "Epoch 80, Loss: 0.007602661848068237\n",
      "Epoch 81, Loss: 0.01012545358389616\n",
      "Epoch 82, Loss: 0.010139279067516327\n",
      "Epoch 83, Loss: 0.017979374155402184\n",
      "Epoch 84, Loss: 0.0059732901863753796\n",
      "Epoch 85, Loss: 0.017557481303811073\n",
      "Epoch 86, Loss: 0.021926598623394966\n",
      "Epoch 87, Loss: 0.01235639862716198\n",
      "Epoch 88, Loss: 0.008439458906650543\n",
      "Epoch 89, Loss: 0.014602165669202805\n",
      "Epoch 90, Loss: 0.011209717020392418\n",
      "Epoch 91, Loss: 0.005271035246551037\n",
      "Epoch 92, Loss: 0.009501519612967968\n",
      "Epoch 93, Loss: 0.004524792544543743\n",
      "Epoch 94, Loss: 0.01446095947176218\n",
      "Epoch 95, Loss: 0.0033808599691838026\n",
      "Epoch 96, Loss: 0.0077322074212133884\n",
      "Epoch 97, Loss: 0.004685061052441597\n",
      "Epoch 98, Loss: 0.00795002281665802\n",
      "Epoch 99, Loss: 0.012145977467298508\n",
      "Epoch 100, Loss: 0.014907456003129482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3718717098236084\n",
      "Epoch 1, Loss: 0.5015681385993958\n",
      "Epoch 2, Loss: 0.4995100200176239\n",
      "Epoch 3, Loss: 0.36503565311431885\n",
      "Epoch 4, Loss: 0.48160016536712646\n",
      "Epoch 5, Loss: 0.4599711000919342\n",
      "Epoch 6, Loss: 0.40511322021484375\n",
      "Epoch 7, Loss: 0.3511900007724762\n",
      "Epoch 8, Loss: 0.3557738661766052\n",
      "Epoch 9, Loss: 0.21166248619556427\n",
      "Epoch 10, Loss: 0.5204298496246338\n",
      "Epoch 11, Loss: 0.6876218914985657\n",
      "Epoch 12, Loss: 0.3662930130958557\n",
      "Epoch 13, Loss: 0.394045352935791\n",
      "Epoch 14, Loss: 0.2714651823043823\n",
      "Epoch 15, Loss: 0.2024223506450653\n",
      "Epoch 16, Loss: 0.3062882423400879\n",
      "Epoch 17, Loss: 0.1229868233203888\n",
      "Epoch 18, Loss: 0.3589247465133667\n",
      "Epoch 19, Loss: 0.2398829162120819\n",
      "Epoch 20, Loss: 0.17867451906204224\n",
      "Epoch 21, Loss: 0.08726335316896439\n",
      "Epoch 22, Loss: 0.11824704706668854\n",
      "Epoch 23, Loss: 0.0864911898970604\n",
      "Epoch 24, Loss: 0.16403144598007202\n",
      "Epoch 25, Loss: 0.2749288082122803\n",
      "Epoch 26, Loss: 0.09600044041872025\n",
      "Epoch 27, Loss: 0.30357515811920166\n",
      "Epoch 28, Loss: 0.05578339844942093\n",
      "Epoch 29, Loss: 0.035474617034196854\n",
      "Epoch 30, Loss: 0.1549796760082245\n",
      "Epoch 31, Loss: 0.0691898837685585\n",
      "Epoch 32, Loss: 0.05325314775109291\n",
      "Epoch 33, Loss: 0.07859786599874496\n",
      "Epoch 34, Loss: 0.07504424452781677\n",
      "Epoch 35, Loss: 0.04055553674697876\n",
      "Epoch 36, Loss: 0.0711386427283287\n",
      "Epoch 37, Loss: 0.05903548002243042\n",
      "Epoch 38, Loss: 0.06658929586410522\n",
      "Epoch 39, Loss: 0.07284092158079147\n",
      "Epoch 40, Loss: 0.05162710323929787\n",
      "Epoch 41, Loss: 0.05668363347649574\n",
      "Epoch 42, Loss: 0.028019066900014877\n",
      "Epoch 43, Loss: 0.06922769546508789\n",
      "Epoch 44, Loss: 0.012273754924535751\n",
      "Epoch 45, Loss: 0.027730189263820648\n",
      "Epoch 46, Loss: 0.040455933660268784\n",
      "Epoch 47, Loss: 0.06376343220472336\n",
      "Epoch 48, Loss: 0.02689417451620102\n",
      "Epoch 49, Loss: 0.008870748803019524\n",
      "Epoch 50, Loss: 0.02847125381231308\n",
      "Epoch 51, Loss: 0.021242814138531685\n",
      "Epoch 52, Loss: 0.017330769449472427\n",
      "Epoch 53, Loss: 0.027821213006973267\n",
      "Epoch 54, Loss: 0.014047364704310894\n",
      "Epoch 55, Loss: 0.02542736940085888\n",
      "Epoch 56, Loss: 0.010185929015278816\n",
      "Epoch 57, Loss: 0.0216001458466053\n",
      "Epoch 58, Loss: 0.007299264892935753\n",
      "Epoch 59, Loss: 0.04047904908657074\n",
      "Epoch 60, Loss: 0.013196339830756187\n",
      "Epoch 61, Loss: 0.010164163075387478\n",
      "Epoch 62, Loss: 0.019119028002023697\n",
      "Epoch 63, Loss: 0.02008775621652603\n",
      "Epoch 64, Loss: 0.019183054566383362\n",
      "Epoch 65, Loss: 0.03746737539768219\n",
      "Epoch 66, Loss: 0.026348087936639786\n",
      "Epoch 67, Loss: 0.032761264592409134\n",
      "Epoch 68, Loss: 0.0166554544121027\n",
      "Epoch 69, Loss: 0.012857705354690552\n",
      "Epoch 70, Loss: 0.033855605870485306\n",
      "Epoch 71, Loss: 0.012815941125154495\n",
      "Epoch 72, Loss: 0.008143145591020584\n",
      "Epoch 73, Loss: 0.01783824898302555\n",
      "Epoch 74, Loss: 0.017685987055301666\n",
      "Epoch 75, Loss: 0.008302719332277775\n",
      "Epoch 76, Loss: 0.008327601477503777\n",
      "Epoch 77, Loss: 0.024073975160717964\n",
      "Epoch 78, Loss: 0.01999429054558277\n",
      "Epoch 79, Loss: 0.01281614601612091\n",
      "Epoch 80, Loss: 0.010073613375425339\n",
      "Epoch 81, Loss: 0.009587637148797512\n",
      "Epoch 82, Loss: 0.02178756147623062\n",
      "Epoch 83, Loss: 0.010047335177659988\n",
      "Epoch 84, Loss: 0.009100041352212429\n",
      "Epoch 85, Loss: 0.006547447759658098\n",
      "Epoch 86, Loss: 0.006024789996445179\n",
      "Epoch 87, Loss: 0.010583797469735146\n",
      "Epoch 88, Loss: 0.03025243617594242\n",
      "Epoch 89, Loss: 0.008551246486604214\n",
      "Epoch 90, Loss: 0.012642276473343372\n",
      "Epoch 91, Loss: 0.008151139132678509\n",
      "Epoch 92, Loss: 0.004657902754843235\n",
      "Epoch 93, Loss: 0.006020979955792427\n",
      "Epoch 94, Loss: 0.025242364034056664\n",
      "Epoch 95, Loss: 0.009166097268462181\n",
      "Epoch 96, Loss: 0.005900869145989418\n",
      "Epoch 97, Loss: 0.0059092845767736435\n",
      "Epoch 98, Loss: 0.007882067002356052\n",
      "Epoch 99, Loss: 0.006809840444475412\n",
      "Epoch 100, Loss: 0.008810807950794697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.4055702686309814\n",
      "Epoch 1, Loss: 0.8982899188995361\n",
      "Epoch 2, Loss: 0.40482282638549805\n",
      "Epoch 3, Loss: 0.6792933940887451\n",
      "Epoch 4, Loss: 0.5262038707733154\n",
      "Epoch 5, Loss: 0.3524671792984009\n",
      "Epoch 6, Loss: 0.6278949975967407\n",
      "Epoch 7, Loss: 0.41150009632110596\n",
      "Epoch 8, Loss: 1.0810781717300415\n",
      "Epoch 9, Loss: 0.5345569849014282\n",
      "Epoch 10, Loss: 0.49217987060546875\n",
      "Epoch 11, Loss: 0.32115596532821655\n",
      "Epoch 12, Loss: 0.2866004407405853\n",
      "Epoch 13, Loss: 0.5271336436271667\n",
      "Epoch 14, Loss: 0.27289140224456787\n",
      "Epoch 15, Loss: 0.4173499047756195\n",
      "Epoch 16, Loss: 0.28213536739349365\n",
      "Epoch 17, Loss: 0.1495736539363861\n",
      "Epoch 18, Loss: 0.10568352788686752\n",
      "Epoch 19, Loss: 0.19471801817417145\n",
      "Epoch 20, Loss: 0.22537916898727417\n",
      "Epoch 21, Loss: 0.2473408579826355\n",
      "Epoch 22, Loss: 0.17191936075687408\n",
      "Epoch 23, Loss: 0.45813778042793274\n",
      "Epoch 24, Loss: 0.12256556004285812\n",
      "Epoch 25, Loss: 0.13393191993236542\n",
      "Epoch 26, Loss: 0.48476117849349976\n",
      "Epoch 27, Loss: 0.3119622766971588\n",
      "Epoch 28, Loss: 0.08599820733070374\n",
      "Epoch 29, Loss: 0.18450012803077698\n",
      "Epoch 30, Loss: 0.17446595430374146\n",
      "Epoch 31, Loss: 0.05149667710065842\n",
      "Epoch 32, Loss: 0.05539556220173836\n",
      "Epoch 33, Loss: 0.1029132604598999\n",
      "Epoch 34, Loss: 0.03674525395035744\n",
      "Epoch 35, Loss: 0.05650673434138298\n",
      "Epoch 36, Loss: 0.09899093210697174\n",
      "Epoch 37, Loss: 0.07169432938098907\n",
      "Epoch 38, Loss: 0.03616754338145256\n",
      "Epoch 39, Loss: 0.047071587294340134\n",
      "Epoch 40, Loss: 0.047423988580703735\n",
      "Epoch 41, Loss: 0.06222843378782272\n",
      "Epoch 42, Loss: 0.04863923043012619\n",
      "Epoch 43, Loss: 0.04329029470682144\n",
      "Epoch 44, Loss: 0.0791599452495575\n",
      "Epoch 45, Loss: 0.04703810065984726\n",
      "Epoch 46, Loss: 0.052126411348581314\n",
      "Epoch 47, Loss: 0.10012742877006531\n",
      "Epoch 48, Loss: 0.02733040042221546\n",
      "Epoch 49, Loss: 0.021419299766421318\n",
      "Epoch 50, Loss: 0.04252740740776062\n",
      "Epoch 51, Loss: 0.04680969938635826\n",
      "Epoch 52, Loss: 0.01746843010187149\n",
      "Epoch 53, Loss: 0.022378502413630486\n",
      "Epoch 54, Loss: 0.02820255048573017\n",
      "Epoch 55, Loss: 0.017492329701781273\n",
      "Epoch 56, Loss: 0.020098350942134857\n",
      "Epoch 57, Loss: 0.015439312905073166\n",
      "Epoch 58, Loss: 0.019927239045500755\n",
      "Epoch 59, Loss: 0.06506281346082687\n",
      "Epoch 60, Loss: 0.03917635977268219\n",
      "Epoch 61, Loss: 0.012233305722475052\n",
      "Epoch 62, Loss: 0.01750265620648861\n",
      "Epoch 63, Loss: 0.03215251863002777\n",
      "Epoch 64, Loss: 0.025101181119680405\n",
      "Epoch 65, Loss: 0.011859098449349403\n",
      "Epoch 66, Loss: 0.03850395977497101\n",
      "Epoch 67, Loss: 0.015433869324624538\n",
      "Epoch 68, Loss: 0.02734050527215004\n",
      "Epoch 69, Loss: 0.012337119318544865\n",
      "Epoch 70, Loss: 0.01950554922223091\n",
      "Epoch 71, Loss: 0.01598174124956131\n",
      "Epoch 72, Loss: 0.018403779715299606\n",
      "Epoch 73, Loss: 0.02637924626469612\n",
      "Epoch 74, Loss: 0.02118963934481144\n",
      "Epoch 75, Loss: 0.016933225095272064\n",
      "Epoch 76, Loss: 0.009881168603897095\n",
      "Epoch 77, Loss: 0.012053394690155983\n",
      "Epoch 78, Loss: 0.014795731753110886\n",
      "Epoch 79, Loss: 0.006555713247507811\n",
      "Epoch 80, Loss: 0.021594392135739326\n",
      "Epoch 81, Loss: 0.004686344414949417\n",
      "Epoch 82, Loss: 0.00982620194554329\n",
      "Epoch 83, Loss: 0.009929699823260307\n",
      "Epoch 84, Loss: 0.012742583639919758\n",
      "Epoch 85, Loss: 0.009362226352095604\n",
      "Epoch 86, Loss: 0.04896635562181473\n",
      "Epoch 87, Loss: 0.00927787460386753\n",
      "Epoch 88, Loss: 0.018891286104917526\n",
      "Epoch 89, Loss: 0.0115402452647686\n",
      "Epoch 90, Loss: 0.010989151895046234\n",
      "Epoch 91, Loss: 0.006444657687097788\n",
      "Epoch 92, Loss: 0.01789809949696064\n",
      "Epoch 93, Loss: 0.00712900934740901\n",
      "Epoch 94, Loss: 0.004753714427351952\n",
      "Epoch 95, Loss: 0.0055887941271066666\n",
      "Epoch 96, Loss: 0.009127022698521614\n",
      "Epoch 97, Loss: 0.01668716035783291\n",
      "Epoch 98, Loss: 0.008338486775755882\n",
      "Epoch 99, Loss: 0.014166455715894699\n",
      "Epoch 100, Loss: 0.011858055368065834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.6046018600463867\n",
      "Epoch 1, Loss: 0.5251145958900452\n",
      "Epoch 2, Loss: 0.6113039255142212\n",
      "Epoch 3, Loss: 0.49606582522392273\n",
      "Epoch 4, Loss: 0.5067823529243469\n",
      "Epoch 5, Loss: 0.4634801149368286\n",
      "Epoch 6, Loss: 0.6534597277641296\n",
      "Epoch 7, Loss: 0.33366772532463074\n",
      "Epoch 8, Loss: 0.2937937080860138\n",
      "Epoch 9, Loss: 0.1735784262418747\n",
      "Epoch 10, Loss: 0.3545886278152466\n",
      "Epoch 11, Loss: 0.09962485730648041\n",
      "Epoch 12, Loss: 0.18257443606853485\n",
      "Epoch 13, Loss: 0.24430124461650848\n",
      "Epoch 14, Loss: 0.250346839427948\n",
      "Epoch 15, Loss: 0.35160908102989197\n",
      "Epoch 16, Loss: 0.20975182950496674\n",
      "Epoch 17, Loss: 0.35378050804138184\n",
      "Epoch 18, Loss: 0.4928569793701172\n",
      "Epoch 19, Loss: 0.1425362229347229\n",
      "Epoch 20, Loss: 0.2912857234477997\n",
      "Epoch 21, Loss: 0.14264699816703796\n",
      "Epoch 22, Loss: 0.12590976059436798\n",
      "Epoch 23, Loss: 0.2590445280075073\n",
      "Epoch 24, Loss: 0.17058753967285156\n",
      "Epoch 25, Loss: 0.18314427137374878\n",
      "Epoch 26, Loss: 0.11950501054525375\n",
      "Epoch 27, Loss: 0.05933881551027298\n",
      "Epoch 28, Loss: 0.2502659559249878\n",
      "Epoch 29, Loss: 0.08949132263660431\n",
      "Epoch 30, Loss: 0.060008399188518524\n",
      "Epoch 31, Loss: 0.11612065881490707\n",
      "Epoch 32, Loss: 0.07337705790996552\n",
      "Epoch 33, Loss: 0.14515884220600128\n",
      "Epoch 34, Loss: 0.09718745946884155\n",
      "Epoch 35, Loss: 0.11129400134086609\n",
      "Epoch 36, Loss: 0.10538547486066818\n",
      "Epoch 37, Loss: 0.030061155557632446\n",
      "Epoch 38, Loss: 0.05314860865473747\n",
      "Epoch 39, Loss: 0.043680645525455475\n",
      "Epoch 40, Loss: 0.10332498699426651\n",
      "Epoch 41, Loss: 0.09112746268510818\n",
      "Epoch 42, Loss: 0.09163826704025269\n",
      "Epoch 43, Loss: 0.022144118323922157\n",
      "Epoch 44, Loss: 0.0185343399643898\n",
      "Epoch 45, Loss: 0.04806986078619957\n",
      "Epoch 46, Loss: 0.014987647533416748\n",
      "Epoch 47, Loss: 0.020752843469381332\n",
      "Epoch 48, Loss: 0.012626897543668747\n",
      "Epoch 49, Loss: 0.04864709451794624\n",
      "Epoch 50, Loss: 0.030809663236141205\n",
      "Epoch 51, Loss: 0.05440088361501694\n",
      "Epoch 52, Loss: 0.1325322687625885\n",
      "Epoch 53, Loss: 0.01761738397181034\n",
      "Epoch 54, Loss: 0.02853068709373474\n",
      "Epoch 55, Loss: 0.012489620596170425\n",
      "Epoch 56, Loss: 0.032465316355228424\n",
      "Epoch 57, Loss: 0.018960462883114815\n",
      "Epoch 58, Loss: 0.010723942890763283\n",
      "Epoch 59, Loss: 0.037030041217803955\n",
      "Epoch 60, Loss: 0.03873056173324585\n",
      "Epoch 61, Loss: 0.01470984984189272\n",
      "Epoch 62, Loss: 0.028579749166965485\n",
      "Epoch 63, Loss: 0.016862796619534492\n",
      "Epoch 64, Loss: 0.013545587658882141\n",
      "Epoch 65, Loss: 0.012966036796569824\n",
      "Epoch 66, Loss: 0.019467512145638466\n",
      "Epoch 67, Loss: 0.017041094601154327\n",
      "Epoch 68, Loss: 0.007305977400392294\n",
      "Epoch 69, Loss: 0.006675144657492638\n",
      "Epoch 70, Loss: 0.012709621340036392\n",
      "Epoch 71, Loss: 0.011174731887876987\n",
      "Epoch 72, Loss: 0.019291717559099197\n",
      "Epoch 73, Loss: 0.019130267202854156\n",
      "Epoch 74, Loss: 0.01217858400195837\n",
      "Epoch 75, Loss: 0.018978100270032883\n",
      "Epoch 76, Loss: 0.04803510382771492\n",
      "Epoch 77, Loss: 0.020739801228046417\n",
      "Epoch 78, Loss: 0.009236883372068405\n",
      "Epoch 79, Loss: 0.011520158499479294\n",
      "Epoch 80, Loss: 0.011295833624899387\n",
      "Epoch 81, Loss: 0.01012014877051115\n",
      "Epoch 82, Loss: 0.009917981922626495\n",
      "Epoch 83, Loss: 0.00822746567428112\n",
      "Epoch 84, Loss: 0.012702438049018383\n",
      "Epoch 85, Loss: 0.010013281367719173\n",
      "Epoch 86, Loss: 0.007043571211397648\n",
      "Epoch 87, Loss: 0.006758039817214012\n",
      "Epoch 88, Loss: 0.017783023416996002\n",
      "Epoch 89, Loss: 0.005326033104211092\n",
      "Epoch 90, Loss: 0.00785608310252428\n",
      "Epoch 91, Loss: 0.004074243828654289\n",
      "Epoch 92, Loss: 0.010040526278316975\n",
      "Epoch 93, Loss: 0.003531138878315687\n",
      "Epoch 94, Loss: 0.013197815977036953\n",
      "Epoch 95, Loss: 0.011139372363686562\n",
      "Epoch 96, Loss: 0.009817700833082199\n",
      "Epoch 97, Loss: 0.007579786702990532\n",
      "Epoch 98, Loss: 0.007263587787747383\n",
      "Epoch 99, Loss: 0.013113371096551418\n",
      "Epoch 100, Loss: 0.006590941920876503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.4159225225448608\n",
      "Epoch 1, Loss: 0.5489168763160706\n",
      "Epoch 2, Loss: 0.38198134303092957\n",
      "Epoch 3, Loss: 0.6951526999473572\n",
      "Epoch 4, Loss: 1.0570098161697388\n",
      "Epoch 5, Loss: 0.3600059747695923\n",
      "Epoch 6, Loss: 0.7194330096244812\n",
      "Epoch 7, Loss: 0.24287107586860657\n",
      "Epoch 8, Loss: 0.4120134115219116\n",
      "Epoch 9, Loss: 0.267667680978775\n",
      "Epoch 10, Loss: 0.3072037994861603\n",
      "Epoch 11, Loss: 0.29283517599105835\n",
      "Epoch 12, Loss: 0.2975473701953888\n",
      "Epoch 13, Loss: 0.5770837664604187\n",
      "Epoch 14, Loss: 0.207319438457489\n",
      "Epoch 15, Loss: 0.20371931791305542\n",
      "Epoch 16, Loss: 0.7749761939048767\n",
      "Epoch 17, Loss: 0.35070517659187317\n",
      "Epoch 18, Loss: 0.3320353031158447\n",
      "Epoch 19, Loss: 0.23534226417541504\n",
      "Epoch 20, Loss: 0.12604063749313354\n",
      "Epoch 21, Loss: 0.15106917917728424\n",
      "Epoch 22, Loss: 0.2552044689655304\n",
      "Epoch 23, Loss: 0.10675521939992905\n",
      "Epoch 24, Loss: 0.17116641998291016\n",
      "Epoch 25, Loss: 0.13748739659786224\n",
      "Epoch 26, Loss: 0.1391317993402481\n",
      "Epoch 27, Loss: 0.18667006492614746\n",
      "Epoch 28, Loss: 0.07301660627126694\n",
      "Epoch 29, Loss: 0.06702902168035507\n",
      "Epoch 30, Loss: 0.05509762465953827\n",
      "Epoch 31, Loss: 0.0579848438501358\n",
      "Epoch 32, Loss: 0.07530030608177185\n",
      "Epoch 33, Loss: 0.0778128132224083\n",
      "Epoch 34, Loss: 0.17487269639968872\n",
      "Epoch 35, Loss: 0.028120126575231552\n",
      "Epoch 36, Loss: 0.06667938083410263\n",
      "Epoch 37, Loss: 0.06504904478788376\n",
      "Epoch 38, Loss: 0.11106949299573898\n",
      "Epoch 39, Loss: 0.0658515989780426\n",
      "Epoch 40, Loss: 0.03420480713248253\n",
      "Epoch 41, Loss: 0.04678557440638542\n",
      "Epoch 42, Loss: 0.041801389306783676\n",
      "Epoch 43, Loss: 0.06338116526603699\n",
      "Epoch 44, Loss: 0.06828044354915619\n",
      "Epoch 45, Loss: 0.024567708373069763\n",
      "Epoch 46, Loss: 0.12250110507011414\n",
      "Epoch 47, Loss: 0.016021616756916046\n",
      "Epoch 48, Loss: 0.03953560069203377\n",
      "Epoch 49, Loss: 0.01857852190732956\n",
      "Epoch 50, Loss: 0.013996290042996407\n",
      "Epoch 51, Loss: 0.06870423257350922\n",
      "Epoch 52, Loss: 0.028487928211688995\n",
      "Epoch 53, Loss: 0.04945836961269379\n",
      "Epoch 54, Loss: 0.024157896637916565\n",
      "Epoch 55, Loss: 0.019575808197259903\n",
      "Epoch 56, Loss: 0.024257268756628036\n",
      "Epoch 57, Loss: 0.016966696828603745\n",
      "Epoch 58, Loss: 0.03014323115348816\n",
      "Epoch 59, Loss: 0.031318411231040955\n",
      "Epoch 60, Loss: 0.02498622238636017\n",
      "Epoch 61, Loss: 0.028505325317382812\n",
      "Epoch 62, Loss: 0.008968325331807137\n",
      "Epoch 63, Loss: 0.010329733602702618\n",
      "Epoch 64, Loss: 0.011906123720109463\n",
      "Epoch 65, Loss: 0.012357283383607864\n",
      "Epoch 66, Loss: 0.03186393156647682\n",
      "Epoch 67, Loss: 0.01894896849989891\n",
      "Epoch 68, Loss: 0.045737024396657944\n",
      "Epoch 69, Loss: 0.006348155438899994\n",
      "Epoch 70, Loss: 0.0266122929751873\n",
      "Epoch 71, Loss: 0.009216409176588058\n",
      "Epoch 72, Loss: 0.018946783617138863\n",
      "Epoch 73, Loss: 0.013007715344429016\n",
      "Epoch 74, Loss: 0.025438733398914337\n",
      "Epoch 75, Loss: 0.011280275881290436\n",
      "Epoch 76, Loss: 0.01066729985177517\n",
      "Epoch 77, Loss: 0.04422057420015335\n",
      "Epoch 78, Loss: 0.015596545301377773\n",
      "Epoch 79, Loss: 0.02111014537513256\n",
      "Epoch 80, Loss: 0.014907743781805038\n",
      "Epoch 81, Loss: 0.02159338817000389\n",
      "Epoch 82, Loss: 0.01995311677455902\n",
      "Epoch 83, Loss: 0.009626788087189198\n",
      "Epoch 84, Loss: 0.012491602450609207\n",
      "Epoch 85, Loss: 0.024159755557775497\n",
      "Epoch 86, Loss: 0.012447834014892578\n",
      "Epoch 87, Loss: 0.005851720925420523\n",
      "Epoch 88, Loss: 0.01948530040681362\n",
      "Epoch 89, Loss: 0.017694085836410522\n",
      "Epoch 90, Loss: 0.014525219798088074\n",
      "Epoch 91, Loss: 0.011569652706384659\n",
      "Epoch 92, Loss: 0.005359232425689697\n",
      "Epoch 93, Loss: 0.005837046541273594\n",
      "Epoch 94, Loss: 0.006164669990539551\n",
      "Epoch 95, Loss: 0.002610231749713421\n",
      "Epoch 96, Loss: 0.011327441781759262\n",
      "Epoch 97, Loss: 0.010106442496180534\n",
      "Epoch 98, Loss: 0.006636865437030792\n",
      "Epoch 99, Loss: 0.006203575059771538\n",
      "Epoch 100, Loss: 0.011122982017695904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.5481610298156738\n",
      "Epoch 1, Loss: 0.8459120392799377\n",
      "Epoch 2, Loss: 0.8635085821151733\n",
      "Epoch 3, Loss: 0.890941858291626\n",
      "Epoch 4, Loss: 1.0147778987884521\n",
      "Epoch 5, Loss: 0.32412946224212646\n",
      "Epoch 6, Loss: 0.7809844017028809\n",
      "Epoch 7, Loss: 0.46201932430267334\n",
      "Epoch 8, Loss: 0.4981633424758911\n",
      "Epoch 9, Loss: 0.3475090265274048\n",
      "Epoch 10, Loss: 0.28354862332344055\n",
      "Epoch 11, Loss: 0.5906908512115479\n",
      "Epoch 12, Loss: 0.4956471621990204\n",
      "Epoch 13, Loss: 0.21662762761116028\n",
      "Epoch 14, Loss: 0.2825368642807007\n",
      "Epoch 15, Loss: 0.3767760097980499\n",
      "Epoch 16, Loss: 0.15388156473636627\n",
      "Epoch 17, Loss: 0.25576213002204895\n",
      "Epoch 18, Loss: 0.05815598741173744\n",
      "Epoch 19, Loss: 0.3553086221218109\n",
      "Epoch 20, Loss: 0.1467151790857315\n",
      "Epoch 21, Loss: 0.2198912352323532\n",
      "Epoch 22, Loss: 0.2617482542991638\n",
      "Epoch 23, Loss: 0.16250506043434143\n",
      "Epoch 24, Loss: 0.09679112583398819\n",
      "Epoch 25, Loss: 0.2651444673538208\n",
      "Epoch 26, Loss: 0.14091235399246216\n",
      "Epoch 27, Loss: 0.08722544461488724\n",
      "Epoch 28, Loss: 0.05385412648320198\n",
      "Epoch 29, Loss: 0.07243109494447708\n",
      "Epoch 30, Loss: 0.03787407651543617\n",
      "Epoch 31, Loss: 0.1885828822851181\n",
      "Epoch 32, Loss: 0.17431515455245972\n",
      "Epoch 33, Loss: 0.08309338986873627\n",
      "Epoch 34, Loss: 0.058844342827796936\n",
      "Epoch 35, Loss: 0.09853553026914597\n",
      "Epoch 36, Loss: 0.11176024377346039\n",
      "Epoch 37, Loss: 0.04930892214179039\n",
      "Epoch 38, Loss: 0.04243350028991699\n",
      "Epoch 39, Loss: 0.07692962884902954\n",
      "Epoch 40, Loss: 0.07162806391716003\n",
      "Epoch 41, Loss: 0.03778944909572601\n",
      "Epoch 42, Loss: 0.027456331998109818\n",
      "Epoch 43, Loss: 0.04021059349179268\n",
      "Epoch 44, Loss: 0.04195047914981842\n",
      "Epoch 45, Loss: 0.15018273890018463\n",
      "Epoch 46, Loss: 0.17194432020187378\n",
      "Epoch 47, Loss: 0.07920321077108383\n",
      "Epoch 48, Loss: 0.02353358082473278\n",
      "Epoch 49, Loss: 0.11050665378570557\n",
      "Epoch 50, Loss: 0.04744219407439232\n",
      "Epoch 51, Loss: 0.08711744844913483\n",
      "Epoch 52, Loss: 0.03153940662741661\n",
      "Epoch 53, Loss: 0.0711006298661232\n",
      "Epoch 54, Loss: 0.01691792532801628\n",
      "Epoch 55, Loss: 0.03876868262887001\n",
      "Epoch 56, Loss: 0.020270105451345444\n",
      "Epoch 57, Loss: 0.03496601805090904\n",
      "Epoch 58, Loss: 0.061489615589380264\n",
      "Epoch 59, Loss: 0.02443578653037548\n",
      "Epoch 60, Loss: 0.023530451580882072\n",
      "Epoch 61, Loss: 0.02018858678638935\n",
      "Epoch 62, Loss: 0.026155268773436546\n",
      "Epoch 63, Loss: 0.026915663853287697\n",
      "Epoch 64, Loss: 0.021214356645941734\n",
      "Epoch 65, Loss: 0.021796785295009613\n",
      "Epoch 66, Loss: 0.005540969781577587\n",
      "Epoch 67, Loss: 0.02524026483297348\n",
      "Epoch 68, Loss: 0.023647019639611244\n",
      "Epoch 69, Loss: 0.041763193905353546\n",
      "Epoch 70, Loss: 0.03111104853451252\n",
      "Epoch 71, Loss: 0.013748891651630402\n",
      "Epoch 72, Loss: 0.009053688496351242\n",
      "Epoch 73, Loss: 0.009069100022315979\n",
      "Epoch 74, Loss: 0.046288155019283295\n",
      "Epoch 75, Loss: 0.034766629338264465\n",
      "Epoch 76, Loss: 0.016342366114258766\n",
      "Epoch 77, Loss: 0.014716889709234238\n",
      "Epoch 78, Loss: 0.025182265788316727\n",
      "Epoch 79, Loss: 0.0085119204595685\n",
      "Epoch 80, Loss: 0.02091320976614952\n",
      "Epoch 81, Loss: 0.023361116647720337\n",
      "Epoch 82, Loss: 0.00522348890081048\n",
      "Epoch 83, Loss: 0.011553185991942883\n",
      "Epoch 84, Loss: 0.007476679049432278\n",
      "Epoch 85, Loss: 0.014344785362482071\n",
      "Epoch 86, Loss: 0.029289595782756805\n",
      "Epoch 87, Loss: 0.009553777053952217\n",
      "Epoch 88, Loss: 0.015475645661354065\n",
      "Epoch 89, Loss: 0.07025468349456787\n",
      "Epoch 90, Loss: 0.007567157503217459\n",
      "Epoch 91, Loss: 0.015041298232972622\n",
      "Epoch 92, Loss: 0.007754993159323931\n",
      "Epoch 93, Loss: 0.011122475378215313\n",
      "Epoch 94, Loss: 0.008786436170339584\n",
      "Epoch 95, Loss: 0.02565741166472435\n",
      "Epoch 96, Loss: 0.004545294214040041\n",
      "Epoch 97, Loss: 0.010730806738138199\n",
      "Epoch 98, Loss: 0.03244319185614586\n",
      "Epoch 99, Loss: 0.011291621252894402\n",
      "Epoch 100, Loss: 0.003618583083152771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.568000078201294\n",
      "Epoch 1, Loss: 0.5343044400215149\n",
      "Epoch 2, Loss: 0.7338420152664185\n",
      "Epoch 3, Loss: 0.755003035068512\n",
      "Epoch 4, Loss: 0.48506960272789\n",
      "Epoch 5, Loss: 0.8418667912483215\n",
      "Epoch 6, Loss: 0.5947473645210266\n",
      "Epoch 7, Loss: 0.4170840084552765\n",
      "Epoch 8, Loss: 0.3558422327041626\n",
      "Epoch 9, Loss: 0.43481796979904175\n",
      "Epoch 10, Loss: 0.47335487604141235\n",
      "Epoch 11, Loss: 0.2698940634727478\n",
      "Epoch 12, Loss: 0.27267584204673767\n",
      "Epoch 13, Loss: 0.41186290979385376\n",
      "Epoch 14, Loss: 0.28333404660224915\n",
      "Epoch 15, Loss: 0.19684740900993347\n",
      "Epoch 16, Loss: 0.35990461707115173\n",
      "Epoch 17, Loss: 0.8471279740333557\n",
      "Epoch 18, Loss: 0.15510420501232147\n",
      "Epoch 19, Loss: 0.12622933089733124\n",
      "Epoch 20, Loss: 0.2698977589607239\n",
      "Epoch 21, Loss: 0.07942822575569153\n",
      "Epoch 22, Loss: 0.17872856557369232\n",
      "Epoch 23, Loss: 0.29495957493782043\n",
      "Epoch 24, Loss: 0.0824822336435318\n",
      "Epoch 25, Loss: 0.10833762586116791\n",
      "Epoch 26, Loss: 0.11128222942352295\n",
      "Epoch 27, Loss: 0.15247590839862823\n",
      "Epoch 28, Loss: 0.16128891706466675\n",
      "Epoch 29, Loss: 0.1408889889717102\n",
      "Epoch 30, Loss: 0.06355293095111847\n",
      "Epoch 31, Loss: 0.0686500295996666\n",
      "Epoch 32, Loss: 0.10866828262805939\n",
      "Epoch 33, Loss: 0.08864560723304749\n",
      "Epoch 34, Loss: 0.0814632996916771\n",
      "Epoch 35, Loss: 0.04514293000102043\n",
      "Epoch 36, Loss: 0.07906518876552582\n",
      "Epoch 37, Loss: 0.06255516409873962\n",
      "Epoch 38, Loss: 0.07340635359287262\n",
      "Epoch 39, Loss: 0.10616887360811234\n",
      "Epoch 40, Loss: 0.018910415470600128\n",
      "Epoch 41, Loss: 0.10225376486778259\n",
      "Epoch 42, Loss: 0.11303099244832993\n",
      "Epoch 43, Loss: 0.013601629994809628\n",
      "Epoch 44, Loss: 0.08075584471225739\n",
      "Epoch 45, Loss: 0.04283979907631874\n",
      "Epoch 46, Loss: 0.02471541427075863\n",
      "Epoch 47, Loss: 0.03130336478352547\n",
      "Epoch 48, Loss: 0.012041364796459675\n",
      "Epoch 49, Loss: 0.039251137524843216\n",
      "Epoch 50, Loss: 0.016799669712781906\n",
      "Epoch 51, Loss: 0.03515690192580223\n",
      "Epoch 52, Loss: 0.04214804619550705\n",
      "Epoch 53, Loss: 0.015410090796649456\n",
      "Epoch 54, Loss: 0.04667110741138458\n",
      "Epoch 55, Loss: 0.059791095554828644\n",
      "Epoch 56, Loss: 0.01720832847058773\n",
      "Epoch 57, Loss: 0.01527288556098938\n",
      "Epoch 58, Loss: 0.006621412932872772\n",
      "Epoch 59, Loss: 0.008621914312243462\n",
      "Epoch 60, Loss: 0.035315658897161484\n",
      "Epoch 61, Loss: 0.015536804683506489\n",
      "Epoch 62, Loss: 0.05096278712153435\n",
      "Epoch 63, Loss: 0.011646035127341747\n",
      "Epoch 64, Loss: 0.005578550044447184\n",
      "Epoch 65, Loss: 0.010751164518296719\n",
      "Epoch 66, Loss: 0.015865080058574677\n",
      "Epoch 67, Loss: 0.01600690372288227\n",
      "Epoch 68, Loss: 0.029035409912467003\n",
      "Epoch 69, Loss: 0.018090639263391495\n",
      "Epoch 70, Loss: 0.015728764235973358\n",
      "Epoch 71, Loss: 0.011221199296414852\n",
      "Epoch 72, Loss: 0.015638787299394608\n",
      "Epoch 73, Loss: 0.009577374905347824\n",
      "Epoch 74, Loss: 0.020613541826605797\n",
      "Epoch 75, Loss: 0.01201164536178112\n",
      "Epoch 76, Loss: 0.020399190485477448\n",
      "Epoch 77, Loss: 0.006875122897326946\n",
      "Epoch 78, Loss: 0.01919594220817089\n",
      "Epoch 79, Loss: 0.009795566089451313\n",
      "Epoch 80, Loss: 0.008939745835959911\n",
      "Epoch 81, Loss: 0.022386500611901283\n",
      "Epoch 82, Loss: 0.004121412988752127\n",
      "Epoch 83, Loss: 0.008999373763799667\n",
      "Epoch 84, Loss: 0.008302059024572372\n",
      "Epoch 85, Loss: 0.016588052734732628\n",
      "Epoch 86, Loss: 0.010426294058561325\n",
      "Epoch 87, Loss: 0.01837848871946335\n",
      "Epoch 88, Loss: 0.007832217961549759\n",
      "Epoch 89, Loss: 0.017479754984378815\n",
      "Epoch 90, Loss: 0.009294507093727589\n",
      "Epoch 91, Loss: 0.009322835132479668\n",
      "Epoch 92, Loss: 0.005890209227800369\n",
      "Epoch 93, Loss: 0.01977786049246788\n",
      "Epoch 94, Loss: 0.008279579691588879\n",
      "Epoch 95, Loss: 0.005842933431267738\n",
      "Epoch 96, Loss: 0.005678020417690277\n",
      "Epoch 97, Loss: 0.005947310943156481\n",
      "Epoch 98, Loss: 0.00960117019712925\n",
      "Epoch 99, Loss: 0.006914326921105385\n",
      "Epoch 100, Loss: 0.004863358102738857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3911550045013428\n",
      "Epoch 1, Loss: 0.4054791331291199\n",
      "Epoch 2, Loss: 0.7498067021369934\n",
      "Epoch 3, Loss: 0.38483235239982605\n",
      "Epoch 4, Loss: 0.36594831943511963\n",
      "Epoch 5, Loss: 1.3327938318252563\n",
      "Epoch 6, Loss: 0.8388979434967041\n",
      "Epoch 7, Loss: 0.3988863229751587\n",
      "Epoch 8, Loss: 0.3632033169269562\n",
      "Epoch 9, Loss: 0.994683563709259\n",
      "Epoch 10, Loss: 0.15862472355365753\n",
      "Epoch 11, Loss: 0.2626745402812958\n",
      "Epoch 12, Loss: 0.1713082641363144\n",
      "Epoch 13, Loss: 0.16957469284534454\n",
      "Epoch 14, Loss: 0.21741288900375366\n",
      "Epoch 15, Loss: 0.12297965586185455\n",
      "Epoch 16, Loss: 0.17943696677684784\n",
      "Epoch 17, Loss: 0.5000495314598083\n",
      "Epoch 18, Loss: 0.11896118521690369\n",
      "Epoch 19, Loss: 0.1514398604631424\n",
      "Epoch 20, Loss: 0.20396700501441956\n",
      "Epoch 21, Loss: 0.1843474954366684\n",
      "Epoch 22, Loss: 0.1579640507698059\n",
      "Epoch 23, Loss: 0.12570978701114655\n",
      "Epoch 24, Loss: 0.09887689352035522\n",
      "Epoch 25, Loss: 0.06683111935853958\n",
      "Epoch 26, Loss: 0.053447943180799484\n",
      "Epoch 27, Loss: 0.08653721213340759\n",
      "Epoch 28, Loss: 0.06230988726019859\n",
      "Epoch 29, Loss: 0.1287820190191269\n",
      "Epoch 30, Loss: 0.12828506529331207\n",
      "Epoch 31, Loss: 0.07513877004384995\n",
      "Epoch 32, Loss: 0.015981430187821388\n",
      "Epoch 33, Loss: 0.07478848099708557\n",
      "Epoch 34, Loss: 0.07525832206010818\n",
      "Epoch 35, Loss: 0.10660770535469055\n",
      "Epoch 36, Loss: 0.020964378491044044\n",
      "Epoch 37, Loss: 0.08020227402448654\n",
      "Epoch 38, Loss: 0.038506243377923965\n",
      "Epoch 39, Loss: 0.02247431129217148\n",
      "Epoch 40, Loss: 0.07187575101852417\n",
      "Epoch 41, Loss: 0.04496372118592262\n",
      "Epoch 42, Loss: 0.11159609258174896\n",
      "Epoch 43, Loss: 0.043279342353343964\n",
      "Epoch 44, Loss: 0.037983253598213196\n",
      "Epoch 45, Loss: 0.06676686555147171\n",
      "Epoch 46, Loss: 0.022554848343133926\n",
      "Epoch 47, Loss: 0.02085968106985092\n",
      "Epoch 48, Loss: 0.027158191427588463\n",
      "Epoch 49, Loss: 0.037982966750860214\n",
      "Epoch 50, Loss: 0.03622562810778618\n",
      "Epoch 51, Loss: 0.018221814185380936\n",
      "Epoch 52, Loss: 0.027260133996605873\n",
      "Epoch 53, Loss: 0.027911169454455376\n",
      "Epoch 54, Loss: 0.051653698086738586\n",
      "Epoch 55, Loss: 0.03290928900241852\n",
      "Epoch 56, Loss: 0.005205162800848484\n",
      "Epoch 57, Loss: 0.01120032463222742\n",
      "Epoch 58, Loss: 0.06004789099097252\n",
      "Epoch 59, Loss: 0.013526077382266521\n",
      "Epoch 60, Loss: 0.020884471014142036\n",
      "Epoch 61, Loss: 0.018921051174402237\n",
      "Epoch 62, Loss: 0.031426284462213516\n",
      "Epoch 63, Loss: 0.009596600197255611\n",
      "Epoch 64, Loss: 0.06322171539068222\n",
      "Epoch 65, Loss: 0.01910683885216713\n",
      "Epoch 66, Loss: 0.016621792688965797\n",
      "Epoch 67, Loss: 0.01017796527594328\n",
      "Epoch 68, Loss: 0.02525748871266842\n",
      "Epoch 69, Loss: 0.01266370341181755\n",
      "Epoch 70, Loss: 0.007841631770133972\n",
      "Epoch 71, Loss: 0.01645578444004059\n",
      "Epoch 72, Loss: 0.007927251048386097\n",
      "Epoch 73, Loss: 0.012816228903830051\n",
      "Epoch 74, Loss: 0.011541827581822872\n",
      "Epoch 75, Loss: 0.01916501112282276\n",
      "Epoch 76, Loss: 0.008408934809267521\n",
      "Epoch 77, Loss: 0.008055168204009533\n",
      "Epoch 78, Loss: 0.016118159517645836\n",
      "Epoch 79, Loss: 0.008636286482214928\n",
      "Epoch 80, Loss: 0.011115177534520626\n",
      "Epoch 81, Loss: 0.02426861971616745\n",
      "Epoch 82, Loss: 0.011520938016474247\n",
      "Epoch 83, Loss: 0.06862699240446091\n",
      "Epoch 84, Loss: 0.02751546911895275\n",
      "Epoch 85, Loss: 0.01141902431845665\n",
      "Epoch 86, Loss: 0.013682354241609573\n",
      "Epoch 87, Loss: 0.012077591381967068\n",
      "Epoch 88, Loss: 0.004824860021471977\n",
      "Epoch 89, Loss: 0.006934021599590778\n",
      "Epoch 90, Loss: 0.006208124104887247\n",
      "Epoch 91, Loss: 0.06950488686561584\n",
      "Epoch 92, Loss: 0.005916645750403404\n",
      "Epoch 93, Loss: 0.011150403879582882\n",
      "Epoch 94, Loss: 0.021281680092215538\n",
      "Epoch 95, Loss: 0.08054821938276291\n",
      "Epoch 96, Loss: 0.012121166102588177\n",
      "Epoch 97, Loss: 0.00916384533047676\n",
      "Epoch 98, Loss: 0.005237382370978594\n",
      "Epoch 99, Loss: 0.017550243064761162\n",
      "Epoch 100, Loss: 0.016756338998675346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3061221837997437\n",
      "Epoch 1, Loss: 0.5457364916801453\n",
      "Epoch 2, Loss: 1.1025125980377197\n",
      "Epoch 3, Loss: 0.6340473294258118\n",
      "Epoch 4, Loss: 0.47105878591537476\n",
      "Epoch 5, Loss: 0.30610066652297974\n",
      "Epoch 6, Loss: 0.6689372658729553\n",
      "Epoch 7, Loss: 0.4381714165210724\n",
      "Epoch 8, Loss: 0.6016308665275574\n",
      "Epoch 9, Loss: 0.22550565004348755\n",
      "Epoch 10, Loss: 0.36982953548431396\n",
      "Epoch 11, Loss: 0.3656812310218811\n",
      "Epoch 12, Loss: 0.2729667127132416\n",
      "Epoch 13, Loss: 1.0775885581970215\n",
      "Epoch 14, Loss: 0.2936690151691437\n",
      "Epoch 15, Loss: 0.2955954372882843\n",
      "Epoch 16, Loss: 0.1358940452337265\n",
      "Epoch 17, Loss: 0.22371233999729156\n",
      "Epoch 18, Loss: 0.2235444337129593\n",
      "Epoch 19, Loss: 0.30502623319625854\n",
      "Epoch 20, Loss: 0.1632150262594223\n",
      "Epoch 21, Loss: 0.1390235424041748\n",
      "Epoch 22, Loss: 0.12156607210636139\n",
      "Epoch 23, Loss: 0.267831027507782\n",
      "Epoch 24, Loss: 0.16725264489650726\n",
      "Epoch 25, Loss: 0.15249603986740112\n",
      "Epoch 26, Loss: 0.16782282292842865\n",
      "Epoch 27, Loss: 0.12538188695907593\n",
      "Epoch 28, Loss: 0.03146615996956825\n",
      "Epoch 29, Loss: 0.08017310500144958\n",
      "Epoch 30, Loss: 0.14456039667129517\n",
      "Epoch 31, Loss: 0.0206610020250082\n",
      "Epoch 32, Loss: 0.07954141497612\n",
      "Epoch 33, Loss: 0.13841602206230164\n",
      "Epoch 34, Loss: 0.06383766978979111\n",
      "Epoch 35, Loss: 0.06012575328350067\n",
      "Epoch 36, Loss: 0.06428918987512589\n",
      "Epoch 37, Loss: 0.1046183705329895\n",
      "Epoch 38, Loss: 0.02922210469841957\n",
      "Epoch 39, Loss: 0.023899909108877182\n",
      "Epoch 40, Loss: 0.037348970770835876\n",
      "Epoch 41, Loss: 0.04499787464737892\n",
      "Epoch 42, Loss: 0.03602410480380058\n",
      "Epoch 43, Loss: 0.013980580493807793\n",
      "Epoch 44, Loss: 0.07902220636606216\n",
      "Epoch 45, Loss: 0.029408540576696396\n",
      "Epoch 46, Loss: 0.013287626206874847\n",
      "Epoch 47, Loss: 0.028809040784835815\n",
      "Epoch 48, Loss: 0.022504521533846855\n",
      "Epoch 49, Loss: 0.019849520176649094\n",
      "Epoch 50, Loss: 0.012136399745941162\n",
      "Epoch 51, Loss: 0.04544142633676529\n",
      "Epoch 52, Loss: 0.015396363101899624\n",
      "Epoch 53, Loss: 0.04376951977610588\n",
      "Epoch 54, Loss: 0.03176493942737579\n",
      "Epoch 55, Loss: 0.018245495855808258\n",
      "Epoch 56, Loss: 0.0295097753405571\n",
      "Epoch 57, Loss: 0.00829794630408287\n",
      "Epoch 58, Loss: 0.0301926601678133\n",
      "Epoch 59, Loss: 0.01836172677576542\n",
      "Epoch 60, Loss: 0.006250174716114998\n",
      "Epoch 61, Loss: 0.024570129811763763\n",
      "Epoch 62, Loss: 0.016216911375522614\n",
      "Epoch 63, Loss: 0.007592871785163879\n",
      "Epoch 64, Loss: 0.018067846074700356\n",
      "Epoch 65, Loss: 0.027715368196368217\n",
      "Epoch 66, Loss: 0.027037397027015686\n",
      "Epoch 67, Loss: 0.010651598684489727\n",
      "Epoch 68, Loss: 0.012452816590666771\n",
      "Epoch 69, Loss: 0.011342455632984638\n",
      "Epoch 70, Loss: 0.008016674779355526\n",
      "Epoch 71, Loss: 0.0160442516207695\n",
      "Epoch 72, Loss: 0.00819765217602253\n",
      "Epoch 73, Loss: 0.03218743950128555\n",
      "Epoch 74, Loss: 0.010941668413579464\n",
      "Epoch 75, Loss: 0.020254239439964294\n",
      "Epoch 76, Loss: 0.02640843391418457\n",
      "Epoch 77, Loss: 0.004782490432262421\n",
      "Epoch 78, Loss: 0.02613396942615509\n",
      "Epoch 79, Loss: 0.007806223351508379\n",
      "Epoch 80, Loss: 0.013624566607177258\n",
      "Epoch 81, Loss: 0.013360989280045033\n",
      "Epoch 82, Loss: 0.007131779566407204\n",
      "Epoch 83, Loss: 0.021273352205753326\n",
      "Epoch 84, Loss: 0.0092952661216259\n",
      "Epoch 85, Loss: 0.00886005349457264\n",
      "Epoch 86, Loss: 0.007317385636270046\n",
      "Epoch 87, Loss: 0.016865933313965797\n",
      "Epoch 88, Loss: 0.006258783396333456\n",
      "Epoch 89, Loss: 0.009510704316198826\n",
      "Epoch 90, Loss: 0.010852377861738205\n",
      "Epoch 91, Loss: 0.009006119333207607\n",
      "Epoch 92, Loss: 0.006898770108819008\n",
      "Epoch 93, Loss: 0.01053993683308363\n",
      "Epoch 94, Loss: 0.028664251789450645\n",
      "Epoch 95, Loss: 0.010497961193323135\n",
      "Epoch 96, Loss: 0.0057386732660233974\n",
      "Epoch 97, Loss: 0.010886339470744133\n",
      "Epoch 98, Loss: 0.012665594927966595\n",
      "Epoch 99, Loss: 0.005018176976591349\n",
      "Epoch 100, Loss: 0.0038317011203616858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.2962009906768799\n",
      "Epoch 1, Loss: 0.8621240258216858\n",
      "Epoch 2, Loss: 0.47110286355018616\n",
      "Epoch 3, Loss: 0.5745289921760559\n",
      "Epoch 4, Loss: 1.0428645610809326\n",
      "Epoch 5, Loss: 0.9818545579910278\n",
      "Epoch 6, Loss: 1.3564181327819824\n",
      "Epoch 7, Loss: 1.0254307985305786\n",
      "Epoch 8, Loss: 0.3179404139518738\n",
      "Epoch 9, Loss: 0.5037024617195129\n",
      "Epoch 10, Loss: 0.5343838930130005\n",
      "Epoch 11, Loss: 0.662242591381073\n",
      "Epoch 12, Loss: 0.2034044861793518\n",
      "Epoch 13, Loss: 0.14502663910388947\n",
      "Epoch 14, Loss: 0.1451812982559204\n",
      "Epoch 15, Loss: 0.3825770914554596\n",
      "Epoch 16, Loss: 0.4285832643508911\n",
      "Epoch 17, Loss: 0.14410455524921417\n",
      "Epoch 18, Loss: 0.2857819199562073\n",
      "Epoch 19, Loss: 0.11400556564331055\n",
      "Epoch 20, Loss: 0.23619049787521362\n",
      "Epoch 21, Loss: 0.11351291090250015\n",
      "Epoch 22, Loss: 0.35987389087677\n",
      "Epoch 23, Loss: 0.08314159512519836\n",
      "Epoch 24, Loss: 0.10287560522556305\n",
      "Epoch 25, Loss: 0.21518439054489136\n",
      "Epoch 26, Loss: 0.03628566861152649\n",
      "Epoch 27, Loss: 0.1190929040312767\n",
      "Epoch 28, Loss: 0.1050538718700409\n",
      "Epoch 29, Loss: 0.23501239717006683\n",
      "Epoch 30, Loss: 0.05986995995044708\n",
      "Epoch 31, Loss: 0.2684558033943176\n",
      "Epoch 32, Loss: 0.06554762274026871\n",
      "Epoch 33, Loss: 0.05556750297546387\n",
      "Epoch 34, Loss: 0.06841263175010681\n",
      "Epoch 35, Loss: 0.11648408323526382\n",
      "Epoch 36, Loss: 0.04459240660071373\n",
      "Epoch 37, Loss: 0.010731024667620659\n",
      "Epoch 38, Loss: 0.05120164901018143\n",
      "Epoch 39, Loss: 0.043650299310684204\n",
      "Epoch 40, Loss: 0.02110011875629425\n",
      "Epoch 41, Loss: 0.0635707676410675\n",
      "Epoch 42, Loss: 0.021104829385876656\n",
      "Epoch 43, Loss: 0.025236066430807114\n",
      "Epoch 44, Loss: 0.04207862913608551\n",
      "Epoch 45, Loss: 0.030286364257335663\n",
      "Epoch 46, Loss: 0.08644785732030869\n",
      "Epoch 47, Loss: 0.029547274112701416\n",
      "Epoch 48, Loss: 0.019078748300671577\n",
      "Epoch 49, Loss: 0.022287607192993164\n",
      "Epoch 50, Loss: 0.025749318301677704\n",
      "Epoch 51, Loss: 0.07082944363355637\n",
      "Epoch 52, Loss: 0.023497281596064568\n",
      "Epoch 53, Loss: 0.011891140602529049\n",
      "Epoch 54, Loss: 0.01494393777102232\n",
      "Epoch 55, Loss: 0.010036258958280087\n",
      "Epoch 56, Loss: 0.03282531350851059\n",
      "Epoch 57, Loss: 0.022307060658931732\n",
      "Epoch 58, Loss: 0.02778506651520729\n",
      "Epoch 59, Loss: 0.03721126541495323\n",
      "Epoch 60, Loss: 0.009554375894367695\n",
      "Epoch 61, Loss: 0.020518647506833076\n",
      "Epoch 62, Loss: 0.010011202655732632\n",
      "Epoch 63, Loss: 0.011552764102816582\n",
      "Epoch 64, Loss: 0.036358825862407684\n",
      "Epoch 65, Loss: 0.01072628516703844\n",
      "Epoch 66, Loss: 0.01091260276734829\n",
      "Epoch 67, Loss: 0.027811957523226738\n",
      "Epoch 68, Loss: 0.02176588587462902\n",
      "Epoch 69, Loss: 0.019696079194545746\n",
      "Epoch 70, Loss: 0.01236704271286726\n",
      "Epoch 71, Loss: 0.014991506934165955\n",
      "Epoch 72, Loss: 0.06247416511178017\n",
      "Epoch 73, Loss: 0.012867028824985027\n",
      "Epoch 74, Loss: 0.009023248217999935\n",
      "Epoch 75, Loss: 0.006625916343182325\n",
      "Epoch 76, Loss: 0.018364522606134415\n",
      "Epoch 77, Loss: 0.012503962963819504\n",
      "Epoch 78, Loss: 0.003993072547018528\n",
      "Epoch 79, Loss: 0.007776776794344187\n",
      "Epoch 80, Loss: 0.014610394835472107\n",
      "Epoch 81, Loss: 0.020723504945635796\n",
      "Epoch 82, Loss: 0.024537431076169014\n",
      "Epoch 83, Loss: 0.012986764311790466\n",
      "Epoch 84, Loss: 0.025960244238376617\n",
      "Epoch 85, Loss: 0.015298346988856792\n",
      "Epoch 86, Loss: 0.00863966066390276\n",
      "Epoch 87, Loss: 0.010028238408267498\n",
      "Epoch 88, Loss: 0.009147468954324722\n",
      "Epoch 89, Loss: 0.007971387356519699\n",
      "Epoch 90, Loss: 0.002423304133117199\n",
      "Epoch 91, Loss: 0.01474758516997099\n",
      "Epoch 92, Loss: 0.016639966517686844\n",
      "Epoch 93, Loss: 0.00701175956055522\n",
      "Epoch 94, Loss: 0.009380657225847244\n",
      "Epoch 95, Loss: 0.00863625854253769\n",
      "Epoch 96, Loss: 0.010156980715692043\n",
      "Epoch 97, Loss: 0.008575922809541225\n",
      "Epoch 98, Loss: 0.005446478258818388\n",
      "Epoch 99, Loss: 0.02140008471906185\n",
      "Epoch 100, Loss: 0.005045968573540449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.4477224349975586\n",
      "Epoch 1, Loss: 1.0911188125610352\n",
      "Epoch 2, Loss: 0.6758562922477722\n",
      "Epoch 3, Loss: 0.8901757001876831\n",
      "Epoch 4, Loss: 1.2463487386703491\n",
      "Epoch 5, Loss: 0.6566951274871826\n",
      "Epoch 6, Loss: 0.42348721623420715\n",
      "Epoch 7, Loss: 0.7707585096359253\n",
      "Epoch 8, Loss: 0.3684227168560028\n",
      "Epoch 9, Loss: 0.9068305492401123\n",
      "Epoch 10, Loss: 0.1524527668952942\n",
      "Epoch 11, Loss: 0.29510459303855896\n",
      "Epoch 12, Loss: 0.9522907733917236\n",
      "Epoch 13, Loss: 0.37039342522621155\n",
      "Epoch 14, Loss: 0.41146302223205566\n",
      "Epoch 15, Loss: 0.10697540640830994\n",
      "Epoch 16, Loss: 0.1179794892668724\n",
      "Epoch 17, Loss: 0.19671203196048737\n",
      "Epoch 18, Loss: 0.09972499310970306\n",
      "Epoch 19, Loss: 0.2234230637550354\n",
      "Epoch 20, Loss: 0.1734771728515625\n",
      "Epoch 21, Loss: 0.07587674260139465\n",
      "Epoch 22, Loss: 0.17820946872234344\n",
      "Epoch 23, Loss: 0.13447235524654388\n",
      "Epoch 24, Loss: 0.13731054961681366\n",
      "Epoch 25, Loss: 0.09353004395961761\n",
      "Epoch 26, Loss: 0.10733898729085922\n",
      "Epoch 27, Loss: 0.5000847578048706\n",
      "Epoch 28, Loss: 0.24372798204421997\n",
      "Epoch 29, Loss: 0.1440785974264145\n",
      "Epoch 30, Loss: 0.4084928035736084\n",
      "Epoch 31, Loss: 0.10897022485733032\n",
      "Epoch 32, Loss: 0.03254462778568268\n",
      "Epoch 33, Loss: 0.07519049942493439\n",
      "Epoch 34, Loss: 0.071326844394207\n",
      "Epoch 35, Loss: 0.0855465978384018\n",
      "Epoch 36, Loss: 0.06207064911723137\n",
      "Epoch 37, Loss: 0.032072629779577255\n",
      "Epoch 38, Loss: 0.030056128278374672\n",
      "Epoch 39, Loss: 0.08692008256912231\n",
      "Epoch 40, Loss: 0.049230076372623444\n",
      "Epoch 41, Loss: 0.03853911533951759\n",
      "Epoch 42, Loss: 0.044928766787052155\n",
      "Epoch 43, Loss: 0.01625249721109867\n",
      "Epoch 44, Loss: 0.10323066264390945\n",
      "Epoch 45, Loss: 0.34211859107017517\n",
      "Epoch 46, Loss: 0.03075016476213932\n",
      "Epoch 47, Loss: 0.06479687243700027\n",
      "Epoch 48, Loss: 0.11146584153175354\n",
      "Epoch 49, Loss: 0.00686252536252141\n",
      "Epoch 50, Loss: 0.01378242764621973\n",
      "Epoch 51, Loss: 0.015706144273281097\n",
      "Epoch 52, Loss: 0.06591454893350601\n",
      "Epoch 53, Loss: 0.017486119642853737\n",
      "Epoch 54, Loss: 0.014831315726041794\n",
      "Epoch 55, Loss: 0.03139518201351166\n",
      "Epoch 56, Loss: 0.01519550010561943\n",
      "Epoch 57, Loss: 0.019026508554816246\n",
      "Epoch 58, Loss: 0.0206388458609581\n",
      "Epoch 59, Loss: 0.01924329251050949\n",
      "Epoch 60, Loss: 0.03478424996137619\n",
      "Epoch 61, Loss: 0.013524521142244339\n",
      "Epoch 62, Loss: 0.019720330834388733\n",
      "Epoch 63, Loss: 0.015127905644476414\n",
      "Epoch 64, Loss: 0.2739216089248657\n",
      "Epoch 65, Loss: 0.03067341074347496\n",
      "Epoch 66, Loss: 0.009289626032114029\n",
      "Epoch 67, Loss: 0.05346722528338432\n",
      "Epoch 68, Loss: 0.009030510671436787\n",
      "Epoch 69, Loss: 0.02689596265554428\n",
      "Epoch 70, Loss: 0.012796029448509216\n",
      "Epoch 71, Loss: 0.012208064086735249\n",
      "Epoch 72, Loss: 0.014875216409564018\n",
      "Epoch 73, Loss: 0.0069135334342718124\n",
      "Epoch 74, Loss: 0.011413734406232834\n",
      "Epoch 75, Loss: 0.029052671045064926\n",
      "Epoch 76, Loss: 0.011481281369924545\n",
      "Epoch 77, Loss: 0.01103871688246727\n",
      "Epoch 78, Loss: 0.03761065751314163\n",
      "Epoch 79, Loss: 0.013639125972986221\n",
      "Epoch 80, Loss: 0.016054244711995125\n",
      "Epoch 81, Loss: 0.006100361701101065\n",
      "Epoch 82, Loss: 0.015602578409016132\n",
      "Epoch 83, Loss: 0.02535986714065075\n",
      "Epoch 84, Loss: 0.013462320901453495\n",
      "Epoch 85, Loss: 0.009998798370361328\n",
      "Epoch 86, Loss: 0.01653876155614853\n",
      "Epoch 87, Loss: 0.011116895824670792\n",
      "Epoch 88, Loss: 0.014619331806898117\n",
      "Epoch 89, Loss: 0.005079795140773058\n",
      "Epoch 90, Loss: 0.009373492561280727\n",
      "Epoch 91, Loss: 0.008578373119235039\n",
      "Epoch 92, Loss: 0.03873462229967117\n",
      "Epoch 93, Loss: 0.013125913217663765\n",
      "Epoch 94, Loss: 0.01105149183422327\n",
      "Epoch 95, Loss: 0.0261527132242918\n",
      "Epoch 96, Loss: 0.02443743124604225\n",
      "Epoch 97, Loss: 0.01798660308122635\n",
      "Epoch 98, Loss: 0.008260637521743774\n",
      "Epoch 99, Loss: 0.019071925431489944\n",
      "Epoch 100, Loss: 0.005704442970454693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3551623821258545\n",
      "Epoch 1, Loss: 0.9760032296180725\n",
      "Epoch 2, Loss: 1.3172717094421387\n",
      "Epoch 3, Loss: 0.46242034435272217\n",
      "Epoch 4, Loss: 0.5934114456176758\n",
      "Epoch 5, Loss: 0.37429431080818176\n",
      "Epoch 6, Loss: 0.25822585821151733\n",
      "Epoch 7, Loss: 0.32462286949157715\n",
      "Epoch 8, Loss: 0.8390141129493713\n",
      "Epoch 9, Loss: 0.44081270694732666\n",
      "Epoch 10, Loss: 0.21965424716472626\n",
      "Epoch 11, Loss: 0.12557536363601685\n",
      "Epoch 12, Loss: 0.3180607557296753\n",
      "Epoch 13, Loss: 1.0036935806274414\n",
      "Epoch 14, Loss: 0.3866807818412781\n",
      "Epoch 15, Loss: 0.6334818005561829\n",
      "Epoch 16, Loss: 0.5493709444999695\n",
      "Epoch 17, Loss: 0.26145896315574646\n",
      "Epoch 18, Loss: 0.2125905305147171\n",
      "Epoch 19, Loss: 0.3143855333328247\n",
      "Epoch 20, Loss: 0.2102014571428299\n",
      "Epoch 21, Loss: 0.23466628789901733\n",
      "Epoch 22, Loss: 0.10923656076192856\n",
      "Epoch 23, Loss: 0.27695757150650024\n",
      "Epoch 24, Loss: 0.5810434818267822\n",
      "Epoch 25, Loss: 0.5168959498405457\n",
      "Epoch 26, Loss: 0.14771226048469543\n",
      "Epoch 27, Loss: 0.09133431315422058\n",
      "Epoch 28, Loss: 0.05492981895804405\n",
      "Epoch 29, Loss: 0.11604007333517075\n",
      "Epoch 30, Loss: 0.1400212198495865\n",
      "Epoch 31, Loss: 0.06830959022045135\n",
      "Epoch 32, Loss: 0.15422090888023376\n",
      "Epoch 33, Loss: 0.14533428847789764\n",
      "Epoch 34, Loss: 0.033308424055576324\n",
      "Epoch 35, Loss: 0.14211691915988922\n",
      "Epoch 36, Loss: 0.06485322117805481\n",
      "Epoch 37, Loss: 0.10982512682676315\n",
      "Epoch 38, Loss: 0.04245494306087494\n",
      "Epoch 39, Loss: 0.07205457240343094\n",
      "Epoch 40, Loss: 0.01631123758852482\n",
      "Epoch 41, Loss: 0.08233419805765152\n",
      "Epoch 42, Loss: 0.05297987163066864\n",
      "Epoch 43, Loss: 0.019644444808363914\n",
      "Epoch 44, Loss: 0.029569122940301895\n",
      "Epoch 45, Loss: 0.05894015356898308\n",
      "Epoch 46, Loss: 0.04252931848168373\n",
      "Epoch 47, Loss: 0.08716291189193726\n",
      "Epoch 48, Loss: 0.015934815630316734\n",
      "Epoch 49, Loss: 0.061486467719078064\n",
      "Epoch 50, Loss: 0.04298434406518936\n",
      "Epoch 51, Loss: 0.0484035462141037\n",
      "Epoch 52, Loss: 0.03114919923245907\n",
      "Epoch 53, Loss: 0.03082215040922165\n",
      "Epoch 54, Loss: 0.02782847173511982\n",
      "Epoch 55, Loss: 0.028396189212799072\n",
      "Epoch 56, Loss: 0.012438816018402576\n",
      "Epoch 57, Loss: 0.050509706139564514\n",
      "Epoch 58, Loss: 0.0830196812748909\n",
      "Epoch 59, Loss: 0.005900006275624037\n",
      "Epoch 60, Loss: 0.014653174206614494\n",
      "Epoch 61, Loss: 0.013161399401724339\n",
      "Epoch 62, Loss: 0.021144183352589607\n",
      "Epoch 63, Loss: 0.020305464044213295\n",
      "Epoch 64, Loss: 0.032027099281549454\n",
      "Epoch 65, Loss: 0.018020544201135635\n",
      "Epoch 66, Loss: 0.029147539287805557\n",
      "Epoch 67, Loss: 0.021804343909025192\n",
      "Epoch 68, Loss: 0.03222183138132095\n",
      "Epoch 69, Loss: 0.011111119762063026\n",
      "Epoch 70, Loss: 0.026200152933597565\n",
      "Epoch 71, Loss: 0.013637419790029526\n",
      "Epoch 72, Loss: 0.005875168368220329\n",
      "Epoch 73, Loss: 0.016767997294664383\n",
      "Epoch 74, Loss: 0.04416332766413689\n",
      "Epoch 75, Loss: 0.011002983897924423\n",
      "Epoch 76, Loss: 0.012854610569775105\n",
      "Epoch 77, Loss: 0.031520918011665344\n",
      "Epoch 78, Loss: 0.12556929886341095\n",
      "Epoch 79, Loss: 0.00435444712638855\n",
      "Epoch 80, Loss: 0.04202304780483246\n",
      "Epoch 81, Loss: 0.023366210982203484\n",
      "Epoch 82, Loss: 0.061143118888139725\n",
      "Epoch 83, Loss: 0.014980778098106384\n",
      "Epoch 84, Loss: 0.007493371143937111\n",
      "Epoch 85, Loss: 0.012130217626690865\n",
      "Epoch 86, Loss: 0.004708095919340849\n",
      "Epoch 87, Loss: 0.012975683435797691\n",
      "Epoch 88, Loss: 0.04646545276045799\n",
      "Epoch 89, Loss: 0.009564276784658432\n",
      "Epoch 90, Loss: 0.005258896853774786\n",
      "Epoch 91, Loss: 0.01302819699048996\n",
      "Epoch 92, Loss: 0.011018682271242142\n",
      "Epoch 93, Loss: 0.014058992266654968\n",
      "Epoch 94, Loss: 0.009353994391858578\n",
      "Epoch 95, Loss: 0.005642776843160391\n",
      "Epoch 96, Loss: 0.01206810399889946\n",
      "Epoch 97, Loss: 0.01008906401693821\n",
      "Epoch 98, Loss: 0.009203224442899227\n",
      "Epoch 99, Loss: 0.0250738263130188\n",
      "Epoch 100, Loss: 0.015453144907951355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3927727937698364\n",
      "Epoch 1, Loss: 0.6603851914405823\n",
      "Epoch 2, Loss: 0.30779197812080383\n",
      "Epoch 3, Loss: 0.91450035572052\n",
      "Epoch 4, Loss: 0.3513733148574829\n",
      "Epoch 5, Loss: 0.8948882222175598\n",
      "Epoch 6, Loss: 0.37878498435020447\n",
      "Epoch 7, Loss: 0.560896635055542\n",
      "Epoch 8, Loss: 0.48223480582237244\n",
      "Epoch 9, Loss: 0.5417648553848267\n",
      "Epoch 10, Loss: 0.39600011706352234\n",
      "Epoch 11, Loss: 0.3468555212020874\n",
      "Epoch 12, Loss: 0.28844398260116577\n",
      "Epoch 13, Loss: 0.1767159253358841\n",
      "Epoch 14, Loss: 0.3281250596046448\n",
      "Epoch 15, Loss: 0.19215042889118195\n",
      "Epoch 16, Loss: 0.24329498410224915\n",
      "Epoch 17, Loss: 0.31305038928985596\n",
      "Epoch 18, Loss: 0.16483503580093384\n",
      "Epoch 19, Loss: 0.3014860153198242\n",
      "Epoch 20, Loss: 0.43950796127319336\n",
      "Epoch 21, Loss: 0.21787363290786743\n",
      "Epoch 22, Loss: 0.08375393599271774\n",
      "Epoch 23, Loss: 0.0635400041937828\n",
      "Epoch 24, Loss: 0.11958418786525726\n",
      "Epoch 25, Loss: 0.10700955241918564\n",
      "Epoch 26, Loss: 0.09076106548309326\n",
      "Epoch 27, Loss: 0.09095887839794159\n",
      "Epoch 28, Loss: 0.11232703179121017\n",
      "Epoch 29, Loss: 0.08370474725961685\n",
      "Epoch 30, Loss: 0.07715091854333878\n",
      "Epoch 31, Loss: 0.10926124453544617\n",
      "Epoch 32, Loss: 0.08350303024053574\n",
      "Epoch 33, Loss: 0.12185817211866379\n",
      "Epoch 34, Loss: 0.024984393268823624\n",
      "Epoch 35, Loss: 0.06023460626602173\n",
      "Epoch 36, Loss: 0.08727245032787323\n",
      "Epoch 37, Loss: 0.046470388770103455\n",
      "Epoch 38, Loss: 0.06501268595457077\n",
      "Epoch 39, Loss: 0.05003170669078827\n",
      "Epoch 40, Loss: 0.054252978414297104\n",
      "Epoch 41, Loss: 0.021901935338974\n",
      "Epoch 42, Loss: 0.0557333379983902\n",
      "Epoch 43, Loss: 0.0465460903942585\n",
      "Epoch 44, Loss: 0.06682007014751434\n",
      "Epoch 45, Loss: 0.016527418047189713\n",
      "Epoch 46, Loss: 0.03159703314304352\n",
      "Epoch 47, Loss: 0.041297443211078644\n",
      "Epoch 48, Loss: 0.03234089910984039\n",
      "Epoch 49, Loss: 0.03941871225833893\n",
      "Epoch 50, Loss: 0.03291266784071922\n",
      "Epoch 51, Loss: 0.03046097606420517\n",
      "Epoch 52, Loss: 0.019643468782305717\n",
      "Epoch 53, Loss: 0.028480999171733856\n",
      "Epoch 54, Loss: 0.013413874432444572\n",
      "Epoch 55, Loss: 0.018726790323853493\n",
      "Epoch 56, Loss: 0.02862444519996643\n",
      "Epoch 57, Loss: 0.0345391184091568\n",
      "Epoch 58, Loss: 0.026335684582591057\n",
      "Epoch 59, Loss: 0.02566094510257244\n",
      "Epoch 60, Loss: 0.013194328173995018\n",
      "Epoch 61, Loss: 0.010698686353862286\n",
      "Epoch 62, Loss: 0.013856228440999985\n",
      "Epoch 63, Loss: 0.019514404237270355\n",
      "Epoch 64, Loss: 0.032045431435108185\n",
      "Epoch 65, Loss: 0.043097831308841705\n",
      "Epoch 66, Loss: 0.011592421680688858\n",
      "Epoch 67, Loss: 0.009745094925165176\n",
      "Epoch 68, Loss: 0.01095674280077219\n",
      "Epoch 69, Loss: 0.015758901834487915\n",
      "Epoch 70, Loss: 0.04070940986275673\n",
      "Epoch 71, Loss: 0.02368333749473095\n",
      "Epoch 72, Loss: 0.0289817713201046\n",
      "Epoch 73, Loss: 0.017954330891370773\n",
      "Epoch 74, Loss: 0.11620260775089264\n",
      "Epoch 75, Loss: 0.024124961346387863\n",
      "Epoch 76, Loss: 0.037232160568237305\n",
      "Epoch 77, Loss: 0.007309300824999809\n",
      "Epoch 78, Loss: 0.017463115975260735\n",
      "Epoch 79, Loss: 0.016012804582715034\n",
      "Epoch 80, Loss: 0.01004782970994711\n",
      "Epoch 81, Loss: 0.004950365982949734\n",
      "Epoch 82, Loss: 0.02041398547589779\n",
      "Epoch 83, Loss: 0.005290783941745758\n",
      "Epoch 84, Loss: 0.002965961117297411\n",
      "Epoch 85, Loss: 0.012695725075900555\n",
      "Epoch 86, Loss: 0.014312098734080791\n",
      "Epoch 87, Loss: 0.01021002046763897\n",
      "Epoch 88, Loss: 0.009172850288450718\n",
      "Epoch 89, Loss: 0.017116792500019073\n",
      "Epoch 90, Loss: 0.003344695083796978\n",
      "Epoch 91, Loss: 0.0075155156664550304\n",
      "Epoch 92, Loss: 0.00985633209347725\n",
      "Epoch 93, Loss: 0.009180146269500256\n",
      "Epoch 94, Loss: 0.006817866116762161\n",
      "Epoch 95, Loss: 0.008526548743247986\n",
      "Epoch 96, Loss: 0.009191859513521194\n",
      "Epoch 97, Loss: 0.008585389703512192\n",
      "Epoch 98, Loss: 0.003790518967434764\n",
      "Epoch 99, Loss: 0.011610869318246841\n",
      "Epoch 100, Loss: 0.007154418155550957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3738868236541748\n",
      "Epoch 1, Loss: 0.9001805186271667\n",
      "Epoch 2, Loss: 1.0194077491760254\n",
      "Epoch 3, Loss: 0.36033686995506287\n",
      "Epoch 4, Loss: 0.5927278995513916\n",
      "Epoch 5, Loss: 0.386446088552475\n",
      "Epoch 6, Loss: 0.5943990349769592\n",
      "Epoch 7, Loss: 0.5648210048675537\n",
      "Epoch 8, Loss: 0.18797092139720917\n",
      "Epoch 9, Loss: 0.45957639813423157\n",
      "Epoch 10, Loss: 0.3176520764827728\n",
      "Epoch 11, Loss: 0.5125662088394165\n",
      "Epoch 12, Loss: 0.3634283244609833\n",
      "Epoch 13, Loss: 0.27580833435058594\n",
      "Epoch 14, Loss: 0.33472704887390137\n",
      "Epoch 15, Loss: 0.0916278213262558\n",
      "Epoch 16, Loss: 0.28601497411727905\n",
      "Epoch 17, Loss: 0.24148575961589813\n",
      "Epoch 18, Loss: 0.23925457894802094\n",
      "Epoch 19, Loss: 0.2085104137659073\n",
      "Epoch 20, Loss: 0.1848149597644806\n",
      "Epoch 21, Loss: 0.09689351171255112\n",
      "Epoch 22, Loss: 0.1357404589653015\n",
      "Epoch 23, Loss: 0.13432936370372772\n",
      "Epoch 24, Loss: 0.14302784204483032\n",
      "Epoch 25, Loss: 0.11366602778434753\n",
      "Epoch 26, Loss: 0.13894054293632507\n",
      "Epoch 27, Loss: 0.03944426402449608\n",
      "Epoch 28, Loss: 0.049421072006225586\n",
      "Epoch 29, Loss: 0.19283141195774078\n",
      "Epoch 30, Loss: 0.2667558491230011\n",
      "Epoch 31, Loss: 0.12925985455513\n",
      "Epoch 32, Loss: 0.03731415420770645\n",
      "Epoch 33, Loss: 0.21366173028945923\n",
      "Epoch 34, Loss: 0.03657091036438942\n",
      "Epoch 35, Loss: 0.0519699826836586\n",
      "Epoch 36, Loss: 0.05063651502132416\n",
      "Epoch 37, Loss: 0.0567220114171505\n",
      "Epoch 38, Loss: 0.09459339827299118\n",
      "Epoch 39, Loss: 0.07723782956600189\n",
      "Epoch 40, Loss: 0.03675437346100807\n",
      "Epoch 41, Loss: 0.0403214767575264\n",
      "Epoch 42, Loss: 0.019517740234732628\n",
      "Epoch 43, Loss: 0.015986399725079536\n",
      "Epoch 44, Loss: 0.06600422412157059\n",
      "Epoch 45, Loss: 0.04840594530105591\n",
      "Epoch 46, Loss: 0.040565166622400284\n",
      "Epoch 47, Loss: 0.06571008265018463\n",
      "Epoch 48, Loss: 0.04686662182211876\n",
      "Epoch 49, Loss: 0.04902159050107002\n",
      "Epoch 50, Loss: 0.030987156555056572\n",
      "Epoch 51, Loss: 0.0382964089512825\n",
      "Epoch 52, Loss: 0.031281281262636185\n",
      "Epoch 53, Loss: 0.030099011957645416\n",
      "Epoch 54, Loss: 0.011801786720752716\n",
      "Epoch 55, Loss: 0.030427346006035805\n",
      "Epoch 56, Loss: 0.035692937672138214\n",
      "Epoch 57, Loss: 0.012646791525185108\n",
      "Epoch 58, Loss: 0.017805423587560654\n",
      "Epoch 59, Loss: 0.021690838038921356\n",
      "Epoch 60, Loss: 0.05107107013463974\n",
      "Epoch 61, Loss: 0.019346274435520172\n",
      "Epoch 62, Loss: 0.011829624883830547\n",
      "Epoch 63, Loss: 0.011319218203425407\n",
      "Epoch 64, Loss: 0.018191074952483177\n",
      "Epoch 65, Loss: 0.025850610807538033\n",
      "Epoch 66, Loss: 0.014238675124943256\n",
      "Epoch 67, Loss: 0.016172774136066437\n",
      "Epoch 68, Loss: 0.022115005180239677\n",
      "Epoch 69, Loss: 0.009908181615173817\n",
      "Epoch 70, Loss: 0.018505265936255455\n",
      "Epoch 71, Loss: 0.01065783016383648\n",
      "Epoch 72, Loss: 0.021572481840848923\n",
      "Epoch 73, Loss: 0.0157618448138237\n",
      "Epoch 74, Loss: 0.03415622562170029\n",
      "Epoch 75, Loss: 0.015550371259450912\n",
      "Epoch 76, Loss: 0.009000717662274837\n",
      "Epoch 77, Loss: 0.011595488525927067\n",
      "Epoch 78, Loss: 0.018604926764965057\n",
      "Epoch 79, Loss: 0.01907210797071457\n",
      "Epoch 80, Loss: 0.040455784648656845\n",
      "Epoch 81, Loss: 0.01083588507026434\n",
      "Epoch 82, Loss: 0.004438644740730524\n",
      "Epoch 83, Loss: 0.007202880457043648\n",
      "Epoch 84, Loss: 0.01822836697101593\n",
      "Epoch 85, Loss: 0.0096395593136549\n",
      "Epoch 86, Loss: 0.011700324714183807\n",
      "Epoch 87, Loss: 0.017723841592669487\n",
      "Epoch 88, Loss: 0.010602256283164024\n",
      "Epoch 89, Loss: 0.012822482734918594\n",
      "Epoch 90, Loss: 0.0118324663490057\n",
      "Epoch 91, Loss: 0.02713177725672722\n",
      "Epoch 92, Loss: 0.006943305488675833\n",
      "Epoch 93, Loss: 0.006759343668818474\n",
      "Epoch 94, Loss: 0.00853804126381874\n",
      "Epoch 95, Loss: 0.004908915609121323\n",
      "Epoch 96, Loss: 0.0074192252941429615\n",
      "Epoch 97, Loss: 0.010988256894052029\n",
      "Epoch 98, Loss: 0.009273623116314411\n",
      "Epoch 99, Loss: 0.00883691105991602\n",
      "Epoch 100, Loss: 0.009579405188560486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.2845851182937622\n",
      "Epoch 1, Loss: 0.21220330893993378\n",
      "Epoch 2, Loss: 1.6053838729858398\n",
      "Epoch 3, Loss: 0.8011360764503479\n",
      "Epoch 4, Loss: 0.5756411552429199\n",
      "Epoch 5, Loss: 0.49769333004951477\n",
      "Epoch 6, Loss: 0.2627077102661133\n",
      "Epoch 7, Loss: 0.2700776159763336\n",
      "Epoch 8, Loss: 0.38130390644073486\n",
      "Epoch 9, Loss: 0.4332922101020813\n",
      "Epoch 10, Loss: 0.21896854043006897\n",
      "Epoch 11, Loss: 0.23715740442276\n",
      "Epoch 12, Loss: 0.7301012277603149\n",
      "Epoch 13, Loss: 0.3478248417377472\n",
      "Epoch 14, Loss: 0.20417529344558716\n",
      "Epoch 15, Loss: 0.6920711398124695\n",
      "Epoch 16, Loss: 0.3626466393470764\n",
      "Epoch 17, Loss: 0.19401367008686066\n",
      "Epoch 18, Loss: 0.19513240456581116\n",
      "Epoch 19, Loss: 0.18218961358070374\n",
      "Epoch 20, Loss: 0.6299620866775513\n",
      "Epoch 21, Loss: 0.3524062931537628\n",
      "Epoch 22, Loss: 0.22982880473136902\n",
      "Epoch 23, Loss: 0.2227439284324646\n",
      "Epoch 24, Loss: 0.15422970056533813\n",
      "Epoch 25, Loss: 0.11452531814575195\n",
      "Epoch 26, Loss: 0.25635379552841187\n",
      "Epoch 27, Loss: 0.12770019471645355\n",
      "Epoch 28, Loss: 0.08294196426868439\n",
      "Epoch 29, Loss: 0.12552808225154877\n",
      "Epoch 30, Loss: 0.1688121259212494\n",
      "Epoch 31, Loss: 0.11992088705301285\n",
      "Epoch 32, Loss: 0.07399594783782959\n",
      "Epoch 33, Loss: 0.1247725859284401\n",
      "Epoch 34, Loss: 0.0339844711124897\n",
      "Epoch 35, Loss: 0.02106342650949955\n",
      "Epoch 36, Loss: 0.15678560733795166\n",
      "Epoch 37, Loss: 0.047681618481874466\n",
      "Epoch 38, Loss: 0.0321594700217247\n",
      "Epoch 39, Loss: 0.06721264868974686\n",
      "Epoch 40, Loss: 0.03451178967952728\n",
      "Epoch 41, Loss: 0.04152084141969681\n",
      "Epoch 42, Loss: 0.050213947892189026\n",
      "Epoch 43, Loss: 0.095136858522892\n",
      "Epoch 44, Loss: 0.040494102984666824\n",
      "Epoch 45, Loss: 0.07701922208070755\n",
      "Epoch 46, Loss: 0.07451706379652023\n",
      "Epoch 47, Loss: 0.03623066842556\n",
      "Epoch 48, Loss: 0.02721206471323967\n",
      "Epoch 49, Loss: 0.027987219393253326\n",
      "Epoch 50, Loss: 0.033526867628097534\n",
      "Epoch 51, Loss: 0.026022257283329964\n",
      "Epoch 52, Loss: 0.020996583625674248\n",
      "Epoch 53, Loss: 0.09685620665550232\n",
      "Epoch 54, Loss: 0.017682654783129692\n",
      "Epoch 55, Loss: 0.027107618749141693\n",
      "Epoch 56, Loss: 0.047831494361162186\n",
      "Epoch 57, Loss: 0.04236476495862007\n",
      "Epoch 58, Loss: 0.026470882818102837\n",
      "Epoch 59, Loss: 0.04566540941596031\n",
      "Epoch 60, Loss: 0.013994632288813591\n",
      "Epoch 61, Loss: 0.05075357109308243\n",
      "Epoch 62, Loss: 0.014649374410510063\n",
      "Epoch 63, Loss: 0.02086521126329899\n",
      "Epoch 64, Loss: 0.01183601189404726\n",
      "Epoch 65, Loss: 0.028631160035729408\n",
      "Epoch 66, Loss: 0.0099966861307621\n",
      "Epoch 67, Loss: 0.039541564881801605\n",
      "Epoch 68, Loss: 0.032276660203933716\n",
      "Epoch 69, Loss: 0.02281104400753975\n",
      "Epoch 70, Loss: 0.010151257738471031\n",
      "Epoch 71, Loss: 0.014426497742533684\n",
      "Epoch 72, Loss: 0.029944734647870064\n",
      "Epoch 73, Loss: 0.03289920464158058\n",
      "Epoch 74, Loss: 0.014444609172642231\n",
      "Epoch 75, Loss: 0.016848914325237274\n",
      "Epoch 76, Loss: 0.00348021206445992\n",
      "Epoch 77, Loss: 0.017097188159823418\n",
      "Epoch 78, Loss: 0.006785454694181681\n",
      "Epoch 79, Loss: 0.019656557589769363\n",
      "Epoch 80, Loss: 0.05592114478349686\n",
      "Epoch 81, Loss: 0.019816987216472626\n",
      "Epoch 82, Loss: 0.010999266058206558\n",
      "Epoch 83, Loss: 0.005091201979666948\n",
      "Epoch 84, Loss: 0.02336231805384159\n",
      "Epoch 85, Loss: 0.013012794777750969\n",
      "Epoch 86, Loss: 0.005198074504733086\n",
      "Epoch 87, Loss: 0.010051223449409008\n",
      "Epoch 88, Loss: 0.008345294743776321\n",
      "Epoch 89, Loss: 0.029535412788391113\n",
      "Epoch 90, Loss: 0.02331121452152729\n",
      "Epoch 91, Loss: 0.014217628166079521\n",
      "Epoch 92, Loss: 0.01088611502200365\n",
      "Epoch 93, Loss: 0.008209549821913242\n",
      "Epoch 94, Loss: 0.012491983361542225\n",
      "Epoch 95, Loss: 0.011886240914463997\n",
      "Epoch 96, Loss: 0.012480039149522781\n",
      "Epoch 97, Loss: 0.005501171573996544\n",
      "Epoch 98, Loss: 0.015319296158850193\n",
      "Epoch 99, Loss: 0.00638675456866622\n",
      "Epoch 100, Loss: 0.008803906850516796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.2982960939407349\n",
      "Epoch 1, Loss: 0.4056568443775177\n",
      "Epoch 2, Loss: 0.40342187881469727\n",
      "Epoch 3, Loss: 0.6172515153884888\n",
      "Epoch 4, Loss: 0.5191777944564819\n",
      "Epoch 5, Loss: 0.37951016426086426\n",
      "Epoch 6, Loss: 0.5444340109825134\n",
      "Epoch 7, Loss: 0.32681047916412354\n",
      "Epoch 8, Loss: 0.5805480480194092\n",
      "Epoch 9, Loss: 0.5425302386283875\n",
      "Epoch 10, Loss: 0.2679368257522583\n",
      "Epoch 11, Loss: 0.5982449054718018\n",
      "Epoch 12, Loss: 0.30566805601119995\n",
      "Epoch 13, Loss: 0.22404111921787262\n",
      "Epoch 14, Loss: 0.24109983444213867\n",
      "Epoch 15, Loss: 0.22858339548110962\n",
      "Epoch 16, Loss: 0.14557033777236938\n",
      "Epoch 17, Loss: 0.3816054165363312\n",
      "Epoch 18, Loss: 0.3212934136390686\n",
      "Epoch 19, Loss: 0.1458916813135147\n",
      "Epoch 20, Loss: 0.0911804661154747\n",
      "Epoch 21, Loss: 0.15769101679325104\n",
      "Epoch 22, Loss: 0.19716696441173553\n",
      "Epoch 23, Loss: 0.25826847553253174\n",
      "Epoch 24, Loss: 0.14615462720394135\n",
      "Epoch 25, Loss: 0.24540798366069794\n",
      "Epoch 26, Loss: 0.12960049510002136\n",
      "Epoch 27, Loss: 0.11156157404184341\n",
      "Epoch 28, Loss: 0.10535268485546112\n",
      "Epoch 29, Loss: 0.0250485148280859\n",
      "Epoch 30, Loss: 0.11582326889038086\n",
      "Epoch 31, Loss: 0.09388874471187592\n",
      "Epoch 32, Loss: 0.025798209011554718\n",
      "Epoch 33, Loss: 0.18476705253124237\n",
      "Epoch 34, Loss: 0.08033452183008194\n",
      "Epoch 35, Loss: 0.062111157923936844\n",
      "Epoch 36, Loss: 0.09984445571899414\n",
      "Epoch 37, Loss: 0.031557366251945496\n",
      "Epoch 38, Loss: 0.052640751004219055\n",
      "Epoch 39, Loss: 0.09049110859632492\n",
      "Epoch 40, Loss: 0.05023537576198578\n",
      "Epoch 41, Loss: 0.029224306344985962\n",
      "Epoch 42, Loss: 0.08207281678915024\n",
      "Epoch 43, Loss: 0.0562908910214901\n",
      "Epoch 44, Loss: 0.031447455286979675\n",
      "Epoch 45, Loss: 0.039689913392066956\n",
      "Epoch 46, Loss: 0.01854068785905838\n",
      "Epoch 47, Loss: 0.06896744668483734\n",
      "Epoch 48, Loss: 0.06486419588327408\n",
      "Epoch 49, Loss: 0.020398467779159546\n",
      "Epoch 50, Loss: 0.035967398434877396\n",
      "Epoch 51, Loss: 0.025200283154845238\n",
      "Epoch 52, Loss: 0.013924826867878437\n",
      "Epoch 53, Loss: 0.018611574545502663\n",
      "Epoch 54, Loss: 0.013977057300508022\n",
      "Epoch 55, Loss: 0.04234221577644348\n",
      "Epoch 56, Loss: 0.025355882942676544\n",
      "Epoch 57, Loss: 0.046703096479177475\n",
      "Epoch 58, Loss: 0.058755382895469666\n",
      "Epoch 59, Loss: 0.02204054780304432\n",
      "Epoch 60, Loss: 0.025606129318475723\n",
      "Epoch 61, Loss: 0.020157387480139732\n",
      "Epoch 62, Loss: 0.017984747886657715\n",
      "Epoch 63, Loss: 0.023609131574630737\n",
      "Epoch 64, Loss: 0.022951796650886536\n",
      "Epoch 65, Loss: 0.03089255467057228\n",
      "Epoch 66, Loss: 0.021910730749368668\n",
      "Epoch 67, Loss: 0.03176236152648926\n",
      "Epoch 68, Loss: 0.020905328914523125\n",
      "Epoch 69, Loss: 0.027607180178165436\n",
      "Epoch 70, Loss: 0.05490158498287201\n",
      "Epoch 71, Loss: 0.015449672937393188\n",
      "Epoch 72, Loss: 0.06484340131282806\n",
      "Epoch 73, Loss: 0.025733811780810356\n",
      "Epoch 74, Loss: 0.01315318327397108\n",
      "Epoch 75, Loss: 0.01395731046795845\n",
      "Epoch 76, Loss: 0.026250576600432396\n",
      "Epoch 77, Loss: 0.01635035127401352\n",
      "Epoch 78, Loss: 0.015328935347497463\n",
      "Epoch 79, Loss: 0.011298519559204578\n",
      "Epoch 80, Loss: 0.021317817270755768\n",
      "Epoch 81, Loss: 0.008165160194039345\n",
      "Epoch 82, Loss: 0.004612630233168602\n",
      "Epoch 83, Loss: 0.009674286469817162\n",
      "Epoch 84, Loss: 0.00811313558369875\n",
      "Epoch 85, Loss: 0.026826225221157074\n",
      "Epoch 86, Loss: 0.015837114304304123\n",
      "Epoch 87, Loss: 0.012539764866232872\n",
      "Epoch 88, Loss: 0.008039494045078754\n",
      "Epoch 89, Loss: 0.005740051157772541\n",
      "Epoch 90, Loss: 0.013179030269384384\n",
      "Epoch 91, Loss: 0.026847578585147858\n",
      "Epoch 92, Loss: 0.007969984784722328\n",
      "Epoch 93, Loss: 0.014769072644412518\n",
      "Epoch 94, Loss: 0.07247361540794373\n",
      "Epoch 95, Loss: 0.007495923899114132\n",
      "Epoch 96, Loss: 0.007616785820573568\n",
      "Epoch 97, Loss: 0.0076541113667190075\n",
      "Epoch 98, Loss: 0.013388063758611679\n",
      "Epoch 99, Loss: 0.004072041250765324\n",
      "Epoch 100, Loss: 0.013313439674675465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3609602451324463\n",
      "Epoch 1, Loss: 0.9647225141525269\n",
      "Epoch 2, Loss: 0.8621717095375061\n",
      "Epoch 3, Loss: 0.7564582824707031\n",
      "Epoch 4, Loss: 0.6445816159248352\n",
      "Epoch 5, Loss: 0.6418079137802124\n",
      "Epoch 6, Loss: 0.40144816040992737\n",
      "Epoch 7, Loss: 0.645510733127594\n",
      "Epoch 8, Loss: 0.40660420060157776\n",
      "Epoch 9, Loss: 0.3999682068824768\n",
      "Epoch 10, Loss: 0.5516517162322998\n",
      "Epoch 11, Loss: 0.21618135273456573\n",
      "Epoch 12, Loss: 0.5721728205680847\n",
      "Epoch 13, Loss: 0.1346724033355713\n",
      "Epoch 14, Loss: 0.1927841454744339\n",
      "Epoch 15, Loss: 0.34627974033355713\n",
      "Epoch 16, Loss: 0.3213414251804352\n",
      "Epoch 17, Loss: 0.182573139667511\n",
      "Epoch 18, Loss: 0.3523285388946533\n",
      "Epoch 19, Loss: 0.21799178421497345\n",
      "Epoch 20, Loss: 0.4647010564804077\n",
      "Epoch 21, Loss: 0.3022605776786804\n",
      "Epoch 22, Loss: 0.14053425192832947\n",
      "Epoch 23, Loss: 0.12075027823448181\n",
      "Epoch 24, Loss: 0.21614590287208557\n",
      "Epoch 25, Loss: 0.12076649069786072\n",
      "Epoch 26, Loss: 0.2697853446006775\n",
      "Epoch 27, Loss: 0.1210930198431015\n",
      "Epoch 28, Loss: 0.08399498462677002\n",
      "Epoch 29, Loss: 0.09672827273607254\n",
      "Epoch 30, Loss: 0.04686497151851654\n",
      "Epoch 31, Loss: 0.11507969349622726\n",
      "Epoch 32, Loss: 0.11246231198310852\n",
      "Epoch 33, Loss: 0.035382967442274094\n",
      "Epoch 34, Loss: 0.048987023532390594\n",
      "Epoch 35, Loss: 0.03528354689478874\n",
      "Epoch 36, Loss: 0.10947683453559875\n",
      "Epoch 37, Loss: 0.04436727240681648\n",
      "Epoch 38, Loss: 0.07282465696334839\n",
      "Epoch 39, Loss: 0.04568936675786972\n",
      "Epoch 40, Loss: 0.049791958183050156\n",
      "Epoch 41, Loss: 0.05868580564856529\n",
      "Epoch 42, Loss: 0.07860195636749268\n",
      "Epoch 43, Loss: 0.054246991872787476\n",
      "Epoch 44, Loss: 0.0436505526304245\n",
      "Epoch 45, Loss: 0.04531969875097275\n",
      "Epoch 46, Loss: 0.03023776412010193\n",
      "Epoch 47, Loss: 0.023186393082141876\n",
      "Epoch 48, Loss: 0.06379867345094681\n",
      "Epoch 49, Loss: 0.037378113716840744\n",
      "Epoch 50, Loss: 0.05465180426836014\n",
      "Epoch 51, Loss: 0.01729643903672695\n",
      "Epoch 52, Loss: 0.015146719291806221\n",
      "Epoch 53, Loss: 0.05738941952586174\n",
      "Epoch 54, Loss: 0.029667463153600693\n",
      "Epoch 55, Loss: 0.06437432020902634\n",
      "Epoch 56, Loss: 0.053250208497047424\n",
      "Epoch 57, Loss: 0.02900574542582035\n",
      "Epoch 58, Loss: 0.08351755887269974\n",
      "Epoch 59, Loss: 0.022711334750056267\n",
      "Epoch 60, Loss: 0.019313158467411995\n",
      "Epoch 61, Loss: 0.014789549633860588\n",
      "Epoch 62, Loss: 0.01948036067187786\n",
      "Epoch 63, Loss: 0.008877317421138287\n",
      "Epoch 64, Loss: 0.01262015663087368\n",
      "Epoch 65, Loss: 0.09631583094596863\n",
      "Epoch 66, Loss: 0.015933377668261528\n",
      "Epoch 67, Loss: 0.02849648706614971\n",
      "Epoch 68, Loss: 0.01649566739797592\n",
      "Epoch 69, Loss: 0.022071458399295807\n",
      "Epoch 70, Loss: 0.012573073618113995\n",
      "Epoch 71, Loss: 0.015561982989311218\n",
      "Epoch 72, Loss: 0.03921690210700035\n",
      "Epoch 73, Loss: 0.009704969823360443\n",
      "Epoch 74, Loss: 0.022812506183981895\n",
      "Epoch 75, Loss: 0.013369658030569553\n",
      "Epoch 76, Loss: 0.00857608299702406\n",
      "Epoch 77, Loss: 0.011470028199255466\n",
      "Epoch 78, Loss: 0.021248847246170044\n",
      "Epoch 79, Loss: 0.010045690461993217\n",
      "Epoch 80, Loss: 0.005995572078973055\n",
      "Epoch 81, Loss: 0.019115591421723366\n",
      "Epoch 82, Loss: 0.032272372394800186\n",
      "Epoch 83, Loss: 0.015568852424621582\n",
      "Epoch 84, Loss: 0.011659646406769753\n",
      "Epoch 85, Loss: 0.009381737560033798\n",
      "Epoch 86, Loss: 0.021632958203554153\n",
      "Epoch 87, Loss: 0.012437954545021057\n",
      "Epoch 88, Loss: 0.01975996419787407\n",
      "Epoch 89, Loss: 0.0065041701309382915\n",
      "Epoch 90, Loss: 0.004129323642700911\n",
      "Epoch 91, Loss: 0.01453980803489685\n",
      "Epoch 92, Loss: 0.010314173996448517\n",
      "Epoch 93, Loss: 0.025914153084158897\n",
      "Epoch 94, Loss: 0.008558850735425949\n",
      "Epoch 95, Loss: 0.013713221997022629\n",
      "Epoch 96, Loss: 0.006405575200915337\n",
      "Epoch 97, Loss: 0.012957166880369186\n",
      "Epoch 98, Loss: 0.00929931178689003\n",
      "Epoch 99, Loss: 0.010003437288105488\n",
      "Epoch 100, Loss: 0.051949642598629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.4247846603393555\n",
      "Epoch 1, Loss: 0.9759126305580139\n",
      "Epoch 2, Loss: 1.1932345628738403\n",
      "Epoch 3, Loss: 1.009517788887024\n",
      "Epoch 4, Loss: 0.5402650833129883\n",
      "Epoch 5, Loss: 1.5706207752227783\n",
      "Epoch 6, Loss: 0.44706809520721436\n",
      "Epoch 7, Loss: 0.5591017007827759\n",
      "Epoch 8, Loss: 0.40388593077659607\n",
      "Epoch 9, Loss: 0.31903356313705444\n",
      "Epoch 10, Loss: 0.6099250912666321\n",
      "Epoch 11, Loss: 0.6411319971084595\n",
      "Epoch 12, Loss: 0.3131689727306366\n",
      "Epoch 13, Loss: 0.34232738614082336\n",
      "Epoch 14, Loss: 0.21651586890220642\n",
      "Epoch 15, Loss: 0.5721843838691711\n",
      "Epoch 16, Loss: 0.24459674954414368\n",
      "Epoch 17, Loss: 0.4471573233604431\n",
      "Epoch 18, Loss: 0.17705002427101135\n",
      "Epoch 19, Loss: 0.29191192984580994\n",
      "Epoch 20, Loss: 0.26057618856430054\n",
      "Epoch 21, Loss: 0.1726633757352829\n",
      "Epoch 22, Loss: 0.3195186257362366\n",
      "Epoch 23, Loss: 0.2457815259695053\n",
      "Epoch 24, Loss: 0.24003519117832184\n",
      "Epoch 25, Loss: 0.3168215751647949\n",
      "Epoch 26, Loss: 0.09263046085834503\n",
      "Epoch 27, Loss: 0.07379573583602905\n",
      "Epoch 28, Loss: 0.37376561760902405\n",
      "Epoch 29, Loss: 0.14810045063495636\n",
      "Epoch 30, Loss: 0.1906244456768036\n",
      "Epoch 31, Loss: 0.03620203584432602\n",
      "Epoch 32, Loss: 0.11597258597612381\n",
      "Epoch 33, Loss: 0.09515199065208435\n",
      "Epoch 34, Loss: 0.043768737465143204\n",
      "Epoch 35, Loss: 0.029700756072998047\n",
      "Epoch 36, Loss: 0.028060240671038628\n",
      "Epoch 37, Loss: 0.03409258648753166\n",
      "Epoch 38, Loss: 0.1090889573097229\n",
      "Epoch 39, Loss: 0.05201740562915802\n",
      "Epoch 40, Loss: 0.047754209488630295\n",
      "Epoch 41, Loss: 0.025653168559074402\n",
      "Epoch 42, Loss: 0.06339767575263977\n",
      "Epoch 43, Loss: 0.02381267584860325\n",
      "Epoch 44, Loss: 0.07572072744369507\n",
      "Epoch 45, Loss: 0.08526691049337387\n",
      "Epoch 46, Loss: 0.022954465821385384\n",
      "Epoch 47, Loss: 0.031201690435409546\n",
      "Epoch 48, Loss: 0.06274887919425964\n",
      "Epoch 49, Loss: 0.020259758457541466\n",
      "Epoch 50, Loss: 0.020381934940814972\n",
      "Epoch 51, Loss: 0.011578395962715149\n",
      "Epoch 52, Loss: 0.03617498651146889\n",
      "Epoch 53, Loss: 0.010545022785663605\n",
      "Epoch 54, Loss: 0.012838782742619514\n",
      "Epoch 55, Loss: 0.04254426807165146\n",
      "Epoch 56, Loss: 0.020340610295534134\n",
      "Epoch 57, Loss: 0.02032875083386898\n",
      "Epoch 58, Loss: 0.022373558953404427\n",
      "Epoch 59, Loss: 0.0612737201154232\n",
      "Epoch 60, Loss: 0.03975070267915726\n",
      "Epoch 61, Loss: 0.04180927574634552\n",
      "Epoch 62, Loss: 0.01675761491060257\n",
      "Epoch 63, Loss: 0.017218250781297684\n",
      "Epoch 64, Loss: 0.012231610715389252\n",
      "Epoch 65, Loss: 0.017243364825844765\n",
      "Epoch 66, Loss: 0.008515847846865654\n",
      "Epoch 67, Loss: 0.018902001902461052\n",
      "Epoch 68, Loss: 0.05709856003522873\n",
      "Epoch 69, Loss: 0.018622739240527153\n",
      "Epoch 70, Loss: 0.018651993945240974\n",
      "Epoch 71, Loss: 0.02966618537902832\n",
      "Epoch 72, Loss: 0.021225182339549065\n",
      "Epoch 73, Loss: 0.012475747615098953\n",
      "Epoch 74, Loss: 0.014317680150270462\n",
      "Epoch 75, Loss: 0.016978837549686432\n",
      "Epoch 76, Loss: 0.01646362990140915\n",
      "Epoch 77, Loss: 0.005492947064340115\n",
      "Epoch 78, Loss: 0.006040099076926708\n",
      "Epoch 79, Loss: 0.020845703780651093\n",
      "Epoch 80, Loss: 0.021837012842297554\n",
      "Epoch 81, Loss: 0.014584594406187534\n",
      "Epoch 82, Loss: 0.00854865089058876\n",
      "Epoch 83, Loss: 0.006190026178956032\n",
      "Epoch 84, Loss: 0.006113720592111349\n",
      "Epoch 85, Loss: 0.009854909032583237\n",
      "Epoch 86, Loss: 0.010550632141530514\n",
      "Epoch 87, Loss: 0.010359777137637138\n",
      "Epoch 88, Loss: 0.007100730203092098\n",
      "Epoch 89, Loss: 0.009773078374564648\n",
      "Epoch 90, Loss: 0.02072516456246376\n",
      "Epoch 91, Loss: 0.008747165091335773\n",
      "Epoch 92, Loss: 0.011108798906207085\n",
      "Epoch 93, Loss: 0.005267268978059292\n",
      "Epoch 94, Loss: 0.01886056549847126\n",
      "Epoch 95, Loss: 0.0054690903052687645\n",
      "Epoch 96, Loss: 0.012345582246780396\n",
      "Epoch 97, Loss: 0.07848493754863739\n",
      "Epoch 98, Loss: 0.006207382306456566\n",
      "Epoch 99, Loss: 0.015113117173314095\n",
      "Epoch 100, Loss: 0.009691592305898666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.650410532951355\n",
      "Epoch 1, Loss: 1.1582874059677124\n",
      "Epoch 2, Loss: 0.507021963596344\n",
      "Epoch 3, Loss: 1.0791230201721191\n",
      "Epoch 4, Loss: 0.8266127109527588\n",
      "Epoch 5, Loss: 0.29700106382369995\n",
      "Epoch 6, Loss: 0.3312927782535553\n",
      "Epoch 7, Loss: 0.2702908217906952\n",
      "Epoch 8, Loss: 0.776654839515686\n",
      "Epoch 9, Loss: 0.8203302025794983\n",
      "Epoch 10, Loss: 0.613927960395813\n",
      "Epoch 11, Loss: 0.3496050536632538\n",
      "Epoch 12, Loss: 0.38726282119750977\n",
      "Epoch 13, Loss: 0.4405885338783264\n",
      "Epoch 14, Loss: 0.12832330167293549\n",
      "Epoch 15, Loss: 0.37602341175079346\n",
      "Epoch 16, Loss: 0.49119487404823303\n",
      "Epoch 17, Loss: 0.09281803667545319\n",
      "Epoch 18, Loss: 0.22967436909675598\n",
      "Epoch 19, Loss: 0.17801962792873383\n",
      "Epoch 20, Loss: 0.15548653900623322\n",
      "Epoch 21, Loss: 0.1833248734474182\n",
      "Epoch 22, Loss: 0.21670269966125488\n",
      "Epoch 23, Loss: 0.2902947664260864\n",
      "Epoch 24, Loss: 0.18831610679626465\n",
      "Epoch 25, Loss: 0.2702507972717285\n",
      "Epoch 26, Loss: 0.10459622740745544\n",
      "Epoch 27, Loss: 0.08937808871269226\n",
      "Epoch 28, Loss: 0.2073599398136139\n",
      "Epoch 29, Loss: 0.27876463532447815\n",
      "Epoch 30, Loss: 0.08855205774307251\n",
      "Epoch 31, Loss: 0.09777066111564636\n",
      "Epoch 32, Loss: 0.04745914041996002\n",
      "Epoch 33, Loss: 0.08519864082336426\n",
      "Epoch 34, Loss: 0.10975193232297897\n",
      "Epoch 35, Loss: 0.04628011956810951\n",
      "Epoch 36, Loss: 0.08419038355350494\n",
      "Epoch 37, Loss: 0.1038283184170723\n",
      "Epoch 38, Loss: 0.10275847464799881\n",
      "Epoch 39, Loss: 0.08089856803417206\n",
      "Epoch 40, Loss: 0.05222947895526886\n",
      "Epoch 41, Loss: 0.043464865535497665\n",
      "Epoch 42, Loss: 0.07519902288913727\n",
      "Epoch 43, Loss: 0.08871247619390488\n",
      "Epoch 44, Loss: 0.0767749696969986\n",
      "Epoch 45, Loss: 0.022585250437259674\n",
      "Epoch 46, Loss: 0.026043584570288658\n",
      "Epoch 47, Loss: 0.02306503988802433\n",
      "Epoch 48, Loss: 0.026397280395030975\n",
      "Epoch 49, Loss: 0.02542126178741455\n",
      "Epoch 50, Loss: 0.024852193892002106\n",
      "Epoch 51, Loss: 0.014339406043291092\n",
      "Epoch 52, Loss: 0.06757348775863647\n",
      "Epoch 53, Loss: 0.03858451917767525\n",
      "Epoch 54, Loss: 0.017641428858041763\n",
      "Epoch 55, Loss: 0.029082536697387695\n",
      "Epoch 56, Loss: 0.017473718151450157\n",
      "Epoch 57, Loss: 0.012439236044883728\n",
      "Epoch 58, Loss: 0.028642889112234116\n",
      "Epoch 59, Loss: 0.01741083711385727\n",
      "Epoch 60, Loss: 0.015000104904174805\n",
      "Epoch 61, Loss: 0.029039356857538223\n",
      "Epoch 62, Loss: 0.013766972348093987\n",
      "Epoch 63, Loss: 0.06201578676700592\n",
      "Epoch 64, Loss: 0.0191242303699255\n",
      "Epoch 65, Loss: 0.020924130454659462\n",
      "Epoch 66, Loss: 0.018421754240989685\n",
      "Epoch 67, Loss: 0.019313976168632507\n",
      "Epoch 68, Loss: 0.01607324369251728\n",
      "Epoch 69, Loss: 0.03764664754271507\n",
      "Epoch 70, Loss: 0.017933644354343414\n",
      "Epoch 71, Loss: 0.020402198657393456\n",
      "Epoch 72, Loss: 0.16293707489967346\n",
      "Epoch 73, Loss: 0.018670538440346718\n",
      "Epoch 74, Loss: 0.021974248811602592\n",
      "Epoch 75, Loss: 0.018124248832464218\n",
      "Epoch 76, Loss: 0.0206044539809227\n",
      "Epoch 77, Loss: 0.00578996492549777\n",
      "Epoch 78, Loss: 0.009450593963265419\n",
      "Epoch 79, Loss: 0.01055342610925436\n",
      "Epoch 80, Loss: 0.014975213445723057\n",
      "Epoch 81, Loss: 0.015929872170090675\n",
      "Epoch 82, Loss: 0.013395165093243122\n",
      "Epoch 83, Loss: 0.005597047507762909\n",
      "Epoch 84, Loss: 0.009246179834008217\n",
      "Epoch 85, Loss: 0.00901014357805252\n",
      "Epoch 86, Loss: 0.010433155111968517\n",
      "Epoch 87, Loss: 0.010447312146425247\n",
      "Epoch 88, Loss: 0.014803028665482998\n",
      "Epoch 89, Loss: 0.008545600809156895\n",
      "Epoch 90, Loss: 0.011245287954807281\n",
      "Epoch 91, Loss: 0.006597238127142191\n",
      "Epoch 92, Loss: 0.015055641531944275\n",
      "Epoch 93, Loss: 0.00974416732788086\n",
      "Epoch 94, Loss: 0.0045224581845104694\n",
      "Epoch 95, Loss: 0.007315881550312042\n",
      "Epoch 96, Loss: 0.009083271957933903\n",
      "Epoch 97, Loss: 0.0045973164960742\n",
      "Epoch 98, Loss: 0.024426333606243134\n",
      "Epoch 99, Loss: 0.0036336774937808514\n",
      "Epoch 100, Loss: 0.012757433578372002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.511431336402893\n",
      "Epoch 1, Loss: 0.6278543472290039\n",
      "Epoch 2, Loss: 0.6491374969482422\n",
      "Epoch 3, Loss: 0.44716617465019226\n",
      "Epoch 4, Loss: 0.5051384568214417\n",
      "Epoch 5, Loss: 0.27204203605651855\n",
      "Epoch 6, Loss: 0.24123869836330414\n",
      "Epoch 7, Loss: 0.19234241545200348\n",
      "Epoch 8, Loss: 0.6239469647407532\n",
      "Epoch 9, Loss: 0.2662627100944519\n",
      "Epoch 10, Loss: 0.2810473144054413\n",
      "Epoch 11, Loss: 0.1783420294523239\n",
      "Epoch 12, Loss: 0.1396186798810959\n",
      "Epoch 13, Loss: 0.22840388119220734\n",
      "Epoch 14, Loss: 0.2294577807188034\n",
      "Epoch 15, Loss: 0.25523287057876587\n",
      "Epoch 16, Loss: 0.2518554627895355\n",
      "Epoch 17, Loss: 0.2441071718931198\n",
      "Epoch 18, Loss: 0.22832123935222626\n",
      "Epoch 19, Loss: 0.1264820694923401\n",
      "Epoch 20, Loss: 0.1568758338689804\n",
      "Epoch 21, Loss: 0.12897133827209473\n",
      "Epoch 22, Loss: 0.13162317872047424\n",
      "Epoch 23, Loss: 0.11922901123762131\n",
      "Epoch 24, Loss: 0.1772007942199707\n",
      "Epoch 25, Loss: 0.06701972335577011\n",
      "Epoch 26, Loss: 0.33973002433776855\n",
      "Epoch 27, Loss: 0.2633742690086365\n",
      "Epoch 28, Loss: 0.020572934299707413\n",
      "Epoch 29, Loss: 0.04908015578985214\n",
      "Epoch 30, Loss: 0.17986635863780975\n",
      "Epoch 31, Loss: 0.10907678306102753\n",
      "Epoch 32, Loss: 0.046894729137420654\n",
      "Epoch 33, Loss: 0.03513065725564957\n",
      "Epoch 34, Loss: 0.07109758257865906\n",
      "Epoch 35, Loss: 0.06112273409962654\n",
      "Epoch 36, Loss: 0.08533336967229843\n",
      "Epoch 37, Loss: 0.05903913080692291\n",
      "Epoch 38, Loss: 0.03621215373277664\n",
      "Epoch 39, Loss: 0.028199097141623497\n",
      "Epoch 40, Loss: 0.09798526018857956\n",
      "Epoch 41, Loss: 0.049886394292116165\n",
      "Epoch 42, Loss: 0.047780752182006836\n",
      "Epoch 43, Loss: 0.060507431626319885\n",
      "Epoch 44, Loss: 0.04020041227340698\n",
      "Epoch 45, Loss: 0.04016556218266487\n",
      "Epoch 46, Loss: 0.0466989204287529\n",
      "Epoch 47, Loss: 0.027488280087709427\n",
      "Epoch 48, Loss: 0.02199980616569519\n",
      "Epoch 49, Loss: 0.09440692514181137\n",
      "Epoch 50, Loss: 0.06116161122918129\n",
      "Epoch 51, Loss: 0.04469435662031174\n",
      "Epoch 52, Loss: 0.012027165852487087\n",
      "Epoch 53, Loss: 0.02093997783958912\n",
      "Epoch 54, Loss: 0.005151843652129173\n",
      "Epoch 55, Loss: 0.03840060904622078\n",
      "Epoch 56, Loss: 0.015208969824016094\n",
      "Epoch 57, Loss: 0.024231957271695137\n",
      "Epoch 58, Loss: 0.009520050138235092\n",
      "Epoch 59, Loss: 0.01813836582005024\n",
      "Epoch 60, Loss: 0.009899427182972431\n",
      "Epoch 61, Loss: 0.03652390092611313\n",
      "Epoch 62, Loss: 0.013520934619009495\n",
      "Epoch 63, Loss: 0.009383190423250198\n",
      "Epoch 64, Loss: 0.016655512154102325\n",
      "Epoch 65, Loss: 0.009437989443540573\n",
      "Epoch 66, Loss: 0.017281915992498398\n",
      "Epoch 67, Loss: 0.01867188885807991\n",
      "Epoch 68, Loss: 0.03000984899699688\n",
      "Epoch 69, Loss: 0.01564561203122139\n",
      "Epoch 70, Loss: 0.026022780686616898\n",
      "Epoch 71, Loss: 0.014907204546034336\n",
      "Epoch 72, Loss: 0.04406212642788887\n",
      "Epoch 73, Loss: 0.007583629805594683\n",
      "Epoch 74, Loss: 0.004427257459610701\n",
      "Epoch 75, Loss: 0.020724182948470116\n",
      "Epoch 76, Loss: 0.010553138330578804\n",
      "Epoch 77, Loss: 0.01009434461593628\n",
      "Epoch 78, Loss: 0.004094338044524193\n",
      "Epoch 79, Loss: 0.009597199968993664\n",
      "Epoch 80, Loss: 0.008982514962553978\n",
      "Epoch 81, Loss: 0.009290430694818497\n",
      "Epoch 82, Loss: 0.0324472039937973\n",
      "Epoch 83, Loss: 0.008309395983815193\n",
      "Epoch 84, Loss: 0.004411093890666962\n",
      "Epoch 85, Loss: 0.007263552863150835\n",
      "Epoch 86, Loss: 0.007422034163028002\n",
      "Epoch 87, Loss: 0.007102931383997202\n",
      "Epoch 88, Loss: 0.029740074649453163\n",
      "Epoch 89, Loss: 0.007118883077055216\n",
      "Epoch 90, Loss: 0.025135278701782227\n",
      "Epoch 91, Loss: 0.00587342819198966\n",
      "Epoch 92, Loss: 0.006277916952967644\n",
      "Epoch 93, Loss: 0.04461979120969772\n",
      "Epoch 94, Loss: 0.004230598919093609\n",
      "Epoch 95, Loss: 0.007565186358988285\n",
      "Epoch 96, Loss: 0.008463006466627121\n",
      "Epoch 97, Loss: 0.013909326866269112\n",
      "Epoch 98, Loss: 0.006071856245398521\n",
      "Epoch 99, Loss: 0.013676642440259457\n",
      "Epoch 100, Loss: 0.009443885646760464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.272709608078003\n",
      "Epoch 1, Loss: 0.3066350817680359\n",
      "Epoch 2, Loss: 0.757512092590332\n",
      "Epoch 3, Loss: 0.9845011830329895\n",
      "Epoch 4, Loss: 0.23015165328979492\n",
      "Epoch 5, Loss: 0.3985242247581482\n",
      "Epoch 6, Loss: 0.4094122648239136\n",
      "Epoch 7, Loss: 0.4956124722957611\n",
      "Epoch 8, Loss: 0.40033209323883057\n",
      "Epoch 9, Loss: 0.44241487979888916\n",
      "Epoch 10, Loss: 0.5756523609161377\n",
      "Epoch 11, Loss: 0.304164320230484\n",
      "Epoch 12, Loss: 0.23764541745185852\n",
      "Epoch 13, Loss: 0.5046935081481934\n",
      "Epoch 14, Loss: 0.14728957414627075\n",
      "Epoch 15, Loss: 0.3534597158432007\n",
      "Epoch 16, Loss: 0.2699486017227173\n",
      "Epoch 17, Loss: 0.2484118938446045\n",
      "Epoch 18, Loss: 0.12053307890892029\n",
      "Epoch 19, Loss: 0.126432403922081\n",
      "Epoch 20, Loss: 0.2747160792350769\n",
      "Epoch 21, Loss: 0.3508448004722595\n",
      "Epoch 22, Loss: 0.11942747235298157\n",
      "Epoch 23, Loss: 0.09439244866371155\n",
      "Epoch 24, Loss: 0.11549823731184006\n",
      "Epoch 25, Loss: 0.1814689189195633\n",
      "Epoch 26, Loss: 0.3188127279281616\n",
      "Epoch 27, Loss: 0.052613161504268646\n",
      "Epoch 28, Loss: 0.10717329382896423\n",
      "Epoch 29, Loss: 0.05588619038462639\n",
      "Epoch 30, Loss: 0.10954500734806061\n",
      "Epoch 31, Loss: 0.06120048463344574\n",
      "Epoch 32, Loss: 0.12395286560058594\n",
      "Epoch 33, Loss: 0.08963147550821304\n",
      "Epoch 34, Loss: 0.03229544311761856\n",
      "Epoch 35, Loss: 0.048473093658685684\n",
      "Epoch 36, Loss: 0.07289040088653564\n",
      "Epoch 37, Loss: 0.12134075164794922\n",
      "Epoch 38, Loss: 0.037446945905685425\n",
      "Epoch 39, Loss: 0.11255410313606262\n",
      "Epoch 40, Loss: 0.04704815894365311\n",
      "Epoch 41, Loss: 0.13072341680526733\n",
      "Epoch 42, Loss: 0.021765679121017456\n",
      "Epoch 43, Loss: 0.034637484699487686\n",
      "Epoch 44, Loss: 0.030231915414333344\n",
      "Epoch 45, Loss: 0.017188098281621933\n",
      "Epoch 46, Loss: 0.04660610482096672\n",
      "Epoch 47, Loss: 0.029671281576156616\n",
      "Epoch 48, Loss: 0.05099935829639435\n",
      "Epoch 49, Loss: 0.045620933175086975\n",
      "Epoch 50, Loss: 0.02088697999715805\n",
      "Epoch 51, Loss: 0.025864390656352043\n",
      "Epoch 52, Loss: 0.055386338382959366\n",
      "Epoch 53, Loss: 0.05760572478175163\n",
      "Epoch 54, Loss: 0.015317548997700214\n",
      "Epoch 55, Loss: 0.023873820900917053\n",
      "Epoch 56, Loss: 0.04736074432730675\n",
      "Epoch 57, Loss: 0.01553670596331358\n",
      "Epoch 58, Loss: 0.02427287958562374\n",
      "Epoch 59, Loss: 0.02104753628373146\n",
      "Epoch 60, Loss: 0.01557333767414093\n",
      "Epoch 61, Loss: 0.039040278643369675\n",
      "Epoch 62, Loss: 0.006421369034796953\n",
      "Epoch 63, Loss: 0.009729189798235893\n",
      "Epoch 64, Loss: 0.009322072379291058\n",
      "Epoch 65, Loss: 0.018953563645482063\n",
      "Epoch 66, Loss: 0.023174472153186798\n",
      "Epoch 67, Loss: 0.019859643653035164\n",
      "Epoch 68, Loss: 0.0221794955432415\n",
      "Epoch 69, Loss: 0.0179798174649477\n",
      "Epoch 70, Loss: 0.03565051406621933\n",
      "Epoch 71, Loss: 0.013949856162071228\n",
      "Epoch 72, Loss: 0.03198614716529846\n",
      "Epoch 73, Loss: 0.028490815311670303\n",
      "Epoch 74, Loss: 0.028901351615786552\n",
      "Epoch 75, Loss: 0.007755354046821594\n",
      "Epoch 76, Loss: 0.02405252307653427\n",
      "Epoch 77, Loss: 0.009947564452886581\n",
      "Epoch 78, Loss: 0.019355937838554382\n",
      "Epoch 79, Loss: 0.014557580463588238\n",
      "Epoch 80, Loss: 0.012605750001966953\n",
      "Epoch 81, Loss: 0.008384985849261284\n",
      "Epoch 82, Loss: 0.006059741601347923\n",
      "Epoch 83, Loss: 0.010813284665346146\n",
      "Epoch 84, Loss: 0.008565105497837067\n",
      "Epoch 85, Loss: 0.01611505076289177\n",
      "Epoch 86, Loss: 0.00684926426038146\n",
      "Epoch 87, Loss: 0.013354944996535778\n",
      "Epoch 88, Loss: 0.010325227864086628\n",
      "Epoch 89, Loss: 0.007165391463786364\n",
      "Epoch 90, Loss: 0.012987284921109676\n",
      "Epoch 91, Loss: 0.01166632492095232\n",
      "Epoch 92, Loss: 0.00768423592671752\n",
      "Epoch 93, Loss: 0.008744325488805771\n",
      "Epoch 94, Loss: 0.011001452803611755\n",
      "Epoch 95, Loss: 0.021130995824933052\n",
      "Epoch 96, Loss: 0.010370869189500809\n",
      "Epoch 97, Loss: 0.017343509942293167\n",
      "Epoch 98, Loss: 0.021774467080831528\n",
      "Epoch 99, Loss: 0.011966953985393047\n",
      "Epoch 100, Loss: 0.010668101720511913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3424450159072876\n",
      "Epoch 1, Loss: 1.0127356052398682\n",
      "Epoch 2, Loss: 0.6876681447029114\n",
      "Epoch 3, Loss: 1.2165383100509644\n",
      "Epoch 4, Loss: 1.1095985174179077\n",
      "Epoch 5, Loss: 1.2106598615646362\n",
      "Epoch 6, Loss: 1.2548655271530151\n",
      "Epoch 7, Loss: 0.45445504784584045\n",
      "Epoch 8, Loss: 0.2945508062839508\n",
      "Epoch 9, Loss: 0.48652204871177673\n",
      "Epoch 10, Loss: 0.34713342785835266\n",
      "Epoch 11, Loss: 0.3369470238685608\n",
      "Epoch 12, Loss: 0.1846185028553009\n",
      "Epoch 13, Loss: 0.2869265675544739\n",
      "Epoch 14, Loss: 0.39105966687202454\n",
      "Epoch 15, Loss: 0.22865363955497742\n",
      "Epoch 16, Loss: 0.24944251775741577\n",
      "Epoch 17, Loss: 0.1631619781255722\n",
      "Epoch 18, Loss: 0.18612490594387054\n",
      "Epoch 19, Loss: 0.25657933950424194\n",
      "Epoch 20, Loss: 0.30180197954177856\n",
      "Epoch 21, Loss: 0.38443151116371155\n",
      "Epoch 22, Loss: 0.04535093158483505\n",
      "Epoch 23, Loss: 0.12795253098011017\n",
      "Epoch 24, Loss: 0.15002062916755676\n",
      "Epoch 25, Loss: 0.15498797595500946\n",
      "Epoch 26, Loss: 0.2104511559009552\n",
      "Epoch 27, Loss: 0.3986201584339142\n",
      "Epoch 28, Loss: 0.07546976208686829\n",
      "Epoch 29, Loss: 0.11572257429361343\n",
      "Epoch 30, Loss: 0.05851971358060837\n",
      "Epoch 31, Loss: 0.07427886128425598\n",
      "Epoch 32, Loss: 0.09763374924659729\n",
      "Epoch 33, Loss: 0.18002372980117798\n",
      "Epoch 34, Loss: 0.040789198130369186\n",
      "Epoch 35, Loss: 0.04113006964325905\n",
      "Epoch 36, Loss: 0.13976138830184937\n",
      "Epoch 37, Loss: 0.119451604783535\n",
      "Epoch 38, Loss: 0.04627944901585579\n",
      "Epoch 39, Loss: 0.051619794219732285\n",
      "Epoch 40, Loss: 0.04578801244497299\n",
      "Epoch 41, Loss: 0.08355584740638733\n",
      "Epoch 42, Loss: 0.023682735860347748\n",
      "Epoch 43, Loss: 0.0676330104470253\n",
      "Epoch 44, Loss: 0.04962830990552902\n",
      "Epoch 45, Loss: 0.1351151168346405\n",
      "Epoch 46, Loss: 0.07469319552183151\n",
      "Epoch 47, Loss: 0.01823933981359005\n",
      "Epoch 48, Loss: 0.03862202540040016\n",
      "Epoch 49, Loss: 0.02540341019630432\n",
      "Epoch 50, Loss: 0.03498854115605354\n",
      "Epoch 51, Loss: 0.036660246551036835\n",
      "Epoch 52, Loss: 0.05670956149697304\n",
      "Epoch 53, Loss: 0.039390288293361664\n",
      "Epoch 54, Loss: 0.126181498169899\n",
      "Epoch 55, Loss: 0.06736984848976135\n",
      "Epoch 56, Loss: 0.04906730726361275\n",
      "Epoch 57, Loss: 0.03711073100566864\n",
      "Epoch 58, Loss: 0.027938514947891235\n",
      "Epoch 59, Loss: 0.01996435970067978\n",
      "Epoch 60, Loss: 0.0891609936952591\n",
      "Epoch 61, Loss: 0.02606787346303463\n",
      "Epoch 62, Loss: 0.03017059899866581\n",
      "Epoch 63, Loss: 0.017858488485217094\n",
      "Epoch 64, Loss: 0.13340389728546143\n",
      "Epoch 65, Loss: 0.02818845957517624\n",
      "Epoch 66, Loss: 0.023417672142386436\n",
      "Epoch 67, Loss: 0.01276033092290163\n",
      "Epoch 68, Loss: 0.016217386350035667\n",
      "Epoch 69, Loss: 0.018676763400435448\n",
      "Epoch 70, Loss: 0.01602517068386078\n",
      "Epoch 71, Loss: 0.020105795934796333\n",
      "Epoch 72, Loss: 0.021826105192303658\n",
      "Epoch 73, Loss: 0.010999049060046673\n",
      "Epoch 74, Loss: 0.025734052062034607\n",
      "Epoch 75, Loss: 0.017986439168453217\n",
      "Epoch 76, Loss: 0.04921697825193405\n",
      "Epoch 77, Loss: 0.018304064869880676\n",
      "Epoch 78, Loss: 0.01883959025144577\n",
      "Epoch 79, Loss: 0.030761156231164932\n",
      "Epoch 80, Loss: 0.011396905407309532\n",
      "Epoch 81, Loss: 0.01645677350461483\n",
      "Epoch 82, Loss: 0.01848381571471691\n",
      "Epoch 83, Loss: 0.01857876405119896\n",
      "Epoch 84, Loss: 0.01266411505639553\n",
      "Epoch 85, Loss: 0.017075160518288612\n",
      "Epoch 86, Loss: 0.0600506067276001\n",
      "Epoch 87, Loss: 0.012377511709928513\n",
      "Epoch 88, Loss: 0.018821487203240395\n",
      "Epoch 89, Loss: 0.020014503970742226\n",
      "Epoch 90, Loss: 0.01973532885313034\n",
      "Epoch 91, Loss: 0.14175091683864594\n",
      "Epoch 92, Loss: 0.011736144311726093\n",
      "Epoch 93, Loss: 0.030149132013320923\n",
      "Epoch 94, Loss: 0.01460509654134512\n",
      "Epoch 95, Loss: 0.0036768673453480005\n",
      "Epoch 96, Loss: 0.010673429816961288\n",
      "Epoch 97, Loss: 0.015650548040866852\n",
      "Epoch 98, Loss: 0.0037970116827636957\n",
      "Epoch 99, Loss: 0.011472935788333416\n",
      "Epoch 100, Loss: 0.00979015976190567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.567314863204956\n",
      "Epoch 1, Loss: 0.38900819420814514\n",
      "Epoch 2, Loss: 0.600191056728363\n",
      "Epoch 3, Loss: 0.5265092849731445\n",
      "Epoch 4, Loss: 0.40511956810951233\n",
      "Epoch 5, Loss: 0.5363444685935974\n",
      "Epoch 6, Loss: 0.36625099182128906\n",
      "Epoch 7, Loss: 0.5754693150520325\n",
      "Epoch 8, Loss: 0.5989457368850708\n",
      "Epoch 9, Loss: 0.4998333752155304\n",
      "Epoch 10, Loss: 0.4140392541885376\n",
      "Epoch 11, Loss: 0.3854602575302124\n",
      "Epoch 12, Loss: 0.4426352381706238\n",
      "Epoch 13, Loss: 0.17128540575504303\n",
      "Epoch 14, Loss: 0.30044373869895935\n",
      "Epoch 15, Loss: 0.2783295810222626\n",
      "Epoch 16, Loss: 0.30488401651382446\n",
      "Epoch 17, Loss: 0.1628836989402771\n",
      "Epoch 18, Loss: 0.26683351397514343\n",
      "Epoch 19, Loss: 0.07429042458534241\n",
      "Epoch 20, Loss: 0.3384542763233185\n",
      "Epoch 21, Loss: 0.08585140109062195\n",
      "Epoch 22, Loss: 0.07851006835699081\n",
      "Epoch 23, Loss: 0.14787036180496216\n",
      "Epoch 24, Loss: 0.06779953837394714\n",
      "Epoch 25, Loss: 0.05521119013428688\n",
      "Epoch 26, Loss: 0.21341535449028015\n",
      "Epoch 27, Loss: 0.11765650659799576\n",
      "Epoch 28, Loss: 0.06406889110803604\n",
      "Epoch 29, Loss: 0.1505764126777649\n",
      "Epoch 30, Loss: 0.05145362764596939\n",
      "Epoch 31, Loss: 0.08824382722377777\n",
      "Epoch 32, Loss: 0.05645669996738434\n",
      "Epoch 33, Loss: 0.19597908854484558\n",
      "Epoch 34, Loss: 0.07520408183336258\n",
      "Epoch 35, Loss: 0.04608476907014847\n",
      "Epoch 36, Loss: 0.05763484537601471\n",
      "Epoch 37, Loss: 0.035682354122400284\n",
      "Epoch 38, Loss: 0.03896482288837433\n",
      "Epoch 39, Loss: 0.12468922138214111\n",
      "Epoch 40, Loss: 0.06541746109724045\n",
      "Epoch 41, Loss: 0.01524356473237276\n",
      "Epoch 42, Loss: 0.042634353041648865\n",
      "Epoch 43, Loss: 0.07067926973104477\n",
      "Epoch 44, Loss: 0.06753680109977722\n",
      "Epoch 45, Loss: 0.03519626334309578\n",
      "Epoch 46, Loss: 0.025900952517986298\n",
      "Epoch 47, Loss: 0.0789341852068901\n",
      "Epoch 48, Loss: 0.015156428329646587\n",
      "Epoch 49, Loss: 0.02513093315064907\n",
      "Epoch 50, Loss: 0.03258631378412247\n",
      "Epoch 51, Loss: 0.03785276412963867\n",
      "Epoch 52, Loss: 0.033417388796806335\n",
      "Epoch 53, Loss: 0.01890231855213642\n",
      "Epoch 54, Loss: 0.025696761906147003\n",
      "Epoch 55, Loss: 0.05108315125107765\n",
      "Epoch 56, Loss: 0.020840052515268326\n",
      "Epoch 57, Loss: 0.026424327865242958\n",
      "Epoch 58, Loss: 0.016053203493356705\n",
      "Epoch 59, Loss: 0.03973052278161049\n",
      "Epoch 60, Loss: 0.04730929434299469\n",
      "Epoch 61, Loss: 0.011899761855602264\n",
      "Epoch 62, Loss: 0.03558577597141266\n",
      "Epoch 63, Loss: 0.01159689761698246\n",
      "Epoch 64, Loss: 0.01805366389453411\n",
      "Epoch 65, Loss: 0.018818505108356476\n",
      "Epoch 66, Loss: 0.012112743221223354\n",
      "Epoch 67, Loss: 0.005089758895337582\n",
      "Epoch 68, Loss: 0.006764467805624008\n",
      "Epoch 69, Loss: 0.0053533269092440605\n",
      "Epoch 70, Loss: 0.007366281468421221\n",
      "Epoch 71, Loss: 0.03496260195970535\n",
      "Epoch 72, Loss: 0.020032169297337532\n",
      "Epoch 73, Loss: 0.01125035434961319\n",
      "Epoch 74, Loss: 0.009899163618683815\n",
      "Epoch 75, Loss: 0.019119327887892723\n",
      "Epoch 76, Loss: 0.007435384672135115\n",
      "Epoch 77, Loss: 0.05328644812107086\n",
      "Epoch 78, Loss: 0.02044311910867691\n",
      "Epoch 79, Loss: 0.0095998365432024\n",
      "Epoch 80, Loss: 0.028777943924069405\n",
      "Epoch 81, Loss: 0.012282316572964191\n",
      "Epoch 82, Loss: 0.030435793101787567\n",
      "Epoch 83, Loss: 0.01133174542337656\n",
      "Epoch 84, Loss: 0.02321457304060459\n",
      "Epoch 85, Loss: 0.006961111444979906\n",
      "Epoch 86, Loss: 0.01268885936588049\n",
      "Epoch 87, Loss: 0.009946945123374462\n",
      "Epoch 88, Loss: 0.010493970476090908\n",
      "Epoch 89, Loss: 0.005129913799464703\n",
      "Epoch 90, Loss: 0.009373972192406654\n",
      "Epoch 91, Loss: 0.006982413586229086\n",
      "Epoch 92, Loss: 0.005459769628942013\n",
      "Epoch 93, Loss: 0.011872433125972748\n",
      "Epoch 94, Loss: 0.015453221276402473\n",
      "Epoch 95, Loss: 0.014265530742704868\n",
      "Epoch 96, Loss: 0.008539028465747833\n",
      "Epoch 97, Loss: 0.009853686206042767\n",
      "Epoch 98, Loss: 0.003826164873316884\n",
      "Epoch 99, Loss: 0.010524401441216469\n",
      "Epoch 100, Loss: 0.004227357916533947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3283082246780396\n",
      "Epoch 1, Loss: 0.5591766834259033\n",
      "Epoch 2, Loss: 0.46593257784843445\n",
      "Epoch 3, Loss: 0.6741339564323425\n",
      "Epoch 4, Loss: 0.7686592936515808\n",
      "Epoch 5, Loss: 0.5263702273368835\n",
      "Epoch 6, Loss: 0.1616085171699524\n",
      "Epoch 7, Loss: 0.3380928933620453\n",
      "Epoch 8, Loss: 0.6901552677154541\n",
      "Epoch 9, Loss: 0.55405592918396\n",
      "Epoch 10, Loss: 0.279401570558548\n",
      "Epoch 11, Loss: 0.3069629967212677\n",
      "Epoch 12, Loss: 0.3458981513977051\n",
      "Epoch 13, Loss: 0.16431035101413727\n",
      "Epoch 14, Loss: 0.23844416439533234\n",
      "Epoch 15, Loss: 0.33658719062805176\n",
      "Epoch 16, Loss: 0.4629111886024475\n",
      "Epoch 17, Loss: 0.2358926683664322\n",
      "Epoch 18, Loss: 0.16376475989818573\n",
      "Epoch 19, Loss: 0.27664124965667725\n",
      "Epoch 20, Loss: 0.2729533910751343\n",
      "Epoch 21, Loss: 0.31807464361190796\n",
      "Epoch 22, Loss: 0.05959509313106537\n",
      "Epoch 23, Loss: 0.1923970729112625\n",
      "Epoch 24, Loss: 0.1681624799966812\n",
      "Epoch 25, Loss: 0.16237635910511017\n",
      "Epoch 26, Loss: 0.06945198774337769\n",
      "Epoch 27, Loss: 0.06030132248997688\n",
      "Epoch 28, Loss: 0.05126984789967537\n",
      "Epoch 29, Loss: 0.11029654741287231\n",
      "Epoch 30, Loss: 0.054963912814855576\n",
      "Epoch 31, Loss: 0.12014541029930115\n",
      "Epoch 32, Loss: 0.1284400373697281\n",
      "Epoch 33, Loss: 0.05863411724567413\n",
      "Epoch 34, Loss: 0.04354376345872879\n",
      "Epoch 35, Loss: 0.05760983005166054\n",
      "Epoch 36, Loss: 0.2575579881668091\n",
      "Epoch 37, Loss: 0.17831799387931824\n",
      "Epoch 38, Loss: 0.06097722798585892\n",
      "Epoch 39, Loss: 0.0660286620259285\n",
      "Epoch 40, Loss: 0.04442395269870758\n",
      "Epoch 41, Loss: 0.06430883705615997\n",
      "Epoch 42, Loss: 0.018923070281744003\n",
      "Epoch 43, Loss: 0.04008175805211067\n",
      "Epoch 44, Loss: 0.028330378234386444\n",
      "Epoch 45, Loss: 0.0157097727060318\n",
      "Epoch 46, Loss: 0.028460826724767685\n",
      "Epoch 47, Loss: 0.06781693547964096\n",
      "Epoch 48, Loss: 0.04521729052066803\n",
      "Epoch 49, Loss: 0.025677107274532318\n",
      "Epoch 50, Loss: 0.01183971669524908\n",
      "Epoch 51, Loss: 0.06475482136011124\n",
      "Epoch 52, Loss: 0.015558485873043537\n",
      "Epoch 53, Loss: 0.036959871649742126\n",
      "Epoch 54, Loss: 0.055089421570301056\n",
      "Epoch 55, Loss: 0.022820837795734406\n",
      "Epoch 56, Loss: 0.02586146630346775\n",
      "Epoch 57, Loss: 0.026529157534241676\n",
      "Epoch 58, Loss: 0.012985358946025372\n",
      "Epoch 59, Loss: 0.01805821806192398\n",
      "Epoch 60, Loss: 0.028333064168691635\n",
      "Epoch 61, Loss: 0.029261641204357147\n",
      "Epoch 62, Loss: 0.016500983387231827\n",
      "Epoch 63, Loss: 0.0043462845496833324\n",
      "Epoch 64, Loss: 0.011519760824739933\n",
      "Epoch 65, Loss: 0.017340827733278275\n",
      "Epoch 66, Loss: 0.015494899824261665\n",
      "Epoch 67, Loss: 0.014740217477083206\n",
      "Epoch 68, Loss: 0.017379973083734512\n",
      "Epoch 69, Loss: 0.004766067955642939\n",
      "Epoch 70, Loss: 0.009504214860498905\n",
      "Epoch 71, Loss: 0.029716942459344864\n",
      "Epoch 72, Loss: 0.005674567073583603\n",
      "Epoch 73, Loss: 0.022892028093338013\n",
      "Epoch 74, Loss: 0.0116548091173172\n",
      "Epoch 75, Loss: 0.01401834562420845\n",
      "Epoch 76, Loss: 0.0056242551654577255\n",
      "Epoch 77, Loss: 0.015396391041576862\n",
      "Epoch 78, Loss: 0.014215068891644478\n",
      "Epoch 79, Loss: 0.00921556819230318\n",
      "Epoch 80, Loss: 0.008820141665637493\n",
      "Epoch 81, Loss: 0.02271191217005253\n",
      "Epoch 82, Loss: 0.008526606485247612\n",
      "Epoch 83, Loss: 0.009494633413851261\n",
      "Epoch 84, Loss: 0.02643386460840702\n",
      "Epoch 85, Loss: 0.011758368462324142\n",
      "Epoch 86, Loss: 0.008787543512880802\n",
      "Epoch 87, Loss: 0.009623895399272442\n",
      "Epoch 88, Loss: 0.02248847298324108\n",
      "Epoch 89, Loss: 0.009455235674977303\n",
      "Epoch 90, Loss: 0.016705147922039032\n",
      "Epoch 91, Loss: 0.022746356204152107\n",
      "Epoch 92, Loss: 0.00891193374991417\n",
      "Epoch 93, Loss: 0.012872696854174137\n",
      "Epoch 94, Loss: 0.03572458028793335\n",
      "Epoch 95, Loss: 0.02036895975470543\n",
      "Epoch 96, Loss: 0.010542761534452438\n",
      "Epoch 97, Loss: 0.007768010254949331\n",
      "Epoch 98, Loss: 0.005588768515735865\n",
      "Epoch 99, Loss: 0.013946096412837505\n",
      "Epoch 100, Loss: 0.004000408574938774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.365718960762024\n",
      "Epoch 1, Loss: 0.49078500270843506\n",
      "Epoch 2, Loss: 0.4125986099243164\n",
      "Epoch 3, Loss: 0.37165331840515137\n",
      "Epoch 4, Loss: 0.5998414158821106\n",
      "Epoch 5, Loss: 0.6089259386062622\n",
      "Epoch 6, Loss: 0.4304400384426117\n",
      "Epoch 7, Loss: 0.21412688493728638\n",
      "Epoch 8, Loss: 0.5177811980247498\n",
      "Epoch 9, Loss: 0.4502030909061432\n",
      "Epoch 10, Loss: 0.4262586534023285\n",
      "Epoch 11, Loss: 0.4002687633037567\n",
      "Epoch 12, Loss: 0.43092137575149536\n",
      "Epoch 13, Loss: 0.2531769573688507\n",
      "Epoch 14, Loss: 0.23367132246494293\n",
      "Epoch 15, Loss: 0.3416706323623657\n",
      "Epoch 16, Loss: 0.1650262475013733\n",
      "Epoch 17, Loss: 0.32856690883636475\n",
      "Epoch 18, Loss: 0.23971880972385406\n",
      "Epoch 19, Loss: 0.21158714592456818\n",
      "Epoch 20, Loss: 0.11748378723859787\n",
      "Epoch 21, Loss: 0.20733030140399933\n",
      "Epoch 22, Loss: 0.3843511939048767\n",
      "Epoch 23, Loss: 0.14267808198928833\n",
      "Epoch 24, Loss: 0.07447785884141922\n",
      "Epoch 25, Loss: 0.1504395455121994\n",
      "Epoch 26, Loss: 0.050129037350416183\n",
      "Epoch 27, Loss: 0.11306869983673096\n",
      "Epoch 28, Loss: 0.052406374365091324\n",
      "Epoch 29, Loss: 0.017905747517943382\n",
      "Epoch 30, Loss: 0.18459664285182953\n",
      "Epoch 31, Loss: 0.1161874383687973\n",
      "Epoch 32, Loss: 0.046563319861888885\n",
      "Epoch 33, Loss: 0.10507442057132721\n",
      "Epoch 34, Loss: 0.01726429909467697\n",
      "Epoch 35, Loss: 0.027584055438637733\n",
      "Epoch 36, Loss: 0.08682920783758163\n",
      "Epoch 37, Loss: 0.05558204650878906\n",
      "Epoch 38, Loss: 0.030655493959784508\n",
      "Epoch 39, Loss: 0.055109500885009766\n",
      "Epoch 40, Loss: 0.04570532590150833\n",
      "Epoch 41, Loss: 0.053261417895555496\n",
      "Epoch 42, Loss: 0.06765730679035187\n",
      "Epoch 43, Loss: 0.04828130453824997\n",
      "Epoch 44, Loss: 0.05548717826604843\n",
      "Epoch 45, Loss: 0.012235836125910282\n",
      "Epoch 46, Loss: 0.03737848252058029\n",
      "Epoch 47, Loss: 0.0470765046775341\n",
      "Epoch 48, Loss: 0.07238191366195679\n",
      "Epoch 49, Loss: 0.08784052729606628\n",
      "Epoch 50, Loss: 0.01578337699174881\n",
      "Epoch 51, Loss: 0.01660226844251156\n",
      "Epoch 52, Loss: 0.0391186960041523\n",
      "Epoch 53, Loss: 0.022094639018177986\n",
      "Epoch 54, Loss: 0.020731978118419647\n",
      "Epoch 55, Loss: 0.06576564908027649\n",
      "Epoch 56, Loss: 0.07091116905212402\n",
      "Epoch 57, Loss: 0.031222466379404068\n",
      "Epoch 58, Loss: 0.018965600058436394\n",
      "Epoch 59, Loss: 0.0230067428201437\n",
      "Epoch 60, Loss: 0.013383585028350353\n",
      "Epoch 61, Loss: 0.017748570069670677\n",
      "Epoch 62, Loss: 0.030888225883245468\n",
      "Epoch 63, Loss: 0.0075882491655647755\n",
      "Epoch 64, Loss: 0.030742380768060684\n",
      "Epoch 65, Loss: 0.0171820018440485\n",
      "Epoch 66, Loss: 0.009181573055684566\n",
      "Epoch 67, Loss: 0.024481352418661118\n",
      "Epoch 68, Loss: 0.007184262853115797\n",
      "Epoch 69, Loss: 0.011039374396204948\n",
      "Epoch 70, Loss: 0.00882445927709341\n",
      "Epoch 71, Loss: 0.020209312438964844\n",
      "Epoch 72, Loss: 0.011170157231390476\n",
      "Epoch 73, Loss: 0.04990563914179802\n",
      "Epoch 74, Loss: 0.013396457768976688\n",
      "Epoch 75, Loss: 0.12821775674819946\n",
      "Epoch 76, Loss: 0.009545250795781612\n",
      "Epoch 77, Loss: 0.008405301719903946\n",
      "Epoch 78, Loss: 0.008933261036872864\n",
      "Epoch 79, Loss: 0.005754760932177305\n",
      "Epoch 80, Loss: 0.007897069677710533\n",
      "Epoch 81, Loss: 0.0751337930560112\n",
      "Epoch 82, Loss: 0.011986251920461655\n",
      "Epoch 83, Loss: 0.04484296590089798\n",
      "Epoch 84, Loss: 0.008130169473588467\n",
      "Epoch 85, Loss: 0.03536777198314667\n",
      "Epoch 86, Loss: 0.007997620850801468\n",
      "Epoch 87, Loss: 0.011268645524978638\n",
      "Epoch 88, Loss: 0.0058815376833081245\n",
      "Epoch 89, Loss: 0.005338740535080433\n",
      "Epoch 90, Loss: 0.014083515852689743\n",
      "Epoch 91, Loss: 0.009074953384697437\n",
      "Epoch 92, Loss: 0.01463580783456564\n",
      "Epoch 93, Loss: 0.011305057443678379\n",
      "Epoch 94, Loss: 0.008881080895662308\n",
      "Epoch 95, Loss: 0.008462879806756973\n",
      "Epoch 96, Loss: 0.0016747547779232264\n",
      "Epoch 97, Loss: 0.00479531055316329\n",
      "Epoch 98, Loss: 0.011334026232361794\n",
      "Epoch 99, Loss: 0.006296928972005844\n",
      "Epoch 100, Loss: 0.012787871062755585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.428554892539978\n",
      "Epoch 1, Loss: 0.9338356852531433\n",
      "Epoch 2, Loss: 0.4515221416950226\n",
      "Epoch 3, Loss: 0.7171504497528076\n",
      "Epoch 4, Loss: 0.5395548343658447\n",
      "Epoch 5, Loss: 0.5888580679893494\n",
      "Epoch 6, Loss: 0.29906177520751953\n",
      "Epoch 7, Loss: 0.6099265217781067\n",
      "Epoch 8, Loss: 0.30837228894233704\n",
      "Epoch 9, Loss: 0.8456817269325256\n",
      "Epoch 10, Loss: 0.4551604986190796\n",
      "Epoch 11, Loss: 0.18387043476104736\n",
      "Epoch 12, Loss: 0.2942933142185211\n",
      "Epoch 13, Loss: 0.36469247937202454\n",
      "Epoch 14, Loss: 0.2186906486749649\n",
      "Epoch 15, Loss: 0.15344040095806122\n",
      "Epoch 16, Loss: 0.19087451696395874\n",
      "Epoch 17, Loss: 0.0882415696978569\n",
      "Epoch 18, Loss: 0.3637537360191345\n",
      "Epoch 19, Loss: 0.06771878898143768\n",
      "Epoch 20, Loss: 0.08686631172895432\n",
      "Epoch 21, Loss: 0.1342754364013672\n",
      "Epoch 22, Loss: 0.17049776017665863\n",
      "Epoch 23, Loss: 0.21646234393119812\n",
      "Epoch 24, Loss: 0.1628052145242691\n",
      "Epoch 25, Loss: 0.1493707150220871\n",
      "Epoch 26, Loss: 0.09272783994674683\n",
      "Epoch 27, Loss: 0.16756290197372437\n",
      "Epoch 28, Loss: 0.034970272332429886\n",
      "Epoch 29, Loss: 0.1117909774184227\n",
      "Epoch 30, Loss: 0.09441322088241577\n",
      "Epoch 31, Loss: 0.12122862786054611\n",
      "Epoch 32, Loss: 0.1275692880153656\n",
      "Epoch 33, Loss: 0.05147089064121246\n",
      "Epoch 34, Loss: 0.0415007509291172\n",
      "Epoch 35, Loss: 0.17814211547374725\n",
      "Epoch 36, Loss: 0.06086505949497223\n",
      "Epoch 37, Loss: 0.14080071449279785\n",
      "Epoch 38, Loss: 0.025760840624570847\n",
      "Epoch 39, Loss: 0.019096219912171364\n",
      "Epoch 40, Loss: 0.045279763638973236\n",
      "Epoch 41, Loss: 0.13783396780490875\n",
      "Epoch 42, Loss: 0.016481764614582062\n",
      "Epoch 43, Loss: 0.086170993745327\n",
      "Epoch 44, Loss: 0.04269196093082428\n",
      "Epoch 45, Loss: 0.04998603090643883\n",
      "Epoch 46, Loss: 0.037517622113227844\n",
      "Epoch 47, Loss: 0.09210918843746185\n",
      "Epoch 48, Loss: 0.033653270453214645\n",
      "Epoch 49, Loss: 0.01252149697393179\n",
      "Epoch 50, Loss: 0.012431002222001553\n",
      "Epoch 51, Loss: 0.02981683611869812\n",
      "Epoch 52, Loss: 0.017110731452703476\n",
      "Epoch 53, Loss: 0.041111480444669724\n",
      "Epoch 54, Loss: 0.1270701140165329\n",
      "Epoch 55, Loss: 0.03225424513220787\n",
      "Epoch 56, Loss: 0.028976133093237877\n",
      "Epoch 57, Loss: 0.012961598113179207\n",
      "Epoch 58, Loss: 0.01705240085721016\n",
      "Epoch 59, Loss: 0.017046313732862473\n",
      "Epoch 60, Loss: 0.01590750180184841\n",
      "Epoch 61, Loss: 0.014676266349852085\n",
      "Epoch 62, Loss: 0.017423197627067566\n",
      "Epoch 63, Loss: 0.013492130674421787\n",
      "Epoch 64, Loss: 0.019339701160788536\n",
      "Epoch 65, Loss: 0.0270504392683506\n",
      "Epoch 66, Loss: 0.03798392042517662\n",
      "Epoch 67, Loss: 0.02068248949944973\n",
      "Epoch 68, Loss: 0.01901312917470932\n",
      "Epoch 69, Loss: 0.017454197630286217\n",
      "Epoch 70, Loss: 0.026957031339406967\n",
      "Epoch 71, Loss: 0.01813637465238571\n",
      "Epoch 72, Loss: 0.012739942409098148\n",
      "Epoch 73, Loss: 0.006611641030758619\n",
      "Epoch 74, Loss: 0.014977087266743183\n",
      "Epoch 75, Loss: 0.01608898863196373\n",
      "Epoch 76, Loss: 0.02463199570775032\n",
      "Epoch 77, Loss: 0.01391333807259798\n",
      "Epoch 78, Loss: 0.005299262702465057\n",
      "Epoch 79, Loss: 0.024430647492408752\n",
      "Epoch 80, Loss: 0.02129555307328701\n",
      "Epoch 81, Loss: 0.019578546285629272\n",
      "Epoch 82, Loss: 0.005611008033156395\n",
      "Epoch 83, Loss: 0.015344775281846523\n",
      "Epoch 84, Loss: 0.011822108179330826\n",
      "Epoch 85, Loss: 0.024532075971364975\n",
      "Epoch 86, Loss: 0.01232965663075447\n",
      "Epoch 87, Loss: 0.009058061987161636\n",
      "Epoch 88, Loss: 0.0071772243827581406\n",
      "Epoch 89, Loss: 0.014834512956440449\n",
      "Epoch 90, Loss: 0.014522294513881207\n",
      "Epoch 91, Loss: 0.006984306499361992\n",
      "Epoch 92, Loss: 0.005011364351958036\n",
      "Epoch 93, Loss: 0.007086475845426321\n",
      "Epoch 94, Loss: 0.014480150304734707\n",
      "Epoch 95, Loss: 0.010414383374154568\n",
      "Epoch 96, Loss: 0.0046560619957745075\n",
      "Epoch 97, Loss: 0.016201743856072426\n",
      "Epoch 98, Loss: 0.013954102993011475\n",
      "Epoch 99, Loss: 0.00869610346853733\n",
      "Epoch 100, Loss: 0.0045113107189536095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.312515377998352\n",
      "Epoch 1, Loss: 0.760807991027832\n",
      "Epoch 2, Loss: 1.194441795349121\n",
      "Epoch 3, Loss: 0.8135471343994141\n",
      "Epoch 4, Loss: 0.4598195254802704\n",
      "Epoch 5, Loss: 0.47210291028022766\n",
      "Epoch 6, Loss: 0.6235135197639465\n",
      "Epoch 7, Loss: 0.47160038352012634\n",
      "Epoch 8, Loss: 0.48496294021606445\n",
      "Epoch 9, Loss: 0.44695186614990234\n",
      "Epoch 10, Loss: 0.4753502309322357\n",
      "Epoch 11, Loss: 0.34002384543418884\n",
      "Epoch 12, Loss: 0.20929087698459625\n",
      "Epoch 13, Loss: 0.15263508260250092\n",
      "Epoch 14, Loss: 0.2764667570590973\n",
      "Epoch 15, Loss: 0.5365231037139893\n",
      "Epoch 16, Loss: 0.2269791215658188\n",
      "Epoch 17, Loss: 0.2815476655960083\n",
      "Epoch 18, Loss: 0.13348454236984253\n",
      "Epoch 19, Loss: 0.45020854473114014\n",
      "Epoch 20, Loss: 0.37167683243751526\n",
      "Epoch 21, Loss: 0.19721946120262146\n",
      "Epoch 22, Loss: 0.13747656345367432\n",
      "Epoch 23, Loss: 0.17821061611175537\n",
      "Epoch 24, Loss: 0.12348318099975586\n",
      "Epoch 25, Loss: 0.19179338216781616\n",
      "Epoch 26, Loss: 0.16727663576602936\n",
      "Epoch 27, Loss: 0.1465611755847931\n",
      "Epoch 28, Loss: 0.11833006888628006\n",
      "Epoch 29, Loss: 0.08782317489385605\n",
      "Epoch 30, Loss: 0.10693913698196411\n",
      "Epoch 31, Loss: 0.06703311949968338\n",
      "Epoch 32, Loss: 0.09855541586875916\n",
      "Epoch 33, Loss: 0.10541550070047379\n",
      "Epoch 34, Loss: 0.10858985781669617\n",
      "Epoch 35, Loss: 0.0670294389128685\n",
      "Epoch 36, Loss: 0.0748625323176384\n",
      "Epoch 37, Loss: 0.04752039164304733\n",
      "Epoch 38, Loss: 0.05370811000466347\n",
      "Epoch 39, Loss: 0.04465396702289581\n",
      "Epoch 40, Loss: 0.0276210755109787\n",
      "Epoch 41, Loss: 0.17782694101333618\n",
      "Epoch 42, Loss: 0.07033688575029373\n",
      "Epoch 43, Loss: 0.1177041158080101\n",
      "Epoch 44, Loss: 0.01639561913907528\n",
      "Epoch 45, Loss: 0.09963083267211914\n",
      "Epoch 46, Loss: 0.021247392520308495\n",
      "Epoch 47, Loss: 0.02831154130399227\n",
      "Epoch 48, Loss: 0.021324777975678444\n",
      "Epoch 49, Loss: 0.04164324700832367\n",
      "Epoch 50, Loss: 0.048696331679821014\n",
      "Epoch 51, Loss: 0.04045678675174713\n",
      "Epoch 52, Loss: 0.04514134302735329\n",
      "Epoch 53, Loss: 0.039461567997932434\n",
      "Epoch 54, Loss: 0.018984688445925713\n",
      "Epoch 55, Loss: 0.03993275761604309\n",
      "Epoch 56, Loss: 0.01824062317609787\n",
      "Epoch 57, Loss: 0.08542034029960632\n",
      "Epoch 58, Loss: 0.022499052807688713\n",
      "Epoch 59, Loss: 0.007378368638455868\n",
      "Epoch 60, Loss: 0.053979359567165375\n",
      "Epoch 61, Loss: 0.013585476204752922\n",
      "Epoch 62, Loss: 0.024658067151904106\n",
      "Epoch 63, Loss: 0.03564663603901863\n",
      "Epoch 64, Loss: 0.023031966760754585\n",
      "Epoch 65, Loss: 0.017652885988354683\n",
      "Epoch 66, Loss: 0.012924935668706894\n",
      "Epoch 67, Loss: 0.01721883751451969\n",
      "Epoch 68, Loss: 0.014004571363329887\n",
      "Epoch 69, Loss: 0.02661280333995819\n",
      "Epoch 70, Loss: 0.00931466929614544\n",
      "Epoch 71, Loss: 0.016709044575691223\n",
      "Epoch 72, Loss: 0.008793933317065239\n",
      "Epoch 73, Loss: 0.008942210115492344\n",
      "Epoch 74, Loss: 0.010823841206729412\n",
      "Epoch 75, Loss: 0.010614803992211819\n",
      "Epoch 76, Loss: 0.017075784504413605\n",
      "Epoch 77, Loss: 0.024860046803951263\n",
      "Epoch 78, Loss: 0.012023178860545158\n",
      "Epoch 79, Loss: 0.017678972333669662\n",
      "Epoch 80, Loss: 0.01694525219500065\n",
      "Epoch 81, Loss: 0.015967879444360733\n",
      "Epoch 82, Loss: 0.007877570576965809\n",
      "Epoch 83, Loss: 0.0035381177440285683\n",
      "Epoch 84, Loss: 0.013366691768169403\n",
      "Epoch 85, Loss: 0.004728709347546101\n",
      "Epoch 86, Loss: 0.004635469056665897\n",
      "Epoch 87, Loss: 0.011272345669567585\n",
      "Epoch 88, Loss: 0.012641018256545067\n",
      "Epoch 89, Loss: 0.010170739144086838\n",
      "Epoch 90, Loss: 0.008162196725606918\n",
      "Epoch 91, Loss: 0.0076402234844863415\n",
      "Epoch 92, Loss: 0.017059968784451485\n",
      "Epoch 93, Loss: 0.009288301691412926\n",
      "Epoch 94, Loss: 0.020295439288020134\n",
      "Epoch 95, Loss: 0.012977883219718933\n",
      "Epoch 96, Loss: 0.005823233164846897\n",
      "Epoch 97, Loss: 0.030691782012581825\n",
      "Epoch 98, Loss: 0.009264536201953888\n",
      "Epoch 99, Loss: 0.007736177183687687\n",
      "Epoch 100, Loss: 0.016841692849993706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.6424181461334229\n",
      "Epoch 1, Loss: 0.3344827890396118\n",
      "Epoch 2, Loss: 0.19593188166618347\n",
      "Epoch 3, Loss: 0.9854271411895752\n",
      "Epoch 4, Loss: 0.5696346759796143\n",
      "Epoch 5, Loss: 0.3806725740432739\n",
      "Epoch 6, Loss: 0.5546813607215881\n",
      "Epoch 7, Loss: 0.26197636127471924\n",
      "Epoch 8, Loss: 0.4982110261917114\n",
      "Epoch 9, Loss: 0.5311824083328247\n",
      "Epoch 10, Loss: 0.22365501523017883\n",
      "Epoch 11, Loss: 0.4182278513908386\n",
      "Epoch 12, Loss: 0.16079770028591156\n",
      "Epoch 13, Loss: 0.4034304618835449\n",
      "Epoch 14, Loss: 0.12565316259860992\n",
      "Epoch 15, Loss: 0.6133986115455627\n",
      "Epoch 16, Loss: 0.20738084614276886\n",
      "Epoch 17, Loss: 0.14012105762958527\n",
      "Epoch 18, Loss: 0.2398427277803421\n",
      "Epoch 19, Loss: 0.1813061386346817\n",
      "Epoch 20, Loss: 0.09649398922920227\n",
      "Epoch 21, Loss: 0.3162565529346466\n",
      "Epoch 22, Loss: 0.2354331612586975\n",
      "Epoch 23, Loss: 0.12918157875537872\n",
      "Epoch 24, Loss: 0.13616876304149628\n",
      "Epoch 25, Loss: 0.19275401532649994\n",
      "Epoch 26, Loss: 0.16649192571640015\n",
      "Epoch 27, Loss: 0.07191020250320435\n",
      "Epoch 28, Loss: 0.10123708844184875\n",
      "Epoch 29, Loss: 0.07369919866323471\n",
      "Epoch 30, Loss: 0.10985372960567474\n",
      "Epoch 31, Loss: 0.13343268632888794\n",
      "Epoch 32, Loss: 0.09369168430566788\n",
      "Epoch 33, Loss: 0.06490226835012436\n",
      "Epoch 34, Loss: 0.11331646889448166\n",
      "Epoch 35, Loss: 0.08030368387699127\n",
      "Epoch 36, Loss: 0.07329847663640976\n",
      "Epoch 37, Loss: 0.03505339100956917\n",
      "Epoch 38, Loss: 0.06465241312980652\n",
      "Epoch 39, Loss: 0.04253150895237923\n",
      "Epoch 40, Loss: 0.04148648679256439\n",
      "Epoch 41, Loss: 0.029281655326485634\n",
      "Epoch 42, Loss: 0.029431521892547607\n",
      "Epoch 43, Loss: 0.033389341086149216\n",
      "Epoch 44, Loss: 0.05645088478922844\n",
      "Epoch 45, Loss: 0.03681156039237976\n",
      "Epoch 46, Loss: 0.06087122857570648\n",
      "Epoch 47, Loss: 0.05826291814446449\n",
      "Epoch 48, Loss: 0.0683244913816452\n",
      "Epoch 49, Loss: 0.030480453744530678\n",
      "Epoch 50, Loss: 0.0192427858710289\n",
      "Epoch 51, Loss: 0.05453608185052872\n",
      "Epoch 52, Loss: 0.03484829142689705\n",
      "Epoch 53, Loss: 0.020791975781321526\n",
      "Epoch 54, Loss: 0.024273190647363663\n",
      "Epoch 55, Loss: 0.04273158311843872\n",
      "Epoch 56, Loss: 0.043675169348716736\n",
      "Epoch 57, Loss: 0.011826482601463795\n",
      "Epoch 58, Loss: 0.026978952810168266\n",
      "Epoch 59, Loss: 0.020049216225743294\n",
      "Epoch 60, Loss: 0.05666191130876541\n",
      "Epoch 61, Loss: 0.02739645354449749\n",
      "Epoch 62, Loss: 0.018763206899166107\n",
      "Epoch 63, Loss: 0.05907811224460602\n",
      "Epoch 64, Loss: 0.029511528089642525\n",
      "Epoch 65, Loss: 0.01804945431649685\n",
      "Epoch 66, Loss: 0.09300211817026138\n",
      "Epoch 67, Loss: 0.01102080475538969\n",
      "Epoch 68, Loss: 0.008938141167163849\n",
      "Epoch 69, Loss: 0.04004953056573868\n",
      "Epoch 70, Loss: 0.009123308584094048\n",
      "Epoch 71, Loss: 0.0056450460106134415\n",
      "Epoch 72, Loss: 0.019828855991363525\n",
      "Epoch 73, Loss: 0.004700550809502602\n",
      "Epoch 74, Loss: 0.011706329882144928\n",
      "Epoch 75, Loss: 0.013831446878612041\n",
      "Epoch 76, Loss: 0.012125843204557896\n",
      "Epoch 77, Loss: 0.008886793628334999\n",
      "Epoch 78, Loss: 0.040214356034994125\n",
      "Epoch 79, Loss: 0.014071081764996052\n",
      "Epoch 80, Loss: 0.010263748466968536\n",
      "Epoch 81, Loss: 0.0030085365287959576\n",
      "Epoch 82, Loss: 0.011599882505834103\n",
      "Epoch 83, Loss: 0.017437759786844254\n",
      "Epoch 84, Loss: 0.002841224893927574\n",
      "Epoch 85, Loss: 0.008382602594792843\n",
      "Epoch 86, Loss: 0.024405281990766525\n",
      "Epoch 87, Loss: 0.015075502917170525\n",
      "Epoch 88, Loss: 0.020104825496673584\n",
      "Epoch 89, Loss: 0.008666838519275188\n",
      "Epoch 90, Loss: 0.0037413861136883497\n",
      "Epoch 91, Loss: 0.008014525286853313\n",
      "Epoch 92, Loss: 0.004835089202970266\n",
      "Epoch 93, Loss: 0.00965664442628622\n",
      "Epoch 94, Loss: 0.009615065529942513\n",
      "Epoch 95, Loss: 0.011529587209224701\n",
      "Epoch 96, Loss: 0.008610155433416367\n",
      "Epoch 97, Loss: 0.008107052184641361\n",
      "Epoch 98, Loss: 0.0075323497876524925\n",
      "Epoch 99, Loss: 0.0044017662294209\n",
      "Epoch 100, Loss: 0.01477325800806284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.4108805656433105\n",
      "Epoch 1, Loss: 0.42747655510902405\n",
      "Epoch 2, Loss: 0.46132707595825195\n",
      "Epoch 3, Loss: 0.788520872592926\n",
      "Epoch 4, Loss: 0.5164198875427246\n",
      "Epoch 5, Loss: 0.7257096767425537\n",
      "Epoch 6, Loss: 0.38129723072052\n",
      "Epoch 7, Loss: 0.2699388265609741\n",
      "Epoch 8, Loss: 0.4579659700393677\n",
      "Epoch 9, Loss: 0.17802482843399048\n",
      "Epoch 10, Loss: 0.26508796215057373\n",
      "Epoch 11, Loss: 0.3644465506076813\n",
      "Epoch 12, Loss: 0.46164417266845703\n",
      "Epoch 13, Loss: 0.5387558341026306\n",
      "Epoch 14, Loss: 0.26849931478500366\n",
      "Epoch 15, Loss: 0.2570027709007263\n",
      "Epoch 16, Loss: 0.22632411122322083\n",
      "Epoch 17, Loss: 0.30286145210266113\n",
      "Epoch 18, Loss: 0.21401789784431458\n",
      "Epoch 19, Loss: 0.17255955934524536\n",
      "Epoch 20, Loss: 0.22114640474319458\n",
      "Epoch 21, Loss: 0.11008566617965698\n",
      "Epoch 22, Loss: 0.24114759266376495\n",
      "Epoch 23, Loss: 0.08798948675394058\n",
      "Epoch 24, Loss: 0.10442183166742325\n",
      "Epoch 25, Loss: 0.11791413277387619\n",
      "Epoch 26, Loss: 0.09170065820217133\n",
      "Epoch 27, Loss: 0.11274564266204834\n",
      "Epoch 28, Loss: 0.09623509645462036\n",
      "Epoch 29, Loss: 0.11634501069784164\n",
      "Epoch 30, Loss: 0.05532323941588402\n",
      "Epoch 31, Loss: 0.07639377564191818\n",
      "Epoch 32, Loss: 0.10360363125801086\n",
      "Epoch 33, Loss: 0.07368919253349304\n",
      "Epoch 34, Loss: 0.1376599818468094\n",
      "Epoch 35, Loss: 0.0447658896446228\n",
      "Epoch 36, Loss: 0.02556195855140686\n",
      "Epoch 37, Loss: 0.07518851011991501\n",
      "Epoch 38, Loss: 0.028002938255667686\n",
      "Epoch 39, Loss: 0.06529072672128677\n",
      "Epoch 40, Loss: 0.01575975865125656\n",
      "Epoch 41, Loss: 0.03174113854765892\n",
      "Epoch 42, Loss: 0.14415022730827332\n",
      "Epoch 43, Loss: 0.10774437338113785\n",
      "Epoch 44, Loss: 0.058685414493083954\n",
      "Epoch 45, Loss: 0.04966595396399498\n",
      "Epoch 46, Loss: 0.04034541919827461\n",
      "Epoch 47, Loss: 0.009956981986761093\n",
      "Epoch 48, Loss: 0.07506463676691055\n",
      "Epoch 49, Loss: 0.04320371896028519\n",
      "Epoch 50, Loss: 0.02054925635457039\n",
      "Epoch 51, Loss: 0.024724313989281654\n",
      "Epoch 52, Loss: 0.03879573941230774\n",
      "Epoch 53, Loss: 0.024481631815433502\n",
      "Epoch 54, Loss: 0.05078946053981781\n",
      "Epoch 55, Loss: 0.07664564251899719\n",
      "Epoch 56, Loss: 0.04324973747134209\n",
      "Epoch 57, Loss: 0.020936736837029457\n",
      "Epoch 58, Loss: 0.012632904574275017\n",
      "Epoch 59, Loss: 0.021414637565612793\n",
      "Epoch 60, Loss: 0.021237056702375412\n",
      "Epoch 61, Loss: 0.013179558329284191\n",
      "Epoch 62, Loss: 0.02139672450721264\n",
      "Epoch 63, Loss: 0.018185794353485107\n",
      "Epoch 64, Loss: 0.006939275655895472\n",
      "Epoch 65, Loss: 0.009008592925965786\n",
      "Epoch 66, Loss: 0.02499806508421898\n",
      "Epoch 67, Loss: 0.029539793729782104\n",
      "Epoch 68, Loss: 0.012443742714822292\n",
      "Epoch 69, Loss: 0.010477784089744091\n",
      "Epoch 70, Loss: 0.012752276845276356\n",
      "Epoch 71, Loss: 0.005503165069967508\n",
      "Epoch 72, Loss: 0.012359542772173882\n",
      "Epoch 73, Loss: 0.0038022196386009455\n",
      "Epoch 74, Loss: 0.00549298757687211\n",
      "Epoch 75, Loss: 0.02394673600792885\n",
      "Epoch 76, Loss: 0.009861206635832787\n",
      "Epoch 77, Loss: 0.0054864585399627686\n",
      "Epoch 78, Loss: 0.007151444908231497\n",
      "Epoch 79, Loss: 0.006545820273458958\n",
      "Epoch 80, Loss: 0.00971312914043665\n",
      "Epoch 81, Loss: 0.008566207252442837\n",
      "Epoch 82, Loss: 0.008825622498989105\n",
      "Epoch 83, Loss: 0.00985743384808302\n",
      "Epoch 84, Loss: 0.014196355827152729\n",
      "Epoch 85, Loss: 0.00576112512499094\n",
      "Epoch 86, Loss: 0.00631357217207551\n",
      "Epoch 87, Loss: 0.010219112038612366\n",
      "Epoch 88, Loss: 0.009608178399503231\n",
      "Epoch 89, Loss: 0.007107733748853207\n",
      "Epoch 90, Loss: 0.007801349740475416\n",
      "Epoch 91, Loss: 0.01846024952828884\n",
      "Epoch 92, Loss: 0.015975721180438995\n",
      "Epoch 93, Loss: 0.008108417503535748\n",
      "Epoch 94, Loss: 0.020305210724473\n",
      "Epoch 95, Loss: 0.0070363599807024\n",
      "Epoch 96, Loss: 0.012678359635174274\n",
      "Epoch 97, Loss: 0.007071528118103743\n",
      "Epoch 98, Loss: 0.006072615273296833\n",
      "Epoch 99, Loss: 0.010599423199892044\n",
      "Epoch 100, Loss: 0.008277466520667076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3332568407058716\n",
      "Epoch 1, Loss: 0.9320275187492371\n",
      "Epoch 2, Loss: 0.6345076560974121\n",
      "Epoch 3, Loss: 0.378129243850708\n",
      "Epoch 4, Loss: 0.3866216242313385\n",
      "Epoch 5, Loss: 0.754119336605072\n",
      "Epoch 6, Loss: 0.40826717019081116\n",
      "Epoch 7, Loss: 0.3187209665775299\n",
      "Epoch 8, Loss: 0.3272339105606079\n",
      "Epoch 9, Loss: 0.3115904629230499\n",
      "Epoch 10, Loss: 0.43369001150131226\n",
      "Epoch 11, Loss: 0.5168707966804504\n",
      "Epoch 12, Loss: 0.27430492639541626\n",
      "Epoch 13, Loss: 0.329321950674057\n",
      "Epoch 14, Loss: 0.28784188628196716\n",
      "Epoch 15, Loss: 0.4586172103881836\n",
      "Epoch 16, Loss: 0.15944868326187134\n",
      "Epoch 17, Loss: 0.35017868876457214\n",
      "Epoch 18, Loss: 0.25795885920524597\n",
      "Epoch 19, Loss: 0.3220581114292145\n",
      "Epoch 20, Loss: 0.18788130581378937\n",
      "Epoch 21, Loss: 0.11946061998605728\n",
      "Epoch 22, Loss: 0.10129060596227646\n",
      "Epoch 23, Loss: 0.13222280144691467\n",
      "Epoch 24, Loss: 0.06848257780075073\n",
      "Epoch 25, Loss: 0.2328605055809021\n",
      "Epoch 26, Loss: 0.0886496976017952\n",
      "Epoch 27, Loss: 0.27735984325408936\n",
      "Epoch 28, Loss: 0.16917578876018524\n",
      "Epoch 29, Loss: 0.10118383169174194\n",
      "Epoch 30, Loss: 0.09261354058980942\n",
      "Epoch 31, Loss: 0.1267421692609787\n",
      "Epoch 32, Loss: 0.06717845797538757\n",
      "Epoch 33, Loss: 0.1378808617591858\n",
      "Epoch 34, Loss: 0.05169467255473137\n",
      "Epoch 35, Loss: 0.08638862520456314\n",
      "Epoch 36, Loss: 0.0923529714345932\n",
      "Epoch 37, Loss: 0.06534329801797867\n",
      "Epoch 38, Loss: 0.07904765009880066\n",
      "Epoch 39, Loss: 0.10360220819711685\n",
      "Epoch 40, Loss: 0.027591250836849213\n",
      "Epoch 41, Loss: 0.06495730578899384\n",
      "Epoch 42, Loss: 0.07432492077350616\n",
      "Epoch 43, Loss: 0.014172181487083435\n",
      "Epoch 44, Loss: 0.03184768557548523\n",
      "Epoch 45, Loss: 0.036792125552892685\n",
      "Epoch 46, Loss: 0.027628136798739433\n",
      "Epoch 47, Loss: 0.024130791425704956\n",
      "Epoch 48, Loss: 0.027698121964931488\n",
      "Epoch 49, Loss: 0.0170902069658041\n",
      "Epoch 50, Loss: 0.014908120036125183\n",
      "Epoch 51, Loss: 0.012620142661035061\n",
      "Epoch 52, Loss: 0.018749743700027466\n",
      "Epoch 53, Loss: 0.06800680607557297\n",
      "Epoch 54, Loss: 0.0566525012254715\n",
      "Epoch 55, Loss: 0.032711420208215714\n",
      "Epoch 56, Loss: 0.01188634056597948\n",
      "Epoch 57, Loss: 0.03267182037234306\n",
      "Epoch 58, Loss: 0.03157055377960205\n",
      "Epoch 59, Loss: 0.023386267945170403\n",
      "Epoch 60, Loss: 0.0875098705291748\n",
      "Epoch 61, Loss: 0.022719280794262886\n",
      "Epoch 62, Loss: 0.02777952328324318\n",
      "Epoch 63, Loss: 0.04374618083238602\n",
      "Epoch 64, Loss: 0.020692510530352592\n",
      "Epoch 65, Loss: 0.017459027469158173\n",
      "Epoch 66, Loss: 0.011035490781068802\n",
      "Epoch 67, Loss: 0.022987956181168556\n",
      "Epoch 68, Loss: 0.024616537615656853\n",
      "Epoch 69, Loss: 0.02182895690202713\n",
      "Epoch 70, Loss: 0.017140354961156845\n",
      "Epoch 71, Loss: 0.014110878109931946\n",
      "Epoch 72, Loss: 0.0081903375685215\n",
      "Epoch 73, Loss: 0.009296391159296036\n",
      "Epoch 74, Loss: 0.03219156712293625\n",
      "Epoch 75, Loss: 0.018859319388866425\n",
      "Epoch 76, Loss: 0.014513571746647358\n",
      "Epoch 77, Loss: 0.02729605697095394\n",
      "Epoch 78, Loss: 0.01969560980796814\n",
      "Epoch 79, Loss: 0.0060371826402843\n",
      "Epoch 80, Loss: 0.01480488944798708\n",
      "Epoch 81, Loss: 0.0065622273832559586\n",
      "Epoch 82, Loss: 0.006846127565950155\n",
      "Epoch 83, Loss: 0.02748247981071472\n",
      "Epoch 84, Loss: 0.007863551378250122\n",
      "Epoch 85, Loss: 0.014000634662806988\n",
      "Epoch 86, Loss: 0.012964784167706966\n",
      "Epoch 87, Loss: 0.006149608641862869\n",
      "Epoch 88, Loss: 0.017123745754361153\n",
      "Epoch 89, Loss: 0.02121794782578945\n",
      "Epoch 90, Loss: 0.009403267875313759\n",
      "Epoch 91, Loss: 0.004952113144099712\n",
      "Epoch 92, Loss: 0.006082494277507067\n",
      "Epoch 93, Loss: 0.005571575835347176\n",
      "Epoch 94, Loss: 0.04316605627536774\n",
      "Epoch 95, Loss: 0.011573548428714275\n",
      "Epoch 96, Loss: 0.008190609514713287\n",
      "Epoch 97, Loss: 0.005067464429885149\n",
      "Epoch 98, Loss: 0.009996718727052212\n",
      "Epoch 99, Loss: 0.0077573456801474094\n",
      "Epoch 100, Loss: 0.01241704635322094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.581618070602417\n",
      "Epoch 1, Loss: 0.3741602897644043\n",
      "Epoch 2, Loss: 0.36102983355522156\n",
      "Epoch 3, Loss: 0.8732011914253235\n",
      "Epoch 4, Loss: 0.6841317415237427\n",
      "Epoch 5, Loss: 0.6254432797431946\n",
      "Epoch 6, Loss: 0.4671700894832611\n",
      "Epoch 7, Loss: 0.6583168506622314\n",
      "Epoch 8, Loss: 0.29644837975502014\n",
      "Epoch 9, Loss: 0.7761685252189636\n",
      "Epoch 10, Loss: 0.6224270462989807\n",
      "Epoch 11, Loss: 0.5213840007781982\n",
      "Epoch 12, Loss: 0.4047311246395111\n",
      "Epoch 13, Loss: 0.34565505385398865\n",
      "Epoch 14, Loss: 0.3595597743988037\n",
      "Epoch 15, Loss: 0.23231154680252075\n",
      "Epoch 16, Loss: 0.13612088561058044\n",
      "Epoch 17, Loss: 0.39391112327575684\n",
      "Epoch 18, Loss: 0.31449630856513977\n",
      "Epoch 19, Loss: 0.12704549729824066\n",
      "Epoch 20, Loss: 0.33361542224884033\n",
      "Epoch 21, Loss: 0.33759474754333496\n",
      "Epoch 22, Loss: 0.14973144233226776\n",
      "Epoch 23, Loss: 0.3058543801307678\n",
      "Epoch 24, Loss: 0.27192747592926025\n",
      "Epoch 25, Loss: 0.06941542029380798\n",
      "Epoch 26, Loss: 0.23245127499103546\n",
      "Epoch 27, Loss: 0.24721407890319824\n",
      "Epoch 28, Loss: 0.149574875831604\n",
      "Epoch 29, Loss: 0.1374732106924057\n",
      "Epoch 30, Loss: 0.1263994425535202\n",
      "Epoch 31, Loss: 0.07064614444971085\n",
      "Epoch 32, Loss: 0.09589990973472595\n",
      "Epoch 33, Loss: 0.06861737370491028\n",
      "Epoch 34, Loss: 0.16692134737968445\n",
      "Epoch 35, Loss: 0.08602527529001236\n",
      "Epoch 36, Loss: 0.1983630508184433\n",
      "Epoch 37, Loss: 0.06798043102025986\n",
      "Epoch 38, Loss: 0.17751020193099976\n",
      "Epoch 39, Loss: 0.023525379598140717\n",
      "Epoch 40, Loss: 0.06025884672999382\n",
      "Epoch 41, Loss: 0.12169244885444641\n",
      "Epoch 42, Loss: 0.06679359078407288\n",
      "Epoch 43, Loss: 0.03989182412624359\n",
      "Epoch 44, Loss: 0.040942057967185974\n",
      "Epoch 45, Loss: 0.044504277408123016\n",
      "Epoch 46, Loss: 0.01657179184257984\n",
      "Epoch 47, Loss: 0.039367709308862686\n",
      "Epoch 48, Loss: 0.03631839528679848\n",
      "Epoch 49, Loss: 0.04529639333486557\n",
      "Epoch 50, Loss: 0.09210751950740814\n",
      "Epoch 51, Loss: 0.024725105613470078\n",
      "Epoch 52, Loss: 0.04811417683959007\n",
      "Epoch 53, Loss: 0.008608098141849041\n",
      "Epoch 54, Loss: 0.02643849141895771\n",
      "Epoch 55, Loss: 0.03987623751163483\n",
      "Epoch 56, Loss: 0.016677817329764366\n",
      "Epoch 57, Loss: 0.04115103930234909\n",
      "Epoch 58, Loss: 0.03448084369301796\n",
      "Epoch 59, Loss: 0.018524160608649254\n",
      "Epoch 60, Loss: 0.0341881588101387\n",
      "Epoch 61, Loss: 0.05609297752380371\n",
      "Epoch 62, Loss: 0.029036743566393852\n",
      "Epoch 63, Loss: 0.04772351682186127\n",
      "Epoch 64, Loss: 0.01857401616871357\n",
      "Epoch 65, Loss: 0.05387697368860245\n",
      "Epoch 66, Loss: 0.0059318020939826965\n",
      "Epoch 67, Loss: 0.01256364956498146\n",
      "Epoch 68, Loss: 0.019945597276091576\n",
      "Epoch 69, Loss: 0.03855949640274048\n",
      "Epoch 70, Loss: 0.021170271560549736\n",
      "Epoch 71, Loss: 0.01496069971472025\n",
      "Epoch 72, Loss: 0.03387710824608803\n",
      "Epoch 73, Loss: 0.016305817291140556\n",
      "Epoch 74, Loss: 0.008557482622563839\n",
      "Epoch 75, Loss: 0.01608366146683693\n",
      "Epoch 76, Loss: 0.007755396421998739\n",
      "Epoch 77, Loss: 0.045870136469602585\n",
      "Epoch 78, Loss: 0.019957302138209343\n",
      "Epoch 79, Loss: 0.014494240283966064\n",
      "Epoch 80, Loss: 0.02244054339826107\n",
      "Epoch 81, Loss: 0.004980717319995165\n",
      "Epoch 82, Loss: 0.03064424730837345\n",
      "Epoch 83, Loss: 0.015774421393871307\n",
      "Epoch 84, Loss: 0.015838900581002235\n",
      "Epoch 85, Loss: 0.017138240858912468\n",
      "Epoch 86, Loss: 0.009974312968552113\n",
      "Epoch 87, Loss: 0.004862942732870579\n",
      "Epoch 88, Loss: 0.009236156940460205\n",
      "Epoch 89, Loss: 0.010913161560893059\n",
      "Epoch 90, Loss: 0.009532267227768898\n",
      "Epoch 91, Loss: 0.009664062410593033\n",
      "Epoch 92, Loss: 0.008362367749214172\n",
      "Epoch 93, Loss: 0.0034843431785702705\n",
      "Epoch 94, Loss: 0.005585923325270414\n",
      "Epoch 95, Loss: 0.008444477804005146\n",
      "Epoch 96, Loss: 0.010261068120598793\n",
      "Epoch 97, Loss: 0.007970236241817474\n",
      "Epoch 98, Loss: 0.018186889588832855\n",
      "Epoch 99, Loss: 0.008976297453045845\n",
      "Epoch 100, Loss: 0.007397310808300972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.5633641481399536\n",
      "Epoch 1, Loss: 0.5809366703033447\n",
      "Epoch 2, Loss: 0.3732367753982544\n",
      "Epoch 3, Loss: 0.4651869535446167\n",
      "Epoch 4, Loss: 0.3409436345100403\n",
      "Epoch 5, Loss: 0.3752644658088684\n",
      "Epoch 6, Loss: 0.6742258071899414\n",
      "Epoch 7, Loss: 0.12632089853286743\n",
      "Epoch 8, Loss: 0.8954777121543884\n",
      "Epoch 9, Loss: 0.14629831910133362\n",
      "Epoch 10, Loss: 0.2800883948802948\n",
      "Epoch 11, Loss: 0.3954750895500183\n",
      "Epoch 12, Loss: 0.37918657064437866\n",
      "Epoch 13, Loss: 0.18039140105247498\n",
      "Epoch 14, Loss: 0.27959325909614563\n",
      "Epoch 15, Loss: 0.31493473052978516\n",
      "Epoch 16, Loss: 0.131677508354187\n",
      "Epoch 17, Loss: 0.15950030088424683\n",
      "Epoch 18, Loss: 0.098373182117939\n",
      "Epoch 19, Loss: 0.09411537647247314\n",
      "Epoch 20, Loss: 0.056967005133628845\n",
      "Epoch 21, Loss: 0.27524223923683167\n",
      "Epoch 22, Loss: 0.11556413769721985\n",
      "Epoch 23, Loss: 0.15983138978481293\n",
      "Epoch 24, Loss: 0.3148966431617737\n",
      "Epoch 25, Loss: 0.2234993278980255\n",
      "Epoch 26, Loss: 0.2124522477388382\n",
      "Epoch 27, Loss: 0.10951951891183853\n",
      "Epoch 28, Loss: 0.12718962132930756\n",
      "Epoch 29, Loss: 0.3933125138282776\n",
      "Epoch 30, Loss: 0.15855816006660461\n",
      "Epoch 31, Loss: 0.03272998332977295\n",
      "Epoch 32, Loss: 0.020740985870361328\n",
      "Epoch 33, Loss: 0.12131796777248383\n",
      "Epoch 34, Loss: 0.09175042808055878\n",
      "Epoch 35, Loss: 0.030967004597187042\n",
      "Epoch 36, Loss: 0.14824505150318146\n",
      "Epoch 37, Loss: 0.06106395274400711\n",
      "Epoch 38, Loss: 0.07208976149559021\n",
      "Epoch 39, Loss: 0.07845412939786911\n",
      "Epoch 40, Loss: 0.07306089997291565\n",
      "Epoch 41, Loss: 0.05403168499469757\n",
      "Epoch 42, Loss: 0.04301205649971962\n",
      "Epoch 43, Loss: 0.023236826062202454\n",
      "Epoch 44, Loss: 0.03386148437857628\n",
      "Epoch 45, Loss: 0.044757209718227386\n",
      "Epoch 46, Loss: 0.11337467283010483\n",
      "Epoch 47, Loss: 0.0414428636431694\n",
      "Epoch 48, Loss: 0.0726763904094696\n",
      "Epoch 49, Loss: 0.050607845187187195\n",
      "Epoch 50, Loss: 0.029763123020529747\n",
      "Epoch 51, Loss: 0.05290394648909569\n",
      "Epoch 52, Loss: 0.028377149254083633\n",
      "Epoch 53, Loss: 0.013331785798072815\n",
      "Epoch 54, Loss: 0.07494260370731354\n",
      "Epoch 55, Loss: 0.02587362937629223\n",
      "Epoch 56, Loss: 0.02386065199971199\n",
      "Epoch 57, Loss: 0.02236572653055191\n",
      "Epoch 58, Loss: 0.016103697940707207\n",
      "Epoch 59, Loss: 0.01514364406466484\n",
      "Epoch 60, Loss: 0.0331030935049057\n",
      "Epoch 61, Loss: 0.01870402693748474\n",
      "Epoch 62, Loss: 0.01422975491732359\n",
      "Epoch 63, Loss: 0.016149144619703293\n",
      "Epoch 64, Loss: 0.014271842315793037\n",
      "Epoch 65, Loss: 0.018808551132678986\n",
      "Epoch 66, Loss: 0.006792484782636166\n",
      "Epoch 67, Loss: 0.04745613783597946\n",
      "Epoch 68, Loss: 0.010879254899919033\n",
      "Epoch 69, Loss: 0.026651665568351746\n",
      "Epoch 70, Loss: 0.007550885900855064\n",
      "Epoch 71, Loss: 0.025676511228084564\n",
      "Epoch 72, Loss: 0.007535103242844343\n",
      "Epoch 73, Loss: 0.016496585682034492\n",
      "Epoch 74, Loss: 0.030544493347406387\n",
      "Epoch 75, Loss: 0.01747218519449234\n",
      "Epoch 76, Loss: 0.015789858996868134\n",
      "Epoch 77, Loss: 0.012157921679317951\n",
      "Epoch 78, Loss: 0.00743193831294775\n",
      "Epoch 79, Loss: 0.004914697725325823\n",
      "Epoch 80, Loss: 0.014992647804319859\n",
      "Epoch 81, Loss: 0.013515844941139221\n",
      "Epoch 82, Loss: 0.019943878054618835\n",
      "Epoch 83, Loss: 0.010869084857404232\n",
      "Epoch 84, Loss: 0.022664153948426247\n",
      "Epoch 85, Loss: 0.035704050213098526\n",
      "Epoch 86, Loss: 0.036928851157426834\n",
      "Epoch 87, Loss: 0.0220340508967638\n",
      "Epoch 88, Loss: 0.011231483891606331\n",
      "Epoch 89, Loss: 0.011424364522099495\n",
      "Epoch 90, Loss: 0.006307840347290039\n",
      "Epoch 91, Loss: 0.008116420358419418\n",
      "Epoch 92, Loss: 0.0200178325176239\n",
      "Epoch 93, Loss: 0.01094753760844469\n",
      "Epoch 94, Loss: 0.010725575499236584\n",
      "Epoch 95, Loss: 0.004328107461333275\n",
      "Epoch 96, Loss: 0.014450754038989544\n",
      "Epoch 97, Loss: 0.006635046564042568\n",
      "Epoch 98, Loss: 0.038182273507118225\n",
      "Epoch 99, Loss: 0.020149806514382362\n",
      "Epoch 100, Loss: 0.0056942845694720745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.400874137878418\n",
      "Epoch 1, Loss: 0.7448770999908447\n",
      "Epoch 2, Loss: 0.7313097715377808\n",
      "Epoch 3, Loss: 0.5402376651763916\n",
      "Epoch 4, Loss: 0.40150490403175354\n",
      "Epoch 5, Loss: 0.4837411344051361\n",
      "Epoch 6, Loss: 0.7919378280639648\n",
      "Epoch 7, Loss: 0.4185289144515991\n",
      "Epoch 8, Loss: 0.756376326084137\n",
      "Epoch 9, Loss: 0.2603265643119812\n",
      "Epoch 10, Loss: 0.1557263731956482\n",
      "Epoch 11, Loss: 0.15149608254432678\n",
      "Epoch 12, Loss: 0.6801093220710754\n",
      "Epoch 13, Loss: 0.1588352471590042\n",
      "Epoch 14, Loss: 0.19322627782821655\n",
      "Epoch 15, Loss: 0.14301718771457672\n",
      "Epoch 16, Loss: 0.3671431541442871\n",
      "Epoch 17, Loss: 0.24317187070846558\n",
      "Epoch 18, Loss: 0.10158643871545792\n",
      "Epoch 19, Loss: 0.2015816867351532\n",
      "Epoch 20, Loss: 0.7560995817184448\n",
      "Epoch 21, Loss: 0.2502869963645935\n",
      "Epoch 22, Loss: 0.18437474966049194\n",
      "Epoch 23, Loss: 0.14513953030109406\n",
      "Epoch 24, Loss: 0.14670737087726593\n",
      "Epoch 25, Loss: 0.052247293293476105\n",
      "Epoch 26, Loss: 0.2983569800853729\n",
      "Epoch 27, Loss: 0.14674274623394012\n",
      "Epoch 28, Loss: 0.10146065056324005\n",
      "Epoch 29, Loss: 0.08582800626754761\n",
      "Epoch 30, Loss: 0.1580641120672226\n",
      "Epoch 31, Loss: 0.09076178818941116\n",
      "Epoch 32, Loss: 0.2045208364725113\n",
      "Epoch 33, Loss: 0.12543436884880066\n",
      "Epoch 34, Loss: 0.10598842054605484\n",
      "Epoch 35, Loss: 0.09412948787212372\n",
      "Epoch 36, Loss: 0.05935691297054291\n",
      "Epoch 37, Loss: 0.043920159339904785\n",
      "Epoch 38, Loss: 0.018445182591676712\n",
      "Epoch 39, Loss: 0.053345657885074615\n",
      "Epoch 40, Loss: 0.025175685063004494\n",
      "Epoch 41, Loss: 0.03925160691142082\n",
      "Epoch 42, Loss: 0.05283449590206146\n",
      "Epoch 43, Loss: 0.06216379627585411\n",
      "Epoch 44, Loss: 0.04848775640130043\n",
      "Epoch 45, Loss: 0.061259057372808456\n",
      "Epoch 46, Loss: 0.05877545103430748\n",
      "Epoch 47, Loss: 0.11782945692539215\n",
      "Epoch 48, Loss: 0.020715855062007904\n",
      "Epoch 49, Loss: 0.12198182195425034\n",
      "Epoch 50, Loss: 0.05391713231801987\n",
      "Epoch 51, Loss: 0.02824758179485798\n",
      "Epoch 52, Loss: 0.10189758241176605\n",
      "Epoch 53, Loss: 0.039229851216077805\n",
      "Epoch 54, Loss: 0.021776527166366577\n",
      "Epoch 55, Loss: 0.01998382993042469\n",
      "Epoch 56, Loss: 0.034475408494472504\n",
      "Epoch 57, Loss: 0.018704110756516457\n",
      "Epoch 58, Loss: 0.012697509489953518\n",
      "Epoch 59, Loss: 0.05760940536856651\n",
      "Epoch 60, Loss: 0.00851052813231945\n",
      "Epoch 61, Loss: 0.02211521565914154\n",
      "Epoch 62, Loss: 0.015761470422148705\n",
      "Epoch 63, Loss: 0.024934636428952217\n",
      "Epoch 64, Loss: 0.015578831546008587\n",
      "Epoch 65, Loss: 0.022488079965114594\n",
      "Epoch 66, Loss: 0.027123983949422836\n",
      "Epoch 67, Loss: 0.03912656754255295\n",
      "Epoch 68, Loss: 0.030507240444421768\n",
      "Epoch 69, Loss: 0.010740473866462708\n",
      "Epoch 70, Loss: 0.012151249684393406\n",
      "Epoch 71, Loss: 0.012085895985364914\n",
      "Epoch 72, Loss: 0.009134439751505852\n",
      "Epoch 73, Loss: 0.018452657386660576\n",
      "Epoch 74, Loss: 0.009707928635179996\n",
      "Epoch 75, Loss: 0.02387377992272377\n",
      "Epoch 76, Loss: 0.031571000814437866\n",
      "Epoch 77, Loss: 0.03393889591097832\n",
      "Epoch 78, Loss: 0.009161767549812794\n",
      "Epoch 79, Loss: 0.07317500561475754\n",
      "Epoch 80, Loss: 0.012860333546996117\n",
      "Epoch 81, Loss: 0.011186071671545506\n",
      "Epoch 82, Loss: 0.019690409302711487\n",
      "Epoch 83, Loss: 0.01810530014336109\n",
      "Epoch 84, Loss: 0.015385519713163376\n",
      "Epoch 85, Loss: 0.011653469875454903\n",
      "Epoch 86, Loss: 0.017966382205486298\n",
      "Epoch 87, Loss: 0.01183149591088295\n",
      "Epoch 88, Loss: 0.020750725641846657\n",
      "Epoch 89, Loss: 0.008558581583201885\n",
      "Epoch 90, Loss: 0.011873764917254448\n",
      "Epoch 91, Loss: 0.00833084061741829\n",
      "Epoch 92, Loss: 0.011359418742358685\n",
      "Epoch 93, Loss: 0.019788267090916634\n",
      "Epoch 94, Loss: 0.01949441246688366\n",
      "Epoch 95, Loss: 0.008106543682515621\n",
      "Epoch 96, Loss: 0.005843615625053644\n",
      "Epoch 97, Loss: 0.006686050444841385\n",
      "Epoch 98, Loss: 0.006918597035109997\n",
      "Epoch 99, Loss: 0.01425523217767477\n",
      "Epoch 100, Loss: 0.01775144413113594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.5931966304779053\n",
      "Epoch 1, Loss: 0.5963630676269531\n",
      "Epoch 2, Loss: 0.4058905243873596\n",
      "Epoch 3, Loss: 0.42806410789489746\n",
      "Epoch 4, Loss: 0.9104000926017761\n",
      "Epoch 5, Loss: 0.29245421290397644\n",
      "Epoch 6, Loss: 0.4343353807926178\n",
      "Epoch 7, Loss: 0.5381938219070435\n",
      "Epoch 8, Loss: 0.24709929525852203\n",
      "Epoch 9, Loss: 0.6531562805175781\n",
      "Epoch 10, Loss: 0.42458251118659973\n",
      "Epoch 11, Loss: 0.43687868118286133\n",
      "Epoch 12, Loss: 0.30930185317993164\n",
      "Epoch 13, Loss: 0.12386149913072586\n",
      "Epoch 14, Loss: 0.18224141001701355\n",
      "Epoch 15, Loss: 0.22033053636550903\n",
      "Epoch 16, Loss: 0.22503627836704254\n",
      "Epoch 17, Loss: 0.15495990216732025\n",
      "Epoch 18, Loss: 0.5295220613479614\n",
      "Epoch 19, Loss: 0.2776009142398834\n",
      "Epoch 20, Loss: 0.059690918773412704\n",
      "Epoch 21, Loss: 0.10529842972755432\n",
      "Epoch 22, Loss: 0.06017426773905754\n",
      "Epoch 23, Loss: 0.21744142472743988\n",
      "Epoch 24, Loss: 0.08240371197462082\n",
      "Epoch 25, Loss: 0.13414105772972107\n",
      "Epoch 26, Loss: 0.1426517367362976\n",
      "Epoch 27, Loss: 0.12772589921951294\n",
      "Epoch 28, Loss: 0.09661814570426941\n",
      "Epoch 29, Loss: 0.19439588487148285\n",
      "Epoch 30, Loss: 0.12082000821828842\n",
      "Epoch 31, Loss: 0.09677621722221375\n",
      "Epoch 32, Loss: 0.10032959282398224\n",
      "Epoch 33, Loss: 0.07269289344549179\n",
      "Epoch 34, Loss: 0.06479448080062866\n",
      "Epoch 35, Loss: 0.05439811944961548\n",
      "Epoch 36, Loss: 0.03530217707157135\n",
      "Epoch 37, Loss: 0.1126629114151001\n",
      "Epoch 38, Loss: 0.04308895766735077\n",
      "Epoch 39, Loss: 0.10999813675880432\n",
      "Epoch 40, Loss: 0.07146316021680832\n",
      "Epoch 41, Loss: 0.08920261263847351\n",
      "Epoch 42, Loss: 0.020818503573536873\n",
      "Epoch 43, Loss: 0.056818511337041855\n",
      "Epoch 44, Loss: 0.09054877609014511\n",
      "Epoch 45, Loss: 0.18329618871212006\n",
      "Epoch 46, Loss: 0.05083509162068367\n",
      "Epoch 47, Loss: 0.0974339172244072\n",
      "Epoch 48, Loss: 0.021230828016996384\n",
      "Epoch 49, Loss: 0.057308394461870193\n",
      "Epoch 50, Loss: 0.021622581407427788\n",
      "Epoch 51, Loss: 0.0074179042130708694\n",
      "Epoch 52, Loss: 0.0136951245367527\n",
      "Epoch 53, Loss: 0.013964485377073288\n",
      "Epoch 54, Loss: 0.0288554634898901\n",
      "Epoch 55, Loss: 0.0190518107265234\n",
      "Epoch 56, Loss: 0.04756496846675873\n",
      "Epoch 57, Loss: 0.01326953899115324\n",
      "Epoch 58, Loss: 0.03201843798160553\n",
      "Epoch 59, Loss: 0.0406007319688797\n",
      "Epoch 60, Loss: 0.06512544304132462\n",
      "Epoch 61, Loss: 0.01292426697909832\n",
      "Epoch 62, Loss: 0.030199743807315826\n",
      "Epoch 63, Loss: 0.031898632645606995\n",
      "Epoch 64, Loss: 0.019844597205519676\n",
      "Epoch 65, Loss: 0.014751126058399677\n",
      "Epoch 66, Loss: 0.041894372552633286\n",
      "Epoch 67, Loss: 0.01996324397623539\n",
      "Epoch 68, Loss: 0.022565118968486786\n",
      "Epoch 69, Loss: 0.012807689607143402\n",
      "Epoch 70, Loss: 0.032029736787080765\n",
      "Epoch 71, Loss: 0.013790970668196678\n",
      "Epoch 72, Loss: 0.011214119382202625\n",
      "Epoch 73, Loss: 0.014353245496749878\n",
      "Epoch 74, Loss: 0.011255914345383644\n",
      "Epoch 75, Loss: 0.004359093960374594\n",
      "Epoch 76, Loss: 0.00812695175409317\n",
      "Epoch 77, Loss: 0.015709204599261284\n",
      "Epoch 78, Loss: 0.01590084657073021\n",
      "Epoch 79, Loss: 0.010686253197491169\n",
      "Epoch 80, Loss: 0.005557970609515905\n",
      "Epoch 81, Loss: 0.009471867233514786\n",
      "Epoch 82, Loss: 0.006616643164306879\n",
      "Epoch 83, Loss: 0.04040985181927681\n",
      "Epoch 84, Loss: 0.007147878408432007\n",
      "Epoch 85, Loss: 0.015426154248416424\n",
      "Epoch 86, Loss: 0.013458482921123505\n",
      "Epoch 87, Loss: 0.04122723639011383\n",
      "Epoch 88, Loss: 0.01352057233452797\n",
      "Epoch 89, Loss: 0.011241386644542217\n",
      "Epoch 90, Loss: 0.014201785437762737\n",
      "Epoch 91, Loss: 0.010046552866697311\n",
      "Epoch 92, Loss: 0.04035802558064461\n",
      "Epoch 93, Loss: 0.010815011337399483\n",
      "Epoch 94, Loss: 0.011081225238740444\n",
      "Epoch 95, Loss: 0.006519554648548365\n",
      "Epoch 96, Loss: 0.015015466138720512\n",
      "Epoch 97, Loss: 0.011896236799657345\n",
      "Epoch 98, Loss: 0.002511379774659872\n",
      "Epoch 99, Loss: 0.03118930570781231\n",
      "Epoch 100, Loss: 0.06937974691390991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3374985456466675\n",
      "Epoch 1, Loss: 0.8237715363502502\n",
      "Epoch 2, Loss: 0.7960231900215149\n",
      "Epoch 3, Loss: 0.408120721578598\n",
      "Epoch 4, Loss: 0.32757529616355896\n",
      "Epoch 5, Loss: 0.4488264322280884\n",
      "Epoch 6, Loss: 0.31344568729400635\n",
      "Epoch 7, Loss: 0.35998380184173584\n",
      "Epoch 8, Loss: 0.3198416233062744\n",
      "Epoch 9, Loss: 0.49469196796417236\n",
      "Epoch 10, Loss: 0.2922830581665039\n",
      "Epoch 11, Loss: 0.38870593905448914\n",
      "Epoch 12, Loss: 0.608492374420166\n",
      "Epoch 13, Loss: 0.3038099706172943\n",
      "Epoch 14, Loss: 0.20136041939258575\n",
      "Epoch 15, Loss: 0.3411047160625458\n",
      "Epoch 16, Loss: 0.23550385236740112\n",
      "Epoch 17, Loss: 0.14300090074539185\n",
      "Epoch 18, Loss: 0.28100502490997314\n",
      "Epoch 19, Loss: 0.14379851520061493\n",
      "Epoch 20, Loss: 0.15174075961112976\n",
      "Epoch 21, Loss: 0.13489912450313568\n",
      "Epoch 22, Loss: 0.10041355341672897\n",
      "Epoch 23, Loss: 0.18103651702404022\n",
      "Epoch 24, Loss: 0.11702705919742584\n",
      "Epoch 25, Loss: 0.08629991859197617\n",
      "Epoch 26, Loss: 0.25867345929145813\n",
      "Epoch 27, Loss: 0.20384371280670166\n",
      "Epoch 28, Loss: 0.07861996442079544\n",
      "Epoch 29, Loss: 0.07817360758781433\n",
      "Epoch 30, Loss: 0.1409393548965454\n",
      "Epoch 31, Loss: 0.08472727984189987\n",
      "Epoch 32, Loss: 0.18583226203918457\n",
      "Epoch 33, Loss: 0.06102718785405159\n",
      "Epoch 34, Loss: 0.1153402179479599\n",
      "Epoch 35, Loss: 0.08190275728702545\n",
      "Epoch 36, Loss: 0.03212970122694969\n",
      "Epoch 37, Loss: 0.1156948134303093\n",
      "Epoch 38, Loss: 0.057291124016046524\n",
      "Epoch 39, Loss: 0.03297756612300873\n",
      "Epoch 40, Loss: 0.042390819638967514\n",
      "Epoch 41, Loss: 0.09902435541152954\n",
      "Epoch 42, Loss: 0.042419638484716415\n",
      "Epoch 43, Loss: 0.04074173420667648\n",
      "Epoch 44, Loss: 0.03855067864060402\n",
      "Epoch 45, Loss: 0.041203573346138\n",
      "Epoch 46, Loss: 0.04082271829247475\n",
      "Epoch 47, Loss: 0.023997072130441666\n",
      "Epoch 48, Loss: 0.014038380235433578\n",
      "Epoch 49, Loss: 0.02369733527302742\n",
      "Epoch 50, Loss: 0.023498637601733208\n",
      "Epoch 51, Loss: 0.054442599415779114\n",
      "Epoch 52, Loss: 0.03617929667234421\n",
      "Epoch 53, Loss: 0.05764920264482498\n",
      "Epoch 54, Loss: 0.057059723883867264\n",
      "Epoch 55, Loss: 0.042480986565351486\n",
      "Epoch 56, Loss: 0.0286293663084507\n",
      "Epoch 57, Loss: 0.025040144100785255\n",
      "Epoch 58, Loss: 0.013277014717459679\n",
      "Epoch 59, Loss: 0.02456786297261715\n",
      "Epoch 60, Loss: 0.04374554380774498\n",
      "Epoch 61, Loss: 0.04106432944536209\n",
      "Epoch 62, Loss: 0.017511017620563507\n",
      "Epoch 63, Loss: 0.01523996889591217\n",
      "Epoch 64, Loss: 0.020308416336774826\n",
      "Epoch 65, Loss: 0.037852007895708084\n",
      "Epoch 66, Loss: 0.032287467271089554\n",
      "Epoch 67, Loss: 0.016436096280813217\n",
      "Epoch 68, Loss: 0.013137861154973507\n",
      "Epoch 69, Loss: 0.048909809440374374\n",
      "Epoch 70, Loss: 0.02223210595548153\n",
      "Epoch 71, Loss: 0.013471577316522598\n",
      "Epoch 72, Loss: 0.0151074742898345\n",
      "Epoch 73, Loss: 0.023640943691134453\n",
      "Epoch 74, Loss: 0.01782715879380703\n",
      "Epoch 75, Loss: 0.01846836693584919\n",
      "Epoch 76, Loss: 0.05612744390964508\n",
      "Epoch 77, Loss: 0.01244898047298193\n",
      "Epoch 78, Loss: 0.010332008823752403\n",
      "Epoch 79, Loss: 0.014004970900714397\n",
      "Epoch 80, Loss: 0.008377227932214737\n",
      "Epoch 81, Loss: 0.012937094084918499\n",
      "Epoch 82, Loss: 0.01702987402677536\n",
      "Epoch 83, Loss: 0.02235231176018715\n",
      "Epoch 84, Loss: 0.01589379273355007\n",
      "Epoch 85, Loss: 0.016413794830441475\n",
      "Epoch 86, Loss: 0.007317772135138512\n",
      "Epoch 87, Loss: 0.023947322741150856\n",
      "Epoch 88, Loss: 0.01999868080019951\n",
      "Epoch 89, Loss: 0.005689740180969238\n",
      "Epoch 90, Loss: 0.009043310768902302\n",
      "Epoch 91, Loss: 0.008467679843306541\n",
      "Epoch 92, Loss: 0.004302099347114563\n",
      "Epoch 93, Loss: 0.023072533309459686\n",
      "Epoch 94, Loss: 0.004745258949697018\n",
      "Epoch 95, Loss: 0.0115407295525074\n",
      "Epoch 96, Loss: 0.008001723326742649\n",
      "Epoch 97, Loss: 0.006355374585837126\n",
      "Epoch 98, Loss: 0.00801763404160738\n",
      "Epoch 99, Loss: 0.011643154546618462\n",
      "Epoch 100, Loss: 0.0076447841711342335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.610162377357483\n",
      "Epoch 1, Loss: 0.37887895107269287\n",
      "Epoch 2, Loss: 1.2771250009536743\n",
      "Epoch 3, Loss: 0.44523271918296814\n",
      "Epoch 4, Loss: 0.7914473414421082\n",
      "Epoch 5, Loss: 0.5557181239128113\n",
      "Epoch 6, Loss: 0.3746095895767212\n",
      "Epoch 7, Loss: 0.2604310214519501\n",
      "Epoch 8, Loss: 0.2574962377548218\n",
      "Epoch 9, Loss: 0.3059511184692383\n",
      "Epoch 10, Loss: 0.9259682893753052\n",
      "Epoch 11, Loss: 0.31969067454338074\n",
      "Epoch 12, Loss: 0.441536545753479\n",
      "Epoch 13, Loss: 0.3220393657684326\n",
      "Epoch 14, Loss: 0.14913442730903625\n",
      "Epoch 15, Loss: 0.14223411679267883\n",
      "Epoch 16, Loss: 0.17813299596309662\n",
      "Epoch 17, Loss: 0.3119431436061859\n",
      "Epoch 18, Loss: 0.226750448346138\n",
      "Epoch 19, Loss: 0.1606469601392746\n",
      "Epoch 20, Loss: 0.19028779864311218\n",
      "Epoch 21, Loss: 0.12171712517738342\n",
      "Epoch 22, Loss: 0.1786363124847412\n",
      "Epoch 23, Loss: 0.10279927402734756\n",
      "Epoch 24, Loss: 0.1457577794790268\n",
      "Epoch 25, Loss: 0.2011195868253708\n",
      "Epoch 26, Loss: 0.11881934106349945\n",
      "Epoch 27, Loss: 0.1771106719970703\n",
      "Epoch 28, Loss: 0.031359534710645676\n",
      "Epoch 29, Loss: 0.09303899854421616\n",
      "Epoch 30, Loss: 0.11955706030130386\n",
      "Epoch 31, Loss: 0.06815075129270554\n",
      "Epoch 32, Loss: 0.0991986021399498\n",
      "Epoch 33, Loss: 0.05626789107918739\n",
      "Epoch 34, Loss: 0.07261092960834503\n",
      "Epoch 35, Loss: 0.05661354586482048\n",
      "Epoch 36, Loss: 0.08097365498542786\n",
      "Epoch 37, Loss: 0.1720205843448639\n",
      "Epoch 38, Loss: 0.0322394073009491\n",
      "Epoch 39, Loss: 0.02381225861608982\n",
      "Epoch 40, Loss: 0.08893109858036041\n",
      "Epoch 41, Loss: 0.03800521045923233\n",
      "Epoch 42, Loss: 0.11599060893058777\n",
      "Epoch 43, Loss: 0.028520038351416588\n",
      "Epoch 44, Loss: 0.030336210504174232\n",
      "Epoch 45, Loss: 0.034085389226675034\n",
      "Epoch 46, Loss: 0.06524086743593216\n",
      "Epoch 47, Loss: 0.06793950498104095\n",
      "Epoch 48, Loss: 0.007089637219905853\n",
      "Epoch 49, Loss: 0.02397574484348297\n",
      "Epoch 50, Loss: 0.026115158572793007\n",
      "Epoch 51, Loss: 0.026323309168219566\n",
      "Epoch 52, Loss: 0.04556864872574806\n",
      "Epoch 53, Loss: 0.03395716845989227\n",
      "Epoch 54, Loss: 0.03474012389779091\n",
      "Epoch 55, Loss: 0.011236756108701229\n",
      "Epoch 56, Loss: 0.014970602467656136\n",
      "Epoch 57, Loss: 0.009637920185923576\n",
      "Epoch 58, Loss: 0.012032071128487587\n",
      "Epoch 59, Loss: 0.01718958467245102\n",
      "Epoch 60, Loss: 0.021931858733296394\n",
      "Epoch 61, Loss: 0.015016787685453892\n",
      "Epoch 62, Loss: 0.015686022117733955\n",
      "Epoch 63, Loss: 0.015094061382114887\n",
      "Epoch 64, Loss: 0.02603979967534542\n",
      "Epoch 65, Loss: 0.013037752360105515\n",
      "Epoch 66, Loss: 0.014362935908138752\n",
      "Epoch 67, Loss: 0.00858297385275364\n",
      "Epoch 68, Loss: 0.01237170398235321\n",
      "Epoch 69, Loss: 0.01483836304396391\n",
      "Epoch 70, Loss: 0.006859506480395794\n",
      "Epoch 71, Loss: 0.011508096940815449\n",
      "Epoch 72, Loss: 0.0075560882687568665\n",
      "Epoch 73, Loss: 0.02055273950099945\n",
      "Epoch 74, Loss: 0.006187254562973976\n",
      "Epoch 75, Loss: 0.01387145183980465\n",
      "Epoch 76, Loss: 0.010546787641942501\n",
      "Epoch 77, Loss: 0.021012885496020317\n",
      "Epoch 78, Loss: 0.018525077030062675\n",
      "Epoch 79, Loss: 0.024819156154990196\n",
      "Epoch 80, Loss: 0.009923677891492844\n",
      "Epoch 81, Loss: 0.008355979807674885\n",
      "Epoch 82, Loss: 0.009829714894294739\n",
      "Epoch 83, Loss: 0.012315298430621624\n",
      "Epoch 84, Loss: 0.022263333201408386\n",
      "Epoch 85, Loss: 0.012188909575343132\n",
      "Epoch 86, Loss: 0.006756203714758158\n",
      "Epoch 87, Loss: 0.004636263474822044\n",
      "Epoch 88, Loss: 0.011311907321214676\n",
      "Epoch 89, Loss: 0.011579973623156548\n",
      "Epoch 90, Loss: 0.013979054056107998\n",
      "Epoch 91, Loss: 0.005542086903005838\n",
      "Epoch 92, Loss: 0.016260555014014244\n",
      "Epoch 93, Loss: 0.008991535753011703\n",
      "Epoch 94, Loss: 0.010183827020227909\n",
      "Epoch 95, Loss: 0.015603550709784031\n",
      "Epoch 96, Loss: 0.010011146776378155\n",
      "Epoch 97, Loss: 0.010419254191219807\n",
      "Epoch 98, Loss: 0.014493394643068314\n",
      "Epoch 99, Loss: 0.006304516457021236\n",
      "Epoch 100, Loss: 0.0071260202676057816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3353127241134644\n",
      "Epoch 1, Loss: 0.7995578646659851\n",
      "Epoch 2, Loss: 0.5708963871002197\n",
      "Epoch 3, Loss: 0.671546220779419\n",
      "Epoch 4, Loss: 0.918964147567749\n",
      "Epoch 5, Loss: 0.28245308995246887\n",
      "Epoch 6, Loss: 0.4661092162132263\n",
      "Epoch 7, Loss: 0.5632292032241821\n",
      "Epoch 8, Loss: 0.49276405572891235\n",
      "Epoch 9, Loss: 0.38461142778396606\n",
      "Epoch 10, Loss: 0.5254355072975159\n",
      "Epoch 11, Loss: 0.5437833070755005\n",
      "Epoch 12, Loss: 0.2809279263019562\n",
      "Epoch 13, Loss: 0.21383678913116455\n",
      "Epoch 14, Loss: 0.10219406336545944\n",
      "Epoch 15, Loss: 0.1838243007659912\n",
      "Epoch 16, Loss: 0.21911098062992096\n",
      "Epoch 17, Loss: 0.45209890604019165\n",
      "Epoch 18, Loss: 0.1009250059723854\n",
      "Epoch 19, Loss: 0.17623065412044525\n",
      "Epoch 20, Loss: 0.21599391102790833\n",
      "Epoch 21, Loss: 0.14617958664894104\n",
      "Epoch 22, Loss: 0.09996840357780457\n",
      "Epoch 23, Loss: 0.1214839518070221\n",
      "Epoch 24, Loss: 0.1472109854221344\n",
      "Epoch 25, Loss: 0.060107987374067307\n",
      "Epoch 26, Loss: 0.09753896296024323\n",
      "Epoch 27, Loss: 0.1400032490491867\n",
      "Epoch 28, Loss: 0.05113682150840759\n",
      "Epoch 29, Loss: 0.03064831718802452\n",
      "Epoch 30, Loss: 0.14881926774978638\n",
      "Epoch 31, Loss: 0.08478763699531555\n",
      "Epoch 32, Loss: 0.0608014315366745\n",
      "Epoch 33, Loss: 0.03235446661710739\n",
      "Epoch 34, Loss: 0.07758740335702896\n",
      "Epoch 35, Loss: 0.14132097363471985\n",
      "Epoch 36, Loss: 0.13123217225074768\n",
      "Epoch 37, Loss: 0.04413608834147453\n",
      "Epoch 38, Loss: 0.08445349335670471\n",
      "Epoch 39, Loss: 0.09767443686723709\n",
      "Epoch 40, Loss: 0.06528907269239426\n",
      "Epoch 41, Loss: 0.02991415001451969\n",
      "Epoch 42, Loss: 0.052473630756139755\n",
      "Epoch 43, Loss: 0.046055108308792114\n",
      "Epoch 44, Loss: 0.020179443061351776\n",
      "Epoch 45, Loss: 0.04854680225253105\n",
      "Epoch 46, Loss: 0.023821361362934113\n",
      "Epoch 47, Loss: 0.026707462966442108\n",
      "Epoch 48, Loss: 0.06956639140844345\n",
      "Epoch 49, Loss: 0.0341188982129097\n",
      "Epoch 50, Loss: 0.03384336456656456\n",
      "Epoch 51, Loss: 0.015872424468398094\n",
      "Epoch 52, Loss: 0.034301601350307465\n",
      "Epoch 53, Loss: 0.026559337973594666\n",
      "Epoch 54, Loss: 0.046088654547929764\n",
      "Epoch 55, Loss: 0.030781077221035957\n",
      "Epoch 56, Loss: 0.012106885202229023\n",
      "Epoch 57, Loss: 0.029287321493029594\n",
      "Epoch 58, Loss: 0.027316797524690628\n",
      "Epoch 59, Loss: 0.0030411791522055864\n",
      "Epoch 60, Loss: 0.012357620522379875\n",
      "Epoch 61, Loss: 0.006617649458348751\n",
      "Epoch 62, Loss: 0.022929050028324127\n",
      "Epoch 63, Loss: 0.011898849159479141\n",
      "Epoch 64, Loss: 0.02203327976167202\n",
      "Epoch 65, Loss: 0.02678608149290085\n",
      "Epoch 66, Loss: 0.01105724461376667\n",
      "Epoch 67, Loss: 0.009841358289122581\n",
      "Epoch 68, Loss: 0.030895616859197617\n",
      "Epoch 69, Loss: 0.010812323540449142\n",
      "Epoch 70, Loss: 0.01063908077776432\n",
      "Epoch 71, Loss: 0.0560898631811142\n",
      "Epoch 72, Loss: 0.042513083666563034\n",
      "Epoch 73, Loss: 0.07679323852062225\n",
      "Epoch 74, Loss: 0.016190003603696823\n",
      "Epoch 75, Loss: 0.019061792641878128\n",
      "Epoch 76, Loss: 0.01790931448340416\n",
      "Epoch 77, Loss: 0.011043352074921131\n",
      "Epoch 78, Loss: 0.016016127541661263\n",
      "Epoch 79, Loss: 0.008506286889314651\n",
      "Epoch 80, Loss: 0.007110085804015398\n",
      "Epoch 81, Loss: 0.011336779221892357\n",
      "Epoch 82, Loss: 0.021253865212202072\n",
      "Epoch 83, Loss: 0.005500549450516701\n",
      "Epoch 84, Loss: 0.0077937594614923\n",
      "Epoch 85, Loss: 0.008027450181543827\n",
      "Epoch 86, Loss: 0.013201463036239147\n",
      "Epoch 87, Loss: 0.010950586758553982\n",
      "Epoch 88, Loss: 0.012355519458651543\n",
      "Epoch 89, Loss: 0.019453264772892\n",
      "Epoch 90, Loss: 0.008884157985448837\n",
      "Epoch 91, Loss: 0.005756693426519632\n",
      "Epoch 92, Loss: 0.011751365847885609\n",
      "Epoch 93, Loss: 0.011171814054250717\n",
      "Epoch 94, Loss: 0.015245810151100159\n",
      "Epoch 95, Loss: 0.005042941775172949\n",
      "Epoch 96, Loss: 0.017910348251461983\n",
      "Epoch 97, Loss: 0.011125962249934673\n",
      "Epoch 98, Loss: 0.004193316213786602\n",
      "Epoch 99, Loss: 0.016606394201517105\n",
      "Epoch 100, Loss: 0.006304342765361071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.365761160850525\n",
      "Epoch 1, Loss: 0.878000795841217\n",
      "Epoch 2, Loss: 0.5265030860900879\n",
      "Epoch 3, Loss: 0.7683092355728149\n",
      "Epoch 4, Loss: 0.5277339220046997\n",
      "Epoch 5, Loss: 0.47627460956573486\n",
      "Epoch 6, Loss: 0.8166701197624207\n",
      "Epoch 7, Loss: 0.2913782596588135\n",
      "Epoch 8, Loss: 0.3534047603607178\n",
      "Epoch 9, Loss: 0.36856693029403687\n",
      "Epoch 10, Loss: 0.682348370552063\n",
      "Epoch 11, Loss: 0.41190028190612793\n",
      "Epoch 12, Loss: 0.47462770342826843\n",
      "Epoch 13, Loss: 0.4296000003814697\n",
      "Epoch 14, Loss: 0.3159947693347931\n",
      "Epoch 15, Loss: 0.29886212944984436\n",
      "Epoch 16, Loss: 0.29093536734580994\n",
      "Epoch 17, Loss: 0.21168285608291626\n",
      "Epoch 18, Loss: 0.08623722195625305\n",
      "Epoch 19, Loss: 0.1576082408428192\n",
      "Epoch 20, Loss: 0.12164241820573807\n",
      "Epoch 21, Loss: 0.0886906310915947\n",
      "Epoch 22, Loss: 0.09134744852781296\n",
      "Epoch 23, Loss: 0.06520643085241318\n",
      "Epoch 24, Loss: 0.25496822595596313\n",
      "Epoch 25, Loss: 0.12068898230791092\n",
      "Epoch 26, Loss: 0.09464314579963684\n",
      "Epoch 27, Loss: 0.042939893901348114\n",
      "Epoch 28, Loss: 0.27306973934173584\n",
      "Epoch 29, Loss: 0.30962318181991577\n",
      "Epoch 30, Loss: 0.14704856276512146\n",
      "Epoch 31, Loss: 0.049167826771736145\n",
      "Epoch 32, Loss: 0.11348879337310791\n",
      "Epoch 33, Loss: 0.09011659026145935\n",
      "Epoch 34, Loss: 0.08984199166297913\n",
      "Epoch 35, Loss: 0.07623690366744995\n",
      "Epoch 36, Loss: 0.03288725018501282\n",
      "Epoch 37, Loss: 0.10720925778150558\n",
      "Epoch 38, Loss: 0.037617865949869156\n",
      "Epoch 39, Loss: 0.08148986101150513\n",
      "Epoch 40, Loss: 0.06581605970859528\n",
      "Epoch 41, Loss: 0.024415701627731323\n",
      "Epoch 42, Loss: 0.05267627537250519\n",
      "Epoch 43, Loss: 0.030705757439136505\n",
      "Epoch 44, Loss: 0.030753254890441895\n",
      "Epoch 45, Loss: 0.07894343882799149\n",
      "Epoch 46, Loss: 0.032649166882038116\n",
      "Epoch 47, Loss: 0.023990856483578682\n",
      "Epoch 48, Loss: 0.04555010795593262\n",
      "Epoch 49, Loss: 0.05165271461009979\n",
      "Epoch 50, Loss: 0.01276282500475645\n",
      "Epoch 51, Loss: 0.028480887413024902\n",
      "Epoch 52, Loss: 0.03305025398731232\n",
      "Epoch 53, Loss: 0.025507010519504547\n",
      "Epoch 54, Loss: 0.02630574256181717\n",
      "Epoch 55, Loss: 0.0282121691852808\n",
      "Epoch 56, Loss: 0.012869500555098057\n",
      "Epoch 57, Loss: 0.02105323225259781\n",
      "Epoch 58, Loss: 0.01138720940798521\n",
      "Epoch 59, Loss: 0.014049447141587734\n",
      "Epoch 60, Loss: 0.025043262168765068\n",
      "Epoch 61, Loss: 0.020031876862049103\n",
      "Epoch 62, Loss: 0.018227998167276382\n",
      "Epoch 63, Loss: 0.008874171413481236\n",
      "Epoch 64, Loss: 0.03554878383874893\n",
      "Epoch 65, Loss: 0.012163975276052952\n",
      "Epoch 66, Loss: 0.008650971576571465\n",
      "Epoch 67, Loss: 0.013562841340899467\n",
      "Epoch 68, Loss: 0.02688869833946228\n",
      "Epoch 69, Loss: 0.022145114839076996\n",
      "Epoch 70, Loss: 0.02290169522166252\n",
      "Epoch 71, Loss: 0.02545500546693802\n",
      "Epoch 72, Loss: 0.07711493968963623\n",
      "Epoch 73, Loss: 0.015220963396131992\n",
      "Epoch 74, Loss: 0.012002848088741302\n",
      "Epoch 75, Loss: 0.008124490268528461\n",
      "Epoch 76, Loss: 0.057985611259937286\n",
      "Epoch 77, Loss: 0.0054384199902415276\n",
      "Epoch 78, Loss: 0.011353736743330956\n",
      "Epoch 79, Loss: 0.008834309875965118\n",
      "Epoch 80, Loss: 0.012380358763039112\n",
      "Epoch 81, Loss: 0.013503560796380043\n",
      "Epoch 82, Loss: 0.026050111278891563\n",
      "Epoch 83, Loss: 0.005185945425182581\n",
      "Epoch 84, Loss: 0.01291542500257492\n",
      "Epoch 85, Loss: 0.015397904440760612\n",
      "Epoch 86, Loss: 0.017193712294101715\n",
      "Epoch 87, Loss: 0.0032348064705729485\n",
      "Epoch 88, Loss: 0.007053064182400703\n",
      "Epoch 89, Loss: 0.008204234763979912\n",
      "Epoch 90, Loss: 0.008726390078663826\n",
      "Epoch 91, Loss: 0.012875731103122234\n",
      "Epoch 92, Loss: 0.015845073387026787\n",
      "Epoch 93, Loss: 0.009198259562253952\n",
      "Epoch 94, Loss: 0.012989431619644165\n",
      "Epoch 95, Loss: 0.008051712065935135\n",
      "Epoch 96, Loss: 0.009058680385351181\n",
      "Epoch 97, Loss: 0.008336770348250866\n",
      "Epoch 98, Loss: 0.005377922207117081\n",
      "Epoch 99, Loss: 0.008103814907371998\n",
      "Epoch 100, Loss: 0.008254822343587875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.39149010181427\n",
      "Epoch 1, Loss: 0.25605231523513794\n",
      "Epoch 2, Loss: 0.4296939969062805\n",
      "Epoch 3, Loss: 0.36448240280151367\n",
      "Epoch 4, Loss: 0.734607458114624\n",
      "Epoch 5, Loss: 0.35903090238571167\n",
      "Epoch 6, Loss: 0.570366621017456\n",
      "Epoch 7, Loss: 0.6113941669464111\n",
      "Epoch 8, Loss: 0.42557984590530396\n",
      "Epoch 9, Loss: 0.2911355197429657\n",
      "Epoch 10, Loss: 0.2098625749349594\n",
      "Epoch 11, Loss: 0.17675605416297913\n",
      "Epoch 12, Loss: 0.4018893241882324\n",
      "Epoch 13, Loss: 0.1983625590801239\n",
      "Epoch 14, Loss: 0.5276192426681519\n",
      "Epoch 15, Loss: 0.1948801577091217\n",
      "Epoch 16, Loss: 0.3449307978153229\n",
      "Epoch 17, Loss: 0.16049128770828247\n",
      "Epoch 18, Loss: 0.1349383443593979\n",
      "Epoch 19, Loss: 0.23054289817810059\n",
      "Epoch 20, Loss: 0.1526758074760437\n",
      "Epoch 21, Loss: 0.1584945023059845\n",
      "Epoch 22, Loss: 0.2613946497440338\n",
      "Epoch 23, Loss: 0.11516211926937103\n",
      "Epoch 24, Loss: 0.12852448225021362\n",
      "Epoch 25, Loss: 0.08405265212059021\n",
      "Epoch 26, Loss: 0.16004948318004608\n",
      "Epoch 27, Loss: 0.06837433576583862\n",
      "Epoch 28, Loss: 0.11412099748849869\n",
      "Epoch 29, Loss: 0.040725648403167725\n",
      "Epoch 30, Loss: 0.027017898857593536\n",
      "Epoch 31, Loss: 0.13212427496910095\n",
      "Epoch 32, Loss: 0.09927120804786682\n",
      "Epoch 33, Loss: 0.04424884915351868\n",
      "Epoch 34, Loss: 0.046136148273944855\n",
      "Epoch 35, Loss: 0.10992447286844254\n",
      "Epoch 36, Loss: 0.07732588797807693\n",
      "Epoch 37, Loss: 0.07842680811882019\n",
      "Epoch 38, Loss: 0.04740768298506737\n",
      "Epoch 39, Loss: 0.05655466020107269\n",
      "Epoch 40, Loss: 0.13044916093349457\n",
      "Epoch 41, Loss: 0.1069365069270134\n",
      "Epoch 42, Loss: 0.05641241744160652\n",
      "Epoch 43, Loss: 0.08022034913301468\n",
      "Epoch 44, Loss: 0.050652436912059784\n",
      "Epoch 45, Loss: 0.03721220791339874\n",
      "Epoch 46, Loss: 0.017489181831479073\n",
      "Epoch 47, Loss: 0.04564361646771431\n",
      "Epoch 48, Loss: 0.05879415571689606\n",
      "Epoch 49, Loss: 0.021505417302250862\n",
      "Epoch 50, Loss: 0.04380595684051514\n",
      "Epoch 51, Loss: 0.012199457734823227\n",
      "Epoch 52, Loss: 0.0240472424775362\n",
      "Epoch 53, Loss: 0.04698628932237625\n",
      "Epoch 54, Loss: 0.03795639052987099\n",
      "Epoch 55, Loss: 0.021635781973600388\n",
      "Epoch 56, Loss: 0.01921735517680645\n",
      "Epoch 57, Loss: 0.012314720079302788\n",
      "Epoch 58, Loss: 0.019646214321255684\n",
      "Epoch 59, Loss: 0.012581687420606613\n",
      "Epoch 60, Loss: 0.020798731595277786\n",
      "Epoch 61, Loss: 0.0211747195571661\n",
      "Epoch 62, Loss: 0.01650290936231613\n",
      "Epoch 63, Loss: 0.014911343343555927\n",
      "Epoch 64, Loss: 0.0143427150323987\n",
      "Epoch 65, Loss: 0.01869245432317257\n",
      "Epoch 66, Loss: 0.019811278209090233\n",
      "Epoch 67, Loss: 0.016844937577843666\n",
      "Epoch 68, Loss: 0.03453175723552704\n",
      "Epoch 69, Loss: 0.008043079636991024\n",
      "Epoch 70, Loss: 0.01651984080672264\n",
      "Epoch 71, Loss: 0.027658559381961823\n",
      "Epoch 72, Loss: 0.01533125713467598\n",
      "Epoch 73, Loss: 0.01940690167248249\n",
      "Epoch 74, Loss: 0.007388988509774208\n",
      "Epoch 75, Loss: 0.012204374186694622\n",
      "Epoch 76, Loss: 0.0110895074903965\n",
      "Epoch 77, Loss: 0.023462677374482155\n",
      "Epoch 78, Loss: 0.006660179700702429\n",
      "Epoch 79, Loss: 0.008297605440020561\n",
      "Epoch 80, Loss: 0.008338991552591324\n",
      "Epoch 81, Loss: 0.009820542298257351\n",
      "Epoch 82, Loss: 0.008570201694965363\n",
      "Epoch 83, Loss: 0.008296379819512367\n",
      "Epoch 84, Loss: 0.015052780508995056\n",
      "Epoch 85, Loss: 0.013477344065904617\n",
      "Epoch 86, Loss: 0.008217258378863335\n",
      "Epoch 87, Loss: 0.008773934096097946\n",
      "Epoch 88, Loss: 0.01690196990966797\n",
      "Epoch 89, Loss: 0.013519096188247204\n",
      "Epoch 90, Loss: 0.009149198420345783\n",
      "Epoch 91, Loss: 0.023013543337583542\n",
      "Epoch 92, Loss: 0.005858518648892641\n",
      "Epoch 93, Loss: 0.011011707596480846\n",
      "Epoch 94, Loss: 0.0063451603055000305\n",
      "Epoch 95, Loss: 0.012738163582980633\n",
      "Epoch 96, Loss: 0.007458960637450218\n",
      "Epoch 97, Loss: 0.011874391697347164\n",
      "Epoch 98, Loss: 0.010088675655424595\n",
      "Epoch 99, Loss: 0.015203320421278477\n",
      "Epoch 100, Loss: 0.010703420266509056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.402941346168518\n",
      "Epoch 1, Loss: 0.39614108204841614\n",
      "Epoch 2, Loss: 0.6875183582305908\n",
      "Epoch 3, Loss: 0.586607038974762\n",
      "Epoch 4, Loss: 0.3815087080001831\n",
      "Epoch 5, Loss: 0.33371227979660034\n",
      "Epoch 6, Loss: 0.41080430150032043\n",
      "Epoch 7, Loss: 0.5007199048995972\n",
      "Epoch 8, Loss: 0.6437429189682007\n",
      "Epoch 9, Loss: 0.2462354451417923\n",
      "Epoch 10, Loss: 0.2937825620174408\n",
      "Epoch 11, Loss: 0.2751990556716919\n",
      "Epoch 12, Loss: 0.2853049337863922\n",
      "Epoch 13, Loss: 0.15384386479854584\n",
      "Epoch 14, Loss: 0.13078573346138\n",
      "Epoch 15, Loss: 0.21310995519161224\n",
      "Epoch 16, Loss: 0.250190794467926\n",
      "Epoch 17, Loss: 0.30217450857162476\n",
      "Epoch 18, Loss: 0.24145038425922394\n",
      "Epoch 19, Loss: 0.15943920612335205\n",
      "Epoch 20, Loss: 0.15430773794651031\n",
      "Epoch 21, Loss: 0.07109335064888\n",
      "Epoch 22, Loss: 0.33592066168785095\n",
      "Epoch 23, Loss: 0.103173166513443\n",
      "Epoch 24, Loss: 0.11787822842597961\n",
      "Epoch 25, Loss: 0.06686153262853622\n",
      "Epoch 26, Loss: 0.07195128500461578\n",
      "Epoch 27, Loss: 0.12518830597400665\n",
      "Epoch 28, Loss: 0.08740939199924469\n",
      "Epoch 29, Loss: 0.08237994462251663\n",
      "Epoch 30, Loss: 0.0827382355928421\n",
      "Epoch 31, Loss: 0.15893243253231049\n",
      "Epoch 32, Loss: 0.030414428561925888\n",
      "Epoch 33, Loss: 0.05008820444345474\n",
      "Epoch 34, Loss: 0.11414310336112976\n",
      "Epoch 35, Loss: 0.09173067659139633\n",
      "Epoch 36, Loss: 0.1102970615029335\n",
      "Epoch 37, Loss: 0.03503809869289398\n",
      "Epoch 38, Loss: 0.06330132484436035\n",
      "Epoch 39, Loss: 0.028029905632138252\n",
      "Epoch 40, Loss: 0.05277611315250397\n",
      "Epoch 41, Loss: 0.04265175014734268\n",
      "Epoch 42, Loss: 0.04599258676171303\n",
      "Epoch 43, Loss: 0.08354104310274124\n",
      "Epoch 44, Loss: 0.03693187236785889\n",
      "Epoch 45, Loss: 0.040252842009067535\n",
      "Epoch 46, Loss: 0.030234400182962418\n",
      "Epoch 47, Loss: 0.04691578820347786\n",
      "Epoch 48, Loss: 0.020240459591150284\n",
      "Epoch 49, Loss: 0.025848839432001114\n",
      "Epoch 50, Loss: 0.014935718849301338\n",
      "Epoch 51, Loss: 0.012068280950188637\n",
      "Epoch 52, Loss: 0.05014440417289734\n",
      "Epoch 53, Loss: 0.01908864825963974\n",
      "Epoch 54, Loss: 0.01984102837741375\n",
      "Epoch 55, Loss: 0.016404276713728905\n",
      "Epoch 56, Loss: 0.028079310432076454\n",
      "Epoch 57, Loss: 0.028485605493187904\n",
      "Epoch 58, Loss: 0.026090247556567192\n",
      "Epoch 59, Loss: 0.014110056683421135\n",
      "Epoch 60, Loss: 0.017951074987649918\n",
      "Epoch 61, Loss: 0.010392559692263603\n",
      "Epoch 62, Loss: 0.0296647846698761\n",
      "Epoch 63, Loss: 0.015122128650546074\n",
      "Epoch 64, Loss: 0.016474628821015358\n",
      "Epoch 65, Loss: 0.006895572412759066\n",
      "Epoch 66, Loss: 0.022021546959877014\n",
      "Epoch 67, Loss: 0.024118397384881973\n",
      "Epoch 68, Loss: 0.013200542889535427\n",
      "Epoch 69, Loss: 0.010040023364126682\n",
      "Epoch 70, Loss: 0.02597285434603691\n",
      "Epoch 71, Loss: 0.036998555064201355\n",
      "Epoch 72, Loss: 0.01359229814261198\n",
      "Epoch 73, Loss: 0.009625781327486038\n",
      "Epoch 74, Loss: 0.017878897488117218\n",
      "Epoch 75, Loss: 0.024864736944437027\n",
      "Epoch 76, Loss: 0.005871409550309181\n",
      "Epoch 77, Loss: 0.008788752369582653\n",
      "Epoch 78, Loss: 0.026394424960017204\n",
      "Epoch 79, Loss: 0.010680426843464375\n",
      "Epoch 80, Loss: 0.019053636118769646\n",
      "Epoch 81, Loss: 0.013136419467628002\n",
      "Epoch 82, Loss: 0.005460597574710846\n",
      "Epoch 83, Loss: 0.006505018100142479\n",
      "Epoch 84, Loss: 0.006157519295811653\n",
      "Epoch 85, Loss: 0.017462391406297684\n",
      "Epoch 86, Loss: 0.030826006084680557\n",
      "Epoch 87, Loss: 0.009505581110715866\n",
      "Epoch 88, Loss: 0.01545494794845581\n",
      "Epoch 89, Loss: 0.011299132369458675\n",
      "Epoch 90, Loss: 0.012738817371428013\n",
      "Epoch 91, Loss: 0.02145427279174328\n",
      "Epoch 92, Loss: 0.003384955460205674\n",
      "Epoch 93, Loss: 0.017688436433672905\n",
      "Epoch 94, Loss: 0.00712157366797328\n",
      "Epoch 95, Loss: 0.007209308445453644\n",
      "Epoch 96, Loss: 0.013190514408051968\n",
      "Epoch 97, Loss: 0.00893313530832529\n",
      "Epoch 98, Loss: 0.012214290909469128\n",
      "Epoch 99, Loss: 0.01626412943005562\n",
      "Epoch 100, Loss: 0.004999789875000715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3525846004486084\n",
      "Epoch 1, Loss: 0.8870353698730469\n",
      "Epoch 2, Loss: 0.3728533685207367\n",
      "Epoch 3, Loss: 0.193613201379776\n",
      "Epoch 4, Loss: 0.32561036944389343\n",
      "Epoch 5, Loss: 0.455202579498291\n",
      "Epoch 6, Loss: 0.41795551776885986\n",
      "Epoch 7, Loss: 0.661933183670044\n",
      "Epoch 8, Loss: 0.42697668075561523\n",
      "Epoch 9, Loss: 0.48850277066230774\n",
      "Epoch 10, Loss: 0.2333625704050064\n",
      "Epoch 11, Loss: 0.3665298819541931\n",
      "Epoch 12, Loss: 0.35453253984451294\n",
      "Epoch 13, Loss: 0.26283717155456543\n",
      "Epoch 14, Loss: 0.25793689489364624\n",
      "Epoch 15, Loss: 0.08068695664405823\n",
      "Epoch 16, Loss: 0.24433939158916473\n",
      "Epoch 17, Loss: 0.18165744841098785\n",
      "Epoch 18, Loss: 0.14947295188903809\n",
      "Epoch 19, Loss: 0.15394452214241028\n",
      "Epoch 20, Loss: 0.1317923665046692\n",
      "Epoch 21, Loss: 0.09161461889743805\n",
      "Epoch 22, Loss: 0.23925818502902985\n",
      "Epoch 23, Loss: 0.14150679111480713\n",
      "Epoch 24, Loss: 0.11196684837341309\n",
      "Epoch 25, Loss: 0.0372147262096405\n",
      "Epoch 26, Loss: 0.07674889266490936\n",
      "Epoch 27, Loss: 0.14721159636974335\n",
      "Epoch 28, Loss: 0.11645260453224182\n",
      "Epoch 29, Loss: 0.08480812609195709\n",
      "Epoch 30, Loss: 0.09090873599052429\n",
      "Epoch 31, Loss: 0.14227141439914703\n",
      "Epoch 32, Loss: 0.04038379713892937\n",
      "Epoch 33, Loss: 0.04303865134716034\n",
      "Epoch 34, Loss: 0.2369789481163025\n",
      "Epoch 35, Loss: 0.07789338380098343\n",
      "Epoch 36, Loss: 0.04508700594305992\n",
      "Epoch 37, Loss: 0.045381464064121246\n",
      "Epoch 38, Loss: 0.11048606038093567\n",
      "Epoch 39, Loss: 0.05509299412369728\n",
      "Epoch 40, Loss: 0.051838550716638565\n",
      "Epoch 41, Loss: 0.07443230599164963\n",
      "Epoch 42, Loss: 0.08412961661815643\n",
      "Epoch 43, Loss: 0.039426449686288834\n",
      "Epoch 44, Loss: 0.040024951100349426\n",
      "Epoch 45, Loss: 0.031071458011865616\n",
      "Epoch 46, Loss: 0.03956111893057823\n",
      "Epoch 47, Loss: 0.0248993132263422\n",
      "Epoch 48, Loss: 0.03020424023270607\n",
      "Epoch 49, Loss: 0.039312198758125305\n",
      "Epoch 50, Loss: 0.040672555565834045\n",
      "Epoch 51, Loss: 0.0776863619685173\n",
      "Epoch 52, Loss: 0.05646026134490967\n",
      "Epoch 53, Loss: 0.03405849263072014\n",
      "Epoch 54, Loss: 0.008811529725790024\n",
      "Epoch 55, Loss: 0.021090859547257423\n",
      "Epoch 56, Loss: 0.01422677282243967\n",
      "Epoch 57, Loss: 0.02957591414451599\n",
      "Epoch 58, Loss: 0.01488602813333273\n",
      "Epoch 59, Loss: 0.019429810345172882\n",
      "Epoch 60, Loss: 0.029757507145404816\n",
      "Epoch 61, Loss: 0.021154848858714104\n",
      "Epoch 62, Loss: 0.027575405314564705\n",
      "Epoch 63, Loss: 0.01043790578842163\n",
      "Epoch 64, Loss: 0.021527837961912155\n",
      "Epoch 65, Loss: 0.01425646711140871\n",
      "Epoch 66, Loss: 0.01004884671419859\n",
      "Epoch 67, Loss: 0.037540122866630554\n",
      "Epoch 68, Loss: 0.011696195229887962\n",
      "Epoch 69, Loss: 0.0513022355735302\n",
      "Epoch 70, Loss: 0.011691833846271038\n",
      "Epoch 71, Loss: 0.014083772897720337\n",
      "Epoch 72, Loss: 0.021137341856956482\n",
      "Epoch 73, Loss: 0.02292376197874546\n",
      "Epoch 74, Loss: 0.012737561017274857\n",
      "Epoch 75, Loss: 0.01821737550199032\n",
      "Epoch 76, Loss: 0.01600269041955471\n",
      "Epoch 77, Loss: 0.013314958661794662\n",
      "Epoch 78, Loss: 0.011783328838646412\n",
      "Epoch 79, Loss: 0.01437884196639061\n",
      "Epoch 80, Loss: 0.012082844972610474\n",
      "Epoch 81, Loss: 0.017314070835709572\n",
      "Epoch 82, Loss: 0.006219780538231134\n",
      "Epoch 83, Loss: 0.006088519003242254\n",
      "Epoch 84, Loss: 0.04407484084367752\n",
      "Epoch 85, Loss: 0.005044214427471161\n",
      "Epoch 86, Loss: 0.0076467115432024\n",
      "Epoch 87, Loss: 0.007799821440130472\n",
      "Epoch 88, Loss: 0.004748162813484669\n",
      "Epoch 89, Loss: 0.009951218031346798\n",
      "Epoch 90, Loss: 0.012121474370360374\n",
      "Epoch 91, Loss: 0.007989191450178623\n",
      "Epoch 92, Loss: 0.006904100999236107\n",
      "Epoch 93, Loss: 0.006842171307653189\n",
      "Epoch 94, Loss: 0.006006268784403801\n",
      "Epoch 95, Loss: 0.015992507338523865\n",
      "Epoch 96, Loss: 0.005725630093365908\n",
      "Epoch 97, Loss: 0.016543198376893997\n",
      "Epoch 98, Loss: 0.009315635077655315\n",
      "Epoch 99, Loss: 0.007577699143439531\n",
      "Epoch 100, Loss: 0.007850738242268562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3963947296142578\n",
      "Epoch 1, Loss: 1.469306230545044\n",
      "Epoch 2, Loss: 0.49889421463012695\n",
      "Epoch 3, Loss: 0.48941659927368164\n",
      "Epoch 4, Loss: 0.2694894075393677\n",
      "Epoch 5, Loss: 0.5168073177337646\n",
      "Epoch 6, Loss: 0.582704484462738\n",
      "Epoch 7, Loss: 0.5716012120246887\n",
      "Epoch 8, Loss: 0.3939196467399597\n",
      "Epoch 9, Loss: 0.33442220091819763\n",
      "Epoch 10, Loss: 0.7385677695274353\n",
      "Epoch 11, Loss: 0.1917097419500351\n",
      "Epoch 12, Loss: 0.33988773822784424\n",
      "Epoch 13, Loss: 0.4373542368412018\n",
      "Epoch 14, Loss: 0.2432234287261963\n",
      "Epoch 15, Loss: 0.28664425015449524\n",
      "Epoch 16, Loss: 0.3379438817501068\n",
      "Epoch 17, Loss: 0.227464497089386\n",
      "Epoch 18, Loss: 0.19290253520011902\n",
      "Epoch 19, Loss: 0.15186600387096405\n",
      "Epoch 20, Loss: 0.1136399656534195\n",
      "Epoch 21, Loss: 0.16906313598155975\n",
      "Epoch 22, Loss: 0.12130134552717209\n",
      "Epoch 23, Loss: 0.17552119493484497\n",
      "Epoch 24, Loss: 0.04778626188635826\n",
      "Epoch 25, Loss: 0.17260640859603882\n",
      "Epoch 26, Loss: 0.181588813662529\n",
      "Epoch 27, Loss: 0.04933709651231766\n",
      "Epoch 28, Loss: 0.12176202237606049\n",
      "Epoch 29, Loss: 0.20543113350868225\n",
      "Epoch 30, Loss: 0.0614740327000618\n",
      "Epoch 31, Loss: 0.08638155460357666\n",
      "Epoch 32, Loss: 0.028223775327205658\n",
      "Epoch 33, Loss: 0.038042161613702774\n",
      "Epoch 34, Loss: 0.05608063191175461\n",
      "Epoch 35, Loss: 0.043701205402612686\n",
      "Epoch 36, Loss: 0.09729649126529694\n",
      "Epoch 37, Loss: 0.0769740641117096\n",
      "Epoch 38, Loss: 0.03707543760538101\n",
      "Epoch 39, Loss: 0.08699676394462585\n",
      "Epoch 40, Loss: 0.05797735974192619\n",
      "Epoch 41, Loss: 0.03580636531114578\n",
      "Epoch 42, Loss: 0.04149385914206505\n",
      "Epoch 43, Loss: 0.051960431039333344\n",
      "Epoch 44, Loss: 0.0908171683549881\n",
      "Epoch 45, Loss: 0.06846672296524048\n",
      "Epoch 46, Loss: 0.06151707470417023\n",
      "Epoch 47, Loss: 0.10169967263936996\n",
      "Epoch 48, Loss: 0.023838993161916733\n",
      "Epoch 49, Loss: 0.03226400911808014\n",
      "Epoch 50, Loss: 0.020851800218224525\n",
      "Epoch 51, Loss: 0.0333687923848629\n",
      "Epoch 52, Loss: 0.03402097523212433\n",
      "Epoch 53, Loss: 0.010356379672884941\n",
      "Epoch 54, Loss: 0.02217809483408928\n",
      "Epoch 55, Loss: 0.008225355297327042\n",
      "Epoch 56, Loss: 0.039473701268434525\n",
      "Epoch 57, Loss: 0.04399697855114937\n",
      "Epoch 58, Loss: 0.02920234203338623\n",
      "Epoch 59, Loss: 0.019197966903448105\n",
      "Epoch 60, Loss: 0.10991760343313217\n",
      "Epoch 61, Loss: 0.039984602481126785\n",
      "Epoch 62, Loss: 0.01972089149057865\n",
      "Epoch 63, Loss: 0.035302747040987015\n",
      "Epoch 64, Loss: 0.009758025407791138\n",
      "Epoch 65, Loss: 0.01325913704931736\n",
      "Epoch 66, Loss: 0.015211678110063076\n",
      "Epoch 67, Loss: 0.022366885095834732\n",
      "Epoch 68, Loss: 0.012794830836355686\n",
      "Epoch 69, Loss: 0.024741139262914658\n",
      "Epoch 70, Loss: 0.0106029799208045\n",
      "Epoch 71, Loss: 0.011579307727515697\n",
      "Epoch 72, Loss: 0.005476837512105703\n",
      "Epoch 73, Loss: 0.013668235391378403\n",
      "Epoch 74, Loss: 0.010023190639913082\n",
      "Epoch 75, Loss: 0.014462634921073914\n",
      "Epoch 76, Loss: 0.012960576452314854\n",
      "Epoch 77, Loss: 0.038653112947940826\n",
      "Epoch 78, Loss: 0.016240911558270454\n",
      "Epoch 79, Loss: 0.016549136489629745\n",
      "Epoch 80, Loss: 0.02729426696896553\n",
      "Epoch 81, Loss: 0.018263371661305428\n",
      "Epoch 82, Loss: 0.008475623093545437\n",
      "Epoch 83, Loss: 0.020747503265738487\n",
      "Epoch 84, Loss: 0.025194426998496056\n",
      "Epoch 85, Loss: 0.05569010227918625\n",
      "Epoch 86, Loss: 0.004380105063319206\n",
      "Epoch 87, Loss: 0.007129686418920755\n",
      "Epoch 88, Loss: 0.005131374578922987\n",
      "Epoch 89, Loss: 0.004946250002831221\n",
      "Epoch 90, Loss: 0.009897639974951744\n",
      "Epoch 91, Loss: 0.00856463611125946\n",
      "Epoch 92, Loss: 0.023894263431429863\n",
      "Epoch 93, Loss: 0.009046114049851894\n",
      "Epoch 94, Loss: 0.0039685387164354324\n",
      "Epoch 95, Loss: 0.010174443013966084\n",
      "Epoch 96, Loss: 0.0321650356054306\n",
      "Epoch 97, Loss: 0.00602052453905344\n",
      "Epoch 98, Loss: 0.008013523183763027\n",
      "Epoch 99, Loss: 0.014226878993213177\n",
      "Epoch 100, Loss: 0.0057977344840765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.3045504093170166\n",
      "Epoch 1, Loss: 1.2362384796142578\n",
      "Epoch 2, Loss: 0.7244035601615906\n",
      "Epoch 3, Loss: 0.46132707595825195\n",
      "Epoch 4, Loss: 0.540290355682373\n",
      "Epoch 5, Loss: 0.9513465166091919\n",
      "Epoch 6, Loss: 0.47494077682495117\n",
      "Epoch 7, Loss: 0.3685254156589508\n",
      "Epoch 8, Loss: 0.41566038131713867\n",
      "Epoch 9, Loss: 0.5279117822647095\n",
      "Epoch 10, Loss: 0.4474746286869049\n",
      "Epoch 11, Loss: 0.290412575006485\n",
      "Epoch 12, Loss: 0.3311861455440521\n",
      "Epoch 13, Loss: 0.25327619910240173\n",
      "Epoch 14, Loss: 0.39427462220191956\n",
      "Epoch 15, Loss: 0.2681940793991089\n",
      "Epoch 16, Loss: 0.28249889612197876\n",
      "Epoch 17, Loss: 0.35747772455215454\n",
      "Epoch 18, Loss: 0.21289615333080292\n",
      "Epoch 19, Loss: 0.15357369184494019\n",
      "Epoch 20, Loss: 0.14895141124725342\n",
      "Epoch 21, Loss: 0.1878017783164978\n",
      "Epoch 22, Loss: 0.309478223323822\n",
      "Epoch 23, Loss: 0.11718077212572098\n",
      "Epoch 24, Loss: 0.20706002414226532\n",
      "Epoch 25, Loss: 0.07358602434396744\n",
      "Epoch 26, Loss: 0.10857158899307251\n",
      "Epoch 27, Loss: 0.10584259778261185\n",
      "Epoch 28, Loss: 0.06858301162719727\n",
      "Epoch 29, Loss: 0.1391209214925766\n",
      "Epoch 30, Loss: 0.0991869643330574\n",
      "Epoch 31, Loss: 0.11145159602165222\n",
      "Epoch 32, Loss: 0.09327482432126999\n",
      "Epoch 33, Loss: 0.09784940630197525\n",
      "Epoch 34, Loss: 0.03292250633239746\n",
      "Epoch 35, Loss: 0.06414519250392914\n",
      "Epoch 36, Loss: 0.05990197882056236\n",
      "Epoch 37, Loss: 0.04329575598239899\n",
      "Epoch 38, Loss: 0.10689195245504379\n",
      "Epoch 39, Loss: 0.04768194258213043\n",
      "Epoch 40, Loss: 0.09524939954280853\n",
      "Epoch 41, Loss: 0.08069213479757309\n",
      "Epoch 42, Loss: 0.032859232276678085\n",
      "Epoch 43, Loss: 0.04038766026496887\n",
      "Epoch 44, Loss: 0.026725446805357933\n",
      "Epoch 45, Loss: 0.03579922020435333\n",
      "Epoch 46, Loss: 0.04788239300251007\n",
      "Epoch 47, Loss: 0.02341454289853573\n",
      "Epoch 48, Loss: 0.01835278607904911\n",
      "Epoch 49, Loss: 0.02576877921819687\n",
      "Epoch 50, Loss: 0.09149660170078278\n",
      "Epoch 51, Loss: 0.022650204598903656\n",
      "Epoch 52, Loss: 0.02098451927304268\n",
      "Epoch 53, Loss: 0.031336333602666855\n",
      "Epoch 54, Loss: 0.019450927153229713\n",
      "Epoch 55, Loss: 0.015714291483163834\n",
      "Epoch 56, Loss: 0.01575758308172226\n",
      "Epoch 57, Loss: 0.01847965270280838\n",
      "Epoch 58, Loss: 0.0224464014172554\n",
      "Epoch 59, Loss: 0.01325217168778181\n",
      "Epoch 60, Loss: 0.028463343158364296\n",
      "Epoch 61, Loss: 0.03137337416410446\n",
      "Epoch 62, Loss: 0.022991547361016273\n",
      "Epoch 63, Loss: 0.021120227873325348\n",
      "Epoch 64, Loss: 0.00967388041317463\n",
      "Epoch 65, Loss: 0.02666749805212021\n",
      "Epoch 66, Loss: 0.017184607684612274\n",
      "Epoch 67, Loss: 0.007026084698736668\n",
      "Epoch 68, Loss: 0.013136382214725018\n",
      "Epoch 69, Loss: 0.013488423079252243\n",
      "Epoch 70, Loss: 0.009818668477237225\n",
      "Epoch 71, Loss: 0.024548862129449844\n",
      "Epoch 72, Loss: 0.009674187749624252\n",
      "Epoch 73, Loss: 0.014514465816318989\n",
      "Epoch 74, Loss: 0.009028198197484016\n",
      "Epoch 75, Loss: 0.019220732152462006\n",
      "Epoch 76, Loss: 0.025315113365650177\n",
      "Epoch 77, Loss: 0.012995459139347076\n",
      "Epoch 78, Loss: 0.009503081440925598\n",
      "Epoch 79, Loss: 0.01774708740413189\n",
      "Epoch 80, Loss: 0.008487473241984844\n",
      "Epoch 81, Loss: 0.010312175378203392\n",
      "Epoch 82, Loss: 0.009944310411810875\n",
      "Epoch 83, Loss: 0.014309646561741829\n",
      "Epoch 84, Loss: 0.01022327970713377\n",
      "Epoch 85, Loss: 0.006650005001574755\n",
      "Epoch 86, Loss: 0.008769351057708263\n",
      "Epoch 87, Loss: 0.01901729218661785\n",
      "Epoch 88, Loss: 0.029740989208221436\n",
      "Epoch 89, Loss: 0.007547495421022177\n",
      "Epoch 90, Loss: 0.013830738142132759\n",
      "Epoch 91, Loss: 0.008142882958054543\n",
      "Epoch 92, Loss: 0.009143928997218609\n",
      "Epoch 93, Loss: 0.008396759629249573\n",
      "Epoch 94, Loss: 0.014317682944238186\n",
      "Epoch 95, Loss: 0.012680886313319206\n",
      "Epoch 96, Loss: 0.01162034086883068\n",
      "Epoch 97, Loss: 0.016155250370502472\n",
      "Epoch 98, Loss: 0.007737461011856794\n",
      "Epoch 99, Loss: 0.01289556734263897\n",
      "Epoch 100, Loss: 0.005921534728258848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34557/3279920816.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['PREDICT'] = preds\n",
      "/tmp/ipykernel_34557/1230091744.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
      "/tmp/ipykernel_34557/2629181029.py:39: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  torch.tensor(self.residence_time_min[idx], dtype=torch.long),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.5071858167648315\n",
      "Epoch 1, Loss: 0.6851193904876709\n",
      "Epoch 2, Loss: 0.3280254602432251\n",
      "Epoch 3, Loss: 0.5493683218955994\n",
      "Epoch 4, Loss: 0.628749430179596\n",
      "Epoch 5, Loss: 0.41169437766075134\n",
      "Epoch 6, Loss: 0.3979223966598511\n",
      "Epoch 7, Loss: 0.38217893242836\n",
      "Epoch 8, Loss: 0.23852556943893433\n",
      "Epoch 9, Loss: 0.15513044595718384\n",
      "Epoch 10, Loss: 0.18172889947891235\n",
      "Epoch 11, Loss: 0.2754479646682739\n",
      "Epoch 12, Loss: 0.133155956864357\n",
      "Epoch 13, Loss: 0.13039261102676392\n",
      "Epoch 14, Loss: 0.3753012418746948\n",
      "Epoch 15, Loss: 0.2052554041147232\n",
      "Epoch 16, Loss: 0.24757780134677887\n",
      "Epoch 17, Loss: 0.08192163705825806\n",
      "Epoch 18, Loss: 0.19813016057014465\n",
      "Epoch 19, Loss: 0.20780760049819946\n",
      "Epoch 20, Loss: 0.26126420497894287\n",
      "Epoch 21, Loss: 0.3231087327003479\n",
      "Epoch 22, Loss: 0.1102854385972023\n",
      "Epoch 23, Loss: 0.20712517201900482\n",
      "Epoch 24, Loss: 0.20574702322483063\n",
      "Epoch 25, Loss: 0.27417615056037903\n",
      "Epoch 26, Loss: 0.15102458000183105\n",
      "Epoch 27, Loss: 0.0869087278842926\n",
      "Epoch 28, Loss: 0.044535282999277115\n",
      "Epoch 29, Loss: 0.17655757069587708\n",
      "Epoch 30, Loss: 0.1068834736943245\n",
      "Epoch 31, Loss: 0.11102551221847534\n",
      "Epoch 32, Loss: 0.02268223837018013\n",
      "Epoch 33, Loss: 0.031928595155477524\n",
      "Epoch 34, Loss: 0.05958902835845947\n",
      "Epoch 35, Loss: 0.045239370316267014\n",
      "Epoch 36, Loss: 0.06187525764107704\n",
      "Epoch 37, Loss: 0.10290592908859253\n",
      "Epoch 38, Loss: 0.037739865481853485\n",
      "Epoch 39, Loss: 0.08123055100440979\n",
      "Epoch 40, Loss: 0.05997844412922859\n",
      "Epoch 41, Loss: 0.05063442513346672\n",
      "Epoch 42, Loss: 0.026898963376879692\n",
      "Epoch 43, Loss: 0.07130806148052216\n",
      "Epoch 44, Loss: 0.038817524909973145\n",
      "Epoch 45, Loss: 0.06138597056269646\n",
      "Epoch 46, Loss: 0.05449635908007622\n",
      "Epoch 47, Loss: 0.04899497702717781\n",
      "Epoch 48, Loss: 0.03483302891254425\n",
      "Epoch 49, Loss: 0.019145242869853973\n",
      "Epoch 50, Loss: 0.01429660152643919\n",
      "Epoch 51, Loss: 0.029671523720026016\n",
      "Epoch 52, Loss: 0.015505288727581501\n",
      "Epoch 53, Loss: 0.021067291498184204\n",
      "Epoch 54, Loss: 0.021213676780462265\n",
      "Epoch 55, Loss: 0.022435132414102554\n",
      "Epoch 56, Loss: 0.04571281000971794\n",
      "Epoch 57, Loss: 0.015361805446445942\n",
      "Epoch 58, Loss: 0.012064298614859581\n",
      "Epoch 59, Loss: 0.01676388457417488\n",
      "Epoch 60, Loss: 0.019972119480371475\n",
      "Epoch 61, Loss: 0.3696141541004181\n",
      "Epoch 62, Loss: 0.03772756829857826\n",
      "Epoch 63, Loss: 0.050662215799093246\n",
      "Epoch 64, Loss: 0.013569856062531471\n",
      "Epoch 65, Loss: 0.03227489814162254\n",
      "Epoch 66, Loss: 0.01999904029071331\n",
      "Epoch 67, Loss: 0.012914512306451797\n",
      "Epoch 68, Loss: 0.013529310934245586\n",
      "Epoch 69, Loss: 0.012263580225408077\n",
      "Epoch 70, Loss: 0.01395343616604805\n",
      "Epoch 71, Loss: 0.016972530633211136\n"
     ]
    }
   ],
   "source": [
    "# 결과를 저장할 DataFrame 초기화\n",
    "random_search_results_df = pd.DataFrame(columns=['w1', 'w2', 'w3', 'mse'])\n",
    "\n",
    "best_mse = float('inf')\n",
    "best_weights = None\n",
    "\n",
    "# Random Search 설정\n",
    "iterations = 100  # 탐색을 수행할 반복 횟수\n",
    "\n",
    "for _ in range(iterations):\n",
    "    # 가중치를 무작위로 선택 (합이 1이 되도록 조정)\n",
    "    w1 = random.random()\n",
    "    w2 = random.random() * (1 - w1)\n",
    "    w3 = 1 - w1 - w2\n",
    "    \n",
    "    # 새로운 SCORE 계산\n",
    "    df['SCORE'] = w1 * df['DGSTFN'] + w2 * df['REVISIT_INTENTION'] + w3 * df['RCMDTN_INTENTION']\n",
    "    #df_test['SCORE'] = w1 * df_test['DGSTFN'] + w2 * df_test['REVISIT_INTENTION'] + w3 * df_test['RCMDTN_INTENTION']\n",
    "    \n",
    "    # Train-test 분할 (실제 df 사용)\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train, Test 데이터셋으로 TravelDataset 인스턴스 생성\n",
    "    train_dataset = TravelDataset(train_df)\n",
    "    test_dataset = TravelDataset(test_df)\n",
    "\n",
    "    # DataLoader 설정\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    num_users = df['TRAVELER_ID'].nunique()\n",
    "    num_items = df['VISIT_AREA_NM'].nunique()\n",
    "    num_sido = df['SIDO'].nunique()\n",
    "    num_gungu = df['GUNGU'].nunique()\n",
    "    num_travel_mission_priority = df['TRAVEL_MISSION_PRIORITY'].nunique()\n",
    "    num_age_grp = df['AGE_GRP'].nunique()\n",
    "    num_income = df['INCOME'].nunique()\n",
    "    num_style1 = df['TRAVEL_STYL_1'].nunique()\n",
    "    num_style2 = df['TRAVEL_STYL_2'].nunique()\n",
    "    num_style3 = df['TRAVEL_STYL_3'].nunique()\n",
    "    num_style4 = df['TRAVEL_STYL_4'].nunique()\n",
    "    num_style5 = df['TRAVEL_STYL_5'].nunique()\n",
    "    num_style6 = df['TRAVEL_STYL_6'].nunique()\n",
    "    num_style7 = df['TRAVEL_STYL_7'].nunique()\n",
    "    num_style8 = df['TRAVEL_STYL_8'].nunique()\n",
    "    num_motive = df['TRAVEL_MOTIVE_1'].nunique()\n",
    "    embed_size = 16  # 임베딩 크기 설정\n",
    "    \n",
    "    # 모델 인스턴스 생성\n",
    "    model = NCF(\n",
    "        num_users=num_users, num_items=num_items, \n",
    "        num_sido=num_sido, num_gungu=num_gungu, \n",
    "        num_travel_mission_priority=num_travel_mission_priority, \n",
    "        num_age_grp=num_age_grp, num_income=num_income,\n",
    "        num_style1=num_style1, num_style2=num_style2, num_style3=num_style3, \n",
    "        num_style4=num_style4, num_style5=num_style5, num_style6=num_style6, \n",
    "        num_style7=num_style7, num_style8=num_style8, num_motive=num_motive, \n",
    "        embed_size=embed_size\n",
    "    )\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    train(train_dataloader, optimizer, model, criterion)\n",
    "    mse = test(test_dataloader, model)\n",
    "    \n",
    "    random_search_results_df = random_search_results_df.append({'w1': w1, 'w2': w2, 'w3': w3, 'mse': mse}, ignore_index=True)\n",
    "    \n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_weights = (w1, w2, w3)\n",
    "    \n",
    "\n",
    "# DataFrame을 CSV 파일로 저장\n",
    "random_search_results_df.to_csv('random_search_cf.csv', index=False)\n",
    "\n",
    "# 최적의 MSE와 가중치 출력\n",
    "print(f\"Best MSE: {best_mse}\")\n",
    "print(f\"Best weights: w1={best_weights[0]}, w2={best_weights[1]}, w3={best_weights[2]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54dd6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# 모델에서 사용자 임베딩 레이어 추출\n",
    "user_embeddings = model.user_embed.weight.data.numpy()\n",
    "\n",
    "# 모든 사용자 간의 코사인 유사도 계산\n",
    "similarity_matrix = cosine_similarity(user_embeddings)\n",
    "\n",
    "# 특정 사용자 ID에 대한 유사도 점수 검색 (예: 0번 사용자)\n",
    "# 사용자 ID와 그에 해당하는 숫자 인덱스 매핑 생성\n",
    "user_id_to_index = {user_id: index for index, user_id in enumerate(df['TRAVELER_ID'].astype('category').cat.categories)}\n",
    "index_to_user_id = {index: user_id for index, user_id in enumerate(df['TRAVELER_ID'].astype('category').cat.categories)}\n",
    "\n",
    "# 문자열 사용자 ID를 숫자 인덱스로 변환\n",
    "id = 'a015688'\n",
    "user_index = user_id_to_index[id]\n",
    "user_similarity_scores = similarity_matrix[user_index]\n",
    "\n",
    "# 자기 자신을 제외한 가장 유사한 사용자 상위 N명 찾기\n",
    "top_n_indices = np.argsort(user_similarity_scores)[::-1][1:6]  # 자기 자신을 제외하고 상위 5명\n",
    "\n",
    "# 숫자 인덱스를 사용자 ID로 변환\n",
    "top_n_user_ids = [index_to_user_id[i] for i in top_n_indices]\n",
    "\n",
    "print(f\"사용자 a015688와 가장 유사한 사용자 ID:\", top_n_user_ids)\n",
    "print(\"유사도 점수:\", user_similarity_scores[top_n_indices])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.13 (NGC 22.05/Python 3.8 Conda) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
